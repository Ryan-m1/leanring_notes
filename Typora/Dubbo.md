# Dubbo架构

![image-20211002075958467](https://raw.githubusercontent.com/syllr/image/main/uPic/20211002080000fVgBAI.png)

Provider启动时会向注册中心把自己的元数据注册上去（比如服务IP和端口等），Consumer在启动时从注册中心订阅（第一次订阅会拉取全量数据）服务提供方的元数据，注册中心中发生数据变更会推送给订阅的Consumer。在获取服务元数据后，Consumer可以发起RPC调用，在RPC调用前后会向监控中心上报统计信息（比如并发数和调用的接口）

## 关键特性

* 面向接口代理的高性能RPC调用：提供高性能的基于代理的远程调用能力，服务以接口为粒度，为开发者屏蔽远程调用底层细节
* 服务自动注册与发现：支持多种注册中心服务，师傅实例上下线实时感知
* 运行期流量调度：内置条件，脚本等路由策略，通过配置不同的路有规则，轻松实现灰度发布，同机房优先等功能
* 智能负载均衡：内置多种负载均衡策略，智能感知下游节点健康状态，显著减少调用延迟，提高系统吞吐量
* 高度可扩展能力：遵循微内核+插件的设计思想，所有核心能力如Protocol，Transport，Serialization被设计为扩展点，平等对待内置实现和第三方实现
* 可视化的服务治理与运维：提供丰富服务治理，运维工具：随时调查服务元数据，服务健康状态及调用统计，实时下发路由策略，调整配置参数

## 解决的问题

* 高性能，透明的RPC调用。只要设计服务之间的通信，RPC就必不可少。Dubbo可以让开发者像调用本地的方法一样调用远程服务，而不需要显式在代码中指定是远程调用。整个过程对上层开发者透明，Dubbo会自动完成后续的所有操作，例如：负载均衡，路由，协议转换，序列化等。开发者只需要接受对应的调用结果即可

* 服务的自动注册与发现。当服务越来越多时，服务URL配置管理变得非常困难，服务的注册和发现已经不可能由人工管理。此时需要一个服务注册中心，动态地注册和发现服务，使服务的位置透明。Dubbo适配了多种注册中心，服务消费方（消费者）可以通过订阅注册中心，及时地知道其他服务提供者的信息，全程无须人工干预

  * 动态负载与容错。当服务越来越多时，F5硬件负载均衡器的单点压力也越来越大。Dubbo提供了完整的集群容错机制，可以实现软件层面的负载均衡，以此降低硬件的压力。Dubbo还提供了调用失败的各种容错机制，如Failover，Failfast，结果集合并等
  * 动态流量调度。在应用运行时，某些服务节点可能因为硬件原因需要减少负载；或者某些节点需要人工手动下线；又或者需要实现单元化的调用，灰度功能。Dubbo提供了管理控制台，用户可以在界面上动态地调整每个服务的权重，路由规则，禁用/启用，实现运行时的流量调度
  * 依赖分析与调用统计。当应用规模进一步提升，服务间的依赖关系变得错综复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？Dubbo可以接入三方APM多分布式链路追踪与性能分析，或者使用已有的独立监控中心来监控接口的调用次数以及耗时，用户可以根据这些数据反推出系统容量

  ## Dubbo总体分层

Dubbo的总体分为业务层(Biz)、RPC层、Remote H层。如果把每一层继续做细分，那么一共可以分为十层，其中Monitor层在最新的官方PPT中不再作为单独的一层

![image-20211002082251496](https://raw.githubusercontent.com/syllr/image/main/uPic/20211002082253u0QEFs.png)

* API层：Service和Config两层可以认为是API层，主要提供给API使用者，使用者无须关心底层 的实现，只需要配置和完成业务代码即可;
* SPI层：后面所有的层级合在一起，可以认为是SPI层，主 要提供给扩展者使用，即用户可以基于Dubb。框架做定制性的二次开发，扩展其功能。Dubbo 的扩展能力非常强，这也是Dubbo一直广受欢迎的原因之一。后续会有专门的章节介绍Dubbo 的扩展机制。

## Dubbo核心组件

* Service：业务层。包括业务代码的接口与实现，即开发者实现的业务代码
* config：配置层。主要围绕ServiceConfig（暴露的服务配置）和ReferenceConfig（引用的服务配置）两个实现类展开，初始化配置信息。可以理解为该层管理了整个Dubbo的配置
* proxy：服务代理层。在Dubbo中，无论生产者还是消费者，框架都会生成一个代理类，整个过 程对上层是透明的。当调用一个远程接口时，看起来就像是调用了一个本地的接口一样， 代理层会自动做远程调用并返回结果，即让业务层对远程调用完全无感
* registry：注册层。负责Dubbo框架的服务注册与发现。当有新的服务加入或旧服务下线时，注册 中心都会感知并通知给所有订阅方。整个过程不需要人工参与
* cluster：集群容错层。该层主要负责:远程调用失败时的容错策略(如失败重试、快速失败); 选择具体调用节点时的负载均衡策略(如随机、一致性Hash等);特殊调用路径的路由 策略(如某个消费者只会调用某个IP的生产者)
* monitor：监控层。这一层主要负责监控统计调用次数和调用时间等
* protocol：远程调用层。封装RPC调用具体过程，Protocol是Invoker暴露(发布一个服务让别人 可以调用)和引用(引用一个远程服务到本地)的主功能入口，它负责管理Invoker的 整个生命周期。Invoker是Dubbo的核心模型，框架中所有其他模型都向它靠拢，或者 转换成它，它代表一个可执行体。允许向它发起invoke调用，它可能是执行一个本地的 接口实现，也可能是一个远程的实现，还可能一个集群实现
* exchange：信息交换层。建立Request-Response模型，封装请求响应模式，如把同步请求转化为异 步请求
* ransport：网络传输层。把网络传输抽象为统一的接口，如Mina和Netty虽然接口不一样，但是 Dubbo在它们上面又封装了统一的接口。用户也可以根据其扩展接口添加更多的网络传 输方式
* Serialize：序列化层。如果数据要通过网络进行发送，则需要先做序列化，变成二进制流。序列化 层负责管理整个框架网络传输时的序列化/反序列化工作

## Dubbo总体调用过程

![image-20211002084556445](https://raw.githubusercontent.com/syllr/image/main/uPic/20211002084557JkR2mu.png)

### 服务者（服务提供者）

服务器端(服务提供者)在框架启动时，会初始化服务实例，通过Proxy组件调 用具体协议(Protocol ),把服务端要暴露的接口封装成Invoker (真实类型是 AbstractProxylnvoker), 然后转换成Exporter,这个时候框架会**打开服务端口**等并记录服务实例 到内存中，最后通过Registry把服务元数据注册到注册中心

* Proxy组件:我们知道，Dubbo中只需要引用一个接口就可以调用远程的服务，并且只需要像调用本地方法一样调用即可。其实是Dubbo框架为我们生成了代理类，调用 的方法其实是Proxy组件生成的代理方法，会自动发起远程/本地调用，并返回结果, 整个过程对用户完全透明。

* Protocol:顾名思义，协议就是对数据格式的一种约定。它可以把我们对接口的配置, 根据不同的协议转换成不同的Invoker对象。例如:用DubboProtocol可以把XML文 件中一个远程接口的配置转换成一个Dubbolnvokero。
* Exporter:用于暴露到注册中心的对象，它的内部属性持有了 Invoker对象，我们可以 认为它在Invoker上包了一层。
* Registry:把Exporter注册到注册中心。

### 消费者

* 获取所有节点：首先，调用过程也是从一个Proxy开始的，Proxy持有了一个Invoker对象。然后触发invoke 调用。在invoke调用过程中，需要使用Cluster, Cluster负责容错，如调用失败的重试，Cluster在调用之前会通过Direcotry获取所有可以调用的远程服务Invoker列表（一个接口可能由多个节点提供服务）由于可以调用的远程服务有很多，此时如果用户配置了路由规则(如指定某些 方法只能调用某个节点)，那么还会根据路由规则将Invoker列表过滤一遍。
* 过滤器，负载均衡：然后，存活下来的Invoker可能还会有很多，此时要调用哪一个呢?于是会继续通过 LoadBalance方法做负载均衡，最终选出一个可以调用的Invokero这个Invoker在调用之前又会 经过一个过滤器链，这个过滤器链通常是处理上下文、限流、计数等。
* 协议改造：接着，会使用Client做数据传输，如我们常见的Netty Client等。传输之前肯定要做一些私 有协议的构造，此时就会用到Codec接口。构造完成后，就对数据包做序列化(Serialization), 然后传输到服务提供者端。服务提供者收到数据包，也会使用Codec处理协议头及一些半包、 粘包等。处理完成后再对完整的数据报文做反序列化处理。
* 线程池处理：随后，这个Request会被分配到线程池(ThreadPool)中进行处理oServer会处理这些Request, 根据请求查找对应的Exporter (它内部持有了 Invoker)0 Invoker是被用装饰器模式一层一层套 了非常多Filter的，因此在调用最终的实现类之前，又会经过一个服务提供者端的过滤器链。

最终，我们得到了具体接口的真实实现并调用，再原路把结果返回。

# Dubbo API

在项目中使用Dubbo由三种方式

* 基于XML实现
* 基于注解实现
* 基于API实现

# 节点角色

| 节点      | 角色说明                               |
| --------- | -------------------------------------- |
| Provider  | 暴露服务的服务提供方                   |
| Consumer  | 调用远程服务的服务消费方               |
| Registry  | 服务注册与发现的注册中心               |
| Monitor   | 统计服务的调用次数和调用时间的监控中心 |
| Container | 服务运行容器                           |

# 注册中心

## 注册中心作用

在Dubbo微服务体系中，注册中心是其核心组件之一。Dubbo通过注册中心实现了分布式环境中各服务之间的注册与发现，是各个分布式节点之间的纽带。其主要作用如下:

* 动态加入。一个服务提供者通过注册中心可以动态地把自己暴露给其他消费者，无须 消费者逐个去更新配置文件。
* 动态发现。一个消费者可以动态地感知新的配置、路由规则和新的服务提供者，无须重启服务使之生效。

* 动态调整。注册中心支持参数的动态调整，新参数自动更新到所有相关服务节点。
* 统一配置。避免了本地配置导致每个服务的配置不一致问题。

## 注册中心分类

Dubbo主要包含四种注册中心的实现，分别是 ZooKeeper，Redis，Simple，Multicast。

* 其中ZooKeeper是官方推荐的注册中心，在生产环境中有过实际使用，具体的实现在Dubbo 源码的dubbo-registry-zookeeper模块中。
* 阿里内部并没有使用Redis作为注册中心，Redis 注册中心并没有经过长时间运行的可靠性验证，其稳定性依赖于Redis本身。
* Simple注册中心 是一个简单的基于内存的注册中心实现，它本身就是一个标准的RPC服务，不支持集群，也可 能出现单点故障。
* Multicast模式则不需要启动任何注册中心，只要通过广播地址，就可以互相 发现。服务提供者启动时，会广播自己的地址。消费者启动时，会广播订阅请求，服务提供者 收到订阅请求，会根据配置广播或单播给订阅者。不建议在生产环境使用。

## 工作流程

* 服务提供者启动时，会向注册中心写入自己的元数据信息，同时会订阅配置元数据信息。
* 消费者启动时，也会向注册中心写入自己的元数据信息，并订阅服务提供者、路由和 配置元数据信息。
* 服务治理中心(dubbo-admin)启动时，会同时订阅所有消费者、服务提供者、路由和 配置元数据信息。

* 当有服务提供者离开或有新的服务提供者加入时，注册中心服务提供者目录会发生变化，变化信息会动态通知给消费者、服务治理中心
* 当消费方发起服务调用时,会异步将调用、统计信息等上报给监控中心( dubbo-monitor・simple)

![image-20211002140144383](https://raw.githubusercontent.com/syllr/image/main/uPic/202110021401452GHyD9.png)

## 数据结构

不同的注册中心的实现方式和数据结构都不同，这里主要讨论ZooKeeper，Redis两种

### ZooKeeper数据结构

ZooKeeper是树形结构的注册中心，每个节点的类型分为持久节点、持久顺序节点、临时节点和临时顺序节点。

Dubbo使用ZooKeeper作为注册中心时，只会创建持久节点和临时节点两种，对创建的顺 序并没有要求。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20211002142737E9pvLw.jpg)

Dubbo把服务信息抽象为四层Root，Service，Type，URL结构，

* Root是注册中心分组，下面由多个服务接口，分组值来自用户配置dubbo:registry中的group属性，默认是/dubbo
* Service：服务接口下包含4类子目录，分别是providers，consumers，routers，configurators，这个路径是持久节点，/dubbo/com.foo.BarService代表了一个Dubbo的服务
  * Providers：这是服务提供者的根节点，每个子节点代表了一个服务者URL元数据信息；
  * Consumers：这是服务消费者的根节点，每个子节点代表了一个消费这URL元数据信息；
  * Routers：每个子节点代表了消费者路由策略URL元数据信息；
  * Configurators：动态配置目录，每个子节点代表了一个用于服务者动态配置URL元数据信息；

| 目录名称                     | 存储值样例                                                   |
| ---------------------------- | ------------------------------------------------------------ |
| /dubbo/service/providers     | dubbo://192.168.0.1.20880/com.alibaba.demo.Service?key=value&... |
| /dubbo/service/consumers     | consumer://192.168.0.1.5002/com.alibaba.demo.Service?key=value&... |
| /dubbo/service/routers       | condition://0.0.0./com.alibaba.demo.Service?category=routers&key=value&... |
| /dubbo/service/configurators | override://com.alibaba.demo.Service?category=configuratots&key=value&... |

服务元数据中的所有参数都是以键值对形式存储的。

### Redis数据结构

Redis注册中心也沿用了Dubbo抽象的Root，Service，Type，URL四层结构。但是由于Redis 属于NoSQL数据库，数据都是以键值对的形式保存的，并不能像ZooKeeper-样直接实现树形 目录结构。因此，Redis使用了 key/Map结构实现了这个需求，Root、Service、Type组合成Redis的key。

Redis的value是一个Map结构，URL作为Map的key,超时时间作为Map的value

![image-20211002144623247](https://raw.githubusercontent.com/syllr/image/main/uPic/202110021446247DPl8Z.png)



## 发布订阅

服务提供者和消费者都需要把自己注册到注册中心。服务提供者的注册是为了让消费者感知服务的存在，从而发起远程调用；也让服务治理中心感知有新的服务提供者上线。消费者的发布是为了让服务治理中心发现自己。

### ZooKeeper

* 发布：在ZooKeeper中创建一个节点（如果是消费者就去Consumers下面创建节点，如果是服务提供者就去Providers下面创建节点）
* 取消发布：删除对应节点
* 订阅：启动时拉取对应目录的全量数据，并在订阅的节点上注册一个watcher，客户端与注册中心之间保持TCP长连接，后续每个节点有任何数据变化的时候，注册中心会通知客户端。
  * 服务端会订阅configurators目录
  * 客户端会订阅providers，routers，configurators三个目录

## 缓存机制

并不是每一次请求都会去查询注册中心获取元数据，消费者或服务治理中心获取注册信息后会做本地缓存。内存中会有一份，保存在Properties 对象里，磁盘上也会持久化一份文件，通过file对象引用

# 服务暴露

所谓的服务暴露就是指根据配置将当前服务使用Netty绑定一个本地的端口号(对于消费者而言，则是尝试连接目标服务的ip和端口)，Dubbo支持很多协议，比如dubbo，http，thrift，webservice，可以选择暴露不同协议的服务，也可以同时暴露多个协议

![image-20211002155704068](https://raw.githubusercontent.com/syllr/image/main/uPic/20211002155705nTD0Vd.png)

在整体上看，Dubbo框架做服务暴露分为两大部分

* 第一步将持有的服务实例通过代理转 换成Invoker

* 第二步会把Invoker通过具体的协议(比如Dubbo) 转换成Exporter,框架做了 这层抽象也大大方便了功能扩展。

  > 这里的Invoker可以简单理解成一个真实的服务对象实例，是 Dubbo框架实体域，所有模型都会向它靠拢，可向它发起invoke调用。它可能是一个本地的实 现，也可能是一个远程的实现，还可能是一个集群实现。

# 服务消费

![image-20211002160152441](https://raw.githubusercontent.com/syllr/image/main/uPic/20211002160153NdHmA8.png)

在整体上看，Dubbo框架做服务消费也分为两大部分

* 第一步通过持有远程服务示例生成Invoker，这个Invoker在客户端是核心的远程代理对象。
* 第二步会把Invoker通过动态代理转换 成实现用户接口的动态代理引用。这里的Invoker承载了网络连接、服务调用和重试等功能，在 客户端，它可能是一个远程的实现，也可能是一个集群实现。

## 直连消费

Dubbo可以绕过注册中心直接向指定服务(直接指定目标IP和端口)发起RPC调用，使 用直连模式可以方便在某些场景下使用，比如压测指定机器等，Dubbo框架也支持同时指定直 连多台机器进行服务调用。

# Dubbo远程调用

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20211002180725sOB4Pv.jpg)

* 首先在客户端启动时会从注册中心拉取和订阅对应的服务列表，Cluster会把拉取的服务列 表聚合成一个Invoker,每次RPC调用前会通过Directory#list获取providers地址(已经生成 好的Invoker列表)，获取这些服务列表给后续路由和负载均衡使用

* 在Dubbo发起服务调用时，**所有路由和负载均衡都是在客户端实现的**。客户端服务调用首 先会触发路由操作，然后将路由结果得到的服务列表作为负载均衡参数，经过负载均衡后会选 出一台机器进行RPC调用，

  > 路由操作：Dubbo的路由机制主要解决的目的就是服务调用时，从已知的所有服务提供者中根据路由规则刷选服务提供者，从当前所有的Provider中根据人为配置的规则，过滤一部分，比如可以用路由机制进行黑白名单配置，对机器实行读写分离（读的服务只保留读服务器，写的服务只保留写服务器），环境隔离等

* 客户端使用负载均衡策略进行负载均衡。

* 将请求交给底层IO线程池处理

# 优雅停机

ubbo 是通过 JDK 的 ShutdownHook 来完成优雅停机的，所以如果用户使用 `kill -9 PID` 等强制关闭指令，是不会执行优雅停机的，只有通过 `kill PID` 时，才会执行。

服务提供方

- 停止时，先标记为不接收新请求，新请求过来时直接报错，让客户端重试其它机器。
- 然后，检测线程池中的线程是否正在运行，如果有，等待所有线程执行完成，除非超时，则强制关闭。

服务消费方

- 停止时，不再发起新的调用请求，所有新的调用在客户端即报错。
- 然后，检测有没有请求的响应还没有返回，等待响应返回，除非超时，则强制关闭。

# Dubbo协议

Dubbo框架支持dubbo、rmi、hessian、http、webservice、thrift、redis等多种协议，但是Dubbo官网是推荐我们使用Dubbo协议的

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20211002181052JPsyvm.jpg)

1. 地址:服务提供者地址
2. 端口:协议指定开放的端口
3. 报文编码:协议报文编码，分为请求头和请求体两部分
4. 序列化方式:将请求体序列化成对象，具体的方式有Hessian2Serialization，DubboSerialization，JavaSerialization，JsonSerization等
5. 运行服务:网络传输实现，实现方式主要有netty，mina，RMI服务，Servlet容器（jetty，tomcat，jboss）

### Dubbo协议格式

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20211002182141GZk5sx.jpg)

如上图可知header总包含了16个字节的数据，其中前两个字节为**魔数**，用来标识一个帧的开始，固定为0xdabb其中第一个字节固定为**0xda**,第二个字节固定为**0xbb**. 

#### 分包粘包

TCP是基于字节流的传输层协议，不会按照应用开发者的期望保持send输入数据的边界，导致接收侧有可能一下子收到多个应用层报文，需要应用开发者自己分开，所以分包粘包的问题其实是基于TCP的应用层协议怎么解析数据的边界问题。

解决方案：

* 应用层设计协议时候协议包分为header和body,header占用固定长度里面记录body长度，当服务端从接受缓冲区读取数据后，如果发现数据大小小于包的长度则说明出现了半包，这时候就回退读取缓存的指针，等待下次读事件到来的时候再次测试。如果发现包长度大于了包长度则看长度是包大小整数倍则说明了出现了粘包，则循环读取多个包，否者就是出现了多个整包+半包。
* 多个包之间添加分隔符。
* 包定长，每个包大小固定长度。

#### Dubbo协议的解决方案

Dubbo也是采用了header和body分离的设计，在header的头两个字节是魔法数字，标志着一个一个新的数据的开始，header一共有16个字节128位，最后4个字节保存着body的长度

# 集群容错

般我们在微服务应用中都是多实例部署，也就是说同一份代码部署多台机器或容器中，这样做的好处是提高服务处理能力。同时由于集群部署，所以整个集群也有容错的能力。

Dubbo有5种容错模式：

* `Failover Cluster`：失败自动切换：当我们在调用Dubbo服务时出现失败，容错策略会重试其它服务器 。（默认策略）对于一些必达性要求高的服务调用，但是服务提供方要求做幂等处理
* `Failfast Cluster`：快速失败：只发起一次调用，如果调用Dubbo服务失败立即报错。通常用于非幂等性的写操作，比如新增记录
* `Failsafe Cluster`：失败安全：当调用Dubbo服务出现异常时，直接忽略，通常用于丢失不敏感业务，例如日志记录等操作
* `Failback Cluster`：失败自动恢复：当调用Dubbo服务失败，后台记录失败请求并定时重发。通常用于必达通知场景，例如消息通知操作
* `Forking Cluster`：集群并行：并行调用多个Dubbo服务，只要其中有一个成功即返回。：通常用于从多个源获取相同数据，以获取最快的响应速度，例如：同时从多个备库查询数据。
* `Broadcast Cluster`：循环调用所有Dubbo服务提供者，任意一台报错则报错。通用用于向多个实例通知消息，例如：更新集群中所有应用缓存或日志。

# 负载均衡策略

Dubbo 负载均衡策略提供下列四种方式：

* Random LoadBalance 随机**，按权重设置随机概率。 **Dubbo的默认负载均衡策略
* RoundRobin LoadBalance 轮循
*  LeastActive LoadBalance 最少活跃调用数：计算滑动窗口中各个节点调用的次数，调用的次数的多的就少调用，调用的次数少的就多调用
* 一致性hash

# 高级特性

* 服务分组和版本：Dubbo中提供的服务分组和版本是强隔离的，如果服务指定了服务分组和版本，则消费方调用也必须传递相同的分组名称和版本名称

* 参数回调：Dubbo支持异步参数回调，当消费方调用服务端方法时，允许服务端在某个时间点回调回 客户端的方法。在服务端回调到客户端时，服务端不会重新开启TCP连接，会复用已经建立的 从客户端到服务端的TCP连接。

* 隐式参数：RpcContext#setAttachment方法中设置隐式参数，后面的远程调用都会隐式的将这些参数发送到服务器端

* 异步调用

* 上下文信息：RpcContext本质上是一个ThreadLocal，当接收到RPC请求或发起RPC请求时，RpcContext的状态会变化。比如A调用B，B再调用C，则B机器上，在B调用C之前，RpcContext记录的是A调用B的信息，在B调用C之后，RpcContext记录的是B调用C.

  ```java
  //服务提供方使用,获取参数
  RpcContext.getContext().getAttachments()
  //服务器消费方使用,设置参数
  RpcContext.getContext().setAttachment() 
  //调接口时，必须是A直接到B，如果A没有直接到B，而是先到C，再由C到B，那么在B里getAttachment()获取不到值
  ```

  