# 并发的性质

并发问题主要有三大性质

* 原子性
* 有序性
* 可见性

## 缓存导致的可见性问题

可见性：一个线程对共享变量的修改，另一个线程能够立刻看到

在单核时代，所有的线程都是在一颗 CPU 上执行，CPU 缓存与内存的数据一致性容易解决。因为所有线程都是操作同一个 CPU 的缓存，一个线程对缓存的写，对另外一个线程来说一定是可见的。

多核时代，每颗 CPU 都有自己的缓存，这时 CPU 缓存与内存的数据一致性就没那么容易解决了，当多个线程在不同的 CPU 上执行时，这些线程操作的是不同的 CPU 缓存。

![image-20211004065637707](https://raw.githubusercontent.com/syllr/image/main/uPic/20211004065639Z11u8o.png)

## 线程切换带来的原子性

![image-20211004065801297](https://raw.githubusercontent.com/syllr/image/main/uPic/202110040658026J2yqy.png)

cpu在执行代码的时候，并不是一行代码就会执行一个指令，往往一条语句需要多条CPU指令完成，比如count += 1

- 指令 1：首先，需要把变量 count 从内存加载到 CPU 的寄存器；
- 指令 2：之后，在寄存器中执行 +1 操作；
- 指令 3：最后，将结果写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）。

操作系统做任务切换，可以发生在任何一条**CPU 指令**执行完，是的，是 CPU 指令，而不是高级语言里的一条语句。

为了我们代码在多线程下面执行的正确性，我们有时候会希望CPU的切换发生在一个完整的语句之后，**我们把一个或者多个操作在 CPU 执行的过程中不被中断的特性称为原子性**。CPU 能保证的原子操作是 CPU 指令级别的，而不是高级语言的操作符，这是违背我们直觉的地方。因此，很多时候我们需要在高级语言层面保证操作的原子性。

## 编译优化带来的有序性问题

有序性指的是程序按照代码的先后顺序执行。编译器为了优化性能，有时候会改变程序中语句的先后顺序。

在 Java 领域一个经典的案例就是利用双重检查创建单例对象

例如下面的代码：在获取实例 getInstance() 的方法中，我们首先判断 instance 是否为空，如果为空，则锁定 Singleton.class 并再次检查 instance 是否为空，如果还为空则创建 Singleton 的一个实例。

```java
public class Singleton {
  static Singleton instance;
  static Singleton getInstance(){
    if (instance == null) {
      synchronized(Singleton.class) {
        if (instance == null)
          instance = new Singleton();
        }
    }
    return instance;
  }
}
```

这看上去一切都很完美，无懈可击，但实际上这个 getInstance() 方法并不完美。问题出在哪里呢？出在 new 操作上，我们以为的 new 操作应该是：

1. 分配一块内存 M；
2. 在内存 M 上初始化 Singleton 对象；
3. 然后 M 的地址赋值给 instance 变量。

但是实际上优化后的执行路径却是这样的：

1. 分配一块内存 M；
2. 将 M 的地址赋值给 instance 变量；
3. 最后在内存 M 上初始化 Singleton 对象。

优化后会导致什么问题呢？我们假设线程 A 先执行 getInstance() 方法，当执行完指令 2 时恰好发生了线程切换，切换到了线程 B 上；如果此时线程 B 也执行 getInstance() 方法，那么线程 B 在执行第一个判断时会发现 `instance != null`，所以直接返回 instance，而此时的 instance 是没有初始化过的，如果我们这个时候访问 instance 的成员变量就可能触发空指针异常。

![image-20211004070547200](https://raw.githubusercontent.com/syllr/image/main/uPic/20211004070548APj6BP.png)

所以需要用volatile关键字修饰变量，禁止指令重排序

```java
public class Singleton {
  //利用volatile修饰变量，禁止指令重排序
  static volatile Singleton instance;
  static Singleton getInstance(){
    if (instance == null) {
      synchronized(Singleton.class) {
        if (instance == null)
          instance = new Singleton();
        }
    }
    return instance;
  }
}
```

# Java内存模型：解决可见性和有序性问题

## 为什么定义Java内存模型

Java语言规范引入了Java内存模型，**通过定义多项规则对编译器和处理器进行限制**，主要是针对可见性和有序性。

导致可见性的原因是缓存，导致有序性的原因是编译优化，那解决可见性、有序性最直接的办法就是**禁用缓存和编译优化**，但是这样问题虽然解决了，我们程序的性能可就堪忧了。

合理的方案应该是**按需禁用缓存以及编译优化**。对于并发程序，何时禁用缓存以及编译优化只有程序员知道，那所谓“按需禁用”其实就是指按照程序员的要求来禁用。所以，为了解决可见性和有序性问题，只需要提供给程序员按需禁用缓存和编译优化的方法即可。

Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括 **volatile**、**synchronized** 和 **final** 三个关键字，以及六项 **Happens-Before 规则**

volatile具有可见性与禁止指令重排序（读操作禁止重排序之后的操作，写操作禁止重排序之前的操作），synchronized的解锁一定在加锁之后，final变量的不变形背后都是Happens-Before规则

## 内存屏障和Happens-Before

先简单了解两个指令：

- Store：将处理器缓存的数据刷新到内存中。
- Load：将内存存储的数据拷贝到处理器的缓存中。

| 屏障类型            | 指令示例                 | 说明                                                         |
| :------------------ | :----------------------- | :----------------------------------------------------------- |
| LoadLoad Barriers   | Load1;LoadLoad;Load2     | 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的的操作 |
| StoreStore Barriers | Store1;StoreStore;Store2 | 该屏障确保Store1立刻刷新数据到内存(使其对其他处理器可见)的操作先于Store2及其后所有存储指令的操作 |
| LoadStore Barriers  | Load1;LoadStore;Store2   | 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作 |
| StoreLoad Barriers  | Store1;StoreLoad;Load2   | 该屏障确保Store1立刻刷新数据到内存的操作先于Load2及其后所有装载装载指令的操作。它会使该屏障之前的所有内存访问指令(存储指令和访问指令)完成之后,才执行该屏障之后的内存访问指令 |

内存屏障可以通过控制cpu对数据的读写顺序来保证有序性，而Happens-before规则可以看作JVM对内存屏障的封装，程序员可以通过编写符合Happens-before规则的代码来控制底层指令执行的顺序。

### Happens-Before的7个规则：

1. 程序次序规则：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说，应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环等结构。
2. 管程（synchronize）锁定规则：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而"后面"是指时间上的先后顺序。
3. volatile变量规则：对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的"后面"同样是指时间上的先后顺序。
4. 线程启动规则：Thread对象的start()方法先行发生于此线程的每一个动作。
5. 线程终止规则：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join（）方法结束、Thread.isAlive（）的返回值等手段检测到线程已经终止执行。
6. 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有中断发生。
7. 对象终结规则：一个对象的初始化完成(构造函数执行结束)先行发生于它的finalize()方法的开始。

## volatile和锁的区别

从语意上来讲

* 锁需要保证可见性和原子性
* volatile只保证可见性

所以锁在功能上是volatile的超集，所有用volatile实现的功能锁都能实现，所以可以很自然的得出volatile的应用场景：在只需要保证可见性的场景才使用volatile，在需要保证原子性的场景，不要使用 volatile。

比如我们使用多线程修改一个X的值，如果修改的语句是X=X+1；就不能使用volatile，因为X=X+1这条语句不是原子性的，需要先读取X原来的值，但是如果修改语句是X=100，就可以使用volatile修饰X，因为这条语句不需要用到X原来的值。

总结下来必须要同时满足以下两个条件才能使用volatile

1. 对变量的写操作不依赖于当前值：因为如果写之前需要读取数据，写依赖读的结果，所以写操作不能保证原子性
2. 该变量所依赖的变量是常量或者也不需要满足原子性

## final

final的语意是不变量，因为是不变量所以在初始化之后就不会有写操作，编译器可以根据这层语意做更多的优化

# Synchronized

<img src="https://raw.githubusercontent.com/syllr/image/main/uPic/202110041017058aqTGD.png" alt="image-20211004101704327" style="zoom:67%;" />

### 管程

管程(英语：Monitors，也称为监视器) 在操作系统中是很重要的概念，管程其实指的是**管理共享变量以及对共享变量的操作过程，让他们支持并发**翻译为 Java 领域的语言，就是管理类的成员变量和成员方法，让这个类是线程安全的。

#### 管程和信号量

信号量机制是可以解决同步/互斥的问题的，但是信号量的操作分散在各个进程或线程中，不方便进行管理，因每次需调用PV操作，还可能导致死锁或破坏互斥请求的问题。

管程是定义了一个数据结构和能为并发所执行的一组操作，这组操作能够进行同步和改变管程中的数据。这相当于对临界资源的同步操作都集中进行管理，凡是要访问临界资源的进程或线程，都必须先通过管程，由管程的这套机制来实现多进程或线程对同一个临界资源的互斥访问和使用。管程的同步主要通过condition类型的变量（条件变量），条件变量可执行操作wait()和signal()。管程一般是由语言编译器进行封装，体现出OOP中的封装思想，管程模型和面向对象高度契合的。

#### 管程模型

在管程的发展史上，先后出现过三种不同的管程模型，分别是：Hasen 模型、Hoare 模型和 MESA 模型。其中，现在广泛应用的是 MESA 模型，并且 Java 管程的实现参考的也是 MESA 模型。

在并发编程领域，有两大核心问题：一个是**互斥**，即同一时刻只允许一个线程访问共享资源；另一个是**同步**，即线程之间如何通信、协作。这两大问题，管程都是能够解决的。

<img src="https://raw.githubusercontent.com/syllr/image/main/uPic/2021100414333220FpAp.png" alt="image-20211004103912227" style="zoom: 50%;" />

**管程解决互斥问题的思路很简单，就是将共享变量及其对共享变量的操作统一封装起来。**

在上图中，管程 X 将共享变量 queue 这个队列和相关的操作入队 enq()、出队 deq() 都封装起来了；线程 A 和线程 B 如果想访问共享变量 queue，只能通过调用管程提供的 enq()、deq() 方法来实现；enq()、deq() 保证互斥性，只允许一个线程进入管程。

具体模型

<img src="https://raw.githubusercontent.com/syllr/image/main/uPic/20211004143351wcgIwW.png" alt="image-20211004143226290" style="zoom:50%;" />

图中最外层的框就代表封装的意思。框的上面只有一个入口，并且在入口旁边还有一个入口等待队列，当多个线程同时试图进入管程内部时，**只允许一个线程进入，入口相当于一把互斥锁，用于线程间的互斥，只让一个线程进入临界区保证了进程间的互斥**，其他线程则在入口等待队列中等待。

管程里还引入了条件变量的概念，而且**每个条件变量都对应有一个等待队列**，条件变量是条件的抽象，指当前线程是否满足继续执行的条件（比如生产者-消费者模型中，消费者必须要等队列不为空的时候才能消费，这个就是消费者线程继续执行的条件），而条件变量的等待队列里面的线程都是进入了临界区然后发现不满足继续执行的条件的线程

> 进入了条件变量等待队列的线程是会让出上面说的入口的互斥锁，所以一旦线程进入条件等待对立之后，别的线程就可以进入临界区了

上面介绍了条件变量和条件变量的等待队列，那么怎么进行条件变量等待队列的出队和入队呢

* wait()：将当前线程阻塞，放入条件变量等待队列中
* notify()：唤醒等待队列中的某一个线程，**让该线程重新加入入口等待队列去获取入口的互斥锁**
* notifyALL()：唤醒等待队列中的所有线程，**让这些线程重新加入入口等待队列去获取入口的互斥锁**

管程模型通过条件变量和条件变量等待队列实现了线程之间的同步，**管程和信号量是等价的，所谓等价指的是用管程能够实现信号量，也能用信号量实现管程，管程就是对信号量的OOP封装**

> 互斥量，信号量，PV操作：互斥量，信号量，PV操作是操作操作系统上的提供的原语
>
> 互斥量表现互斥现象的数据结构，也被当作二元信号灯。一个互斥基本上是一个多任务敏感的二元信号，它能用作同步多任务的行为，它常用作保护从中断来的临界段代码并且在共享同步使用的资源。
>
> 信号量(Semaphore)，有时被称为信号灯，是在多线程环境下使用的一种设施, 它负责协调各个线程, 以保证它们能够正确、合理的使用公共资源。
>
> 从上面可以看出来，值为1的信号量就是互斥量，互斥量主要用于线程间的互斥，信号量用于线程间通信
>
> 注意信号量和互斥量，PV操作都是抽象的概念，不同的语言有不同的实现，不管实现怎么实现，其本质其实就是用一个数值类型的变量（int或者long都可以）存储线程间的共享信息，而信号量和互斥量能作为线程间通信资源的理由是要满足对信号量，互斥量的操作都是**原子操作**，PV操作就是对信号量的操作
>
> P代表对信号量减一
>
> V代表对信号量加一
>
> PV操作的底层实现是基于CPU的特殊指令，该指令实现了对数据增加和减少的原子性（具体的逻辑是CPU在用该指令修改数据的时候会Lock住总线，防止其他CPU修改数据），其他任何满足这种特性的操作都可以作为PV操作

### 管程模型的实现

管程的MESA模型的实现，java中有两种MESA模型的实现，一种是synchronized，一种JUC包中的AQS，其中synchronized实现的是单条件变量模型，AQS实现的是多条件变量模型，下图为单条件变量模型

<img src="https://raw.githubusercontent.com/syllr/image/main/uPic/20211007204114VeVSS0.png" alt="image-20211007204106859" style="zoom: 67%;" />

下图为多条件变量模型

<img src="https://raw.githubusercontent.com/syllr/image/main/uPic/20211007204042vPCNEa.png" alt="image-20211007204025607" style="zoom:67%;" />

下面是JUC中并发锁的代表实现ReentrantLock实现生产者消费者模式的代码

```java
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class BlockedQueue<T> {
    final Lock lock = new ReentrantLock();
  	//ReentrantLock可以支持多个条件变量
    // 条件变量：队列不满
    final Condition notFull = lock.newCondition();
    // 条件变量：队列不空
    final Condition notEmpty = lock.newCondition();
    
    // 入队
    void enq(T x) {
        lock.lock();
        try {
            while (队列已满) {
                // 等待队列不满，（当前线程加入到notFull条件变量的等待队列中）
                notFull.await();
            }
            // 省略入队操作...
            // 入队后, 通知可出队（从notEmpty条件变量的等待队列中唤醒线程）
            notEmpty.signal();
        } finally {
            lock.unlock();
        }
    }
    
    // 出队
    void deq() {
        lock.lock();
        try {
            while (队列已空) {
                // 等待队列不空，（当前线程加入到notEmpty条件变量的等待队列中）
                notEmpty.await();
            }
            // 省略出队操作...
            // 出队后，通知可入队（从notFull条件变量的等待对立中唤醒线程）
            notFull.signal();
        } finally {
            lock.unlock();
        }
    }
}
```

### 管程需要注意的两点

1. wait()要放在while循环里面，不能放在for循环

   > 因为当一个线程被唤醒的时候会被重新加入到入口的等待队列中重新进行锁竞争，这个时候可能入口的等待队列还有别的线程，可能是别的线程竞争到了锁，**导致被唤醒的线程拿到锁之后并不是一定满足条件变量的**，线程被唤醒后会从上次阻塞的位置继续执行代码，如果是for循环，不会在进行一次条件变量判断，会造成异常情况，而while循环会在每一次进入的时候重新判断条件变量，如果不满足则重新wait()，以所有的java书籍都会建议开发者**永远都要把wait()放到while循环语句里面**

2. 在唤醒线程的时候使用notifyAll()，而不是notify()

   > 假如现在有一个生产者消费者模型，里面有生产者A，生产者B，消费者A，消费者B，4个线程，缓冲区只能存放一个数据，可能会出现这么一种情况，生产者A获取到了锁，而生产者B，消费者A，消费者B都在条件变量的等待队列中，这个时候如果生产者A生产了一个数据之后，调用了notify()，唤醒的是生产者B，生产者B线程意外退出，而生产者A因为缓冲区已经满了，所以也进入条件变量的等待队列，这个时候整个系统里面就只有三个线程了，而且这三个线程全都在条件变量的等待队列中等待被唤醒。
   >
   > 所以用notifyAll一次性唤醒所有线程，可以避免有线程意外退出导致的所有线程都被阻塞的情况
   >
   > 代码如下
   >
   > ```java
   > import java.util.ArrayList;
   > import java.util.List;
   > 
   > public class Something {
   >     private Buffer mBuf = new Buffer();
   > 
   >     public void produce() {
   >         synchronized (this) {
   >             while (mBuf.isFull()) {
   >                 try {
   >                     wait();
   >                 } catch (InterruptedException e) {
   >                     e.printStackTrace();
   >                 }
   >             }
   >             mBuf.add();
   >             notifyAll();
   >         }
   >     }
   > 
   >     public void consume() {
   >         synchronized (this) {
   >             while (mBuf.isEmpty()) {
   >                 try {
   >                     wait();
   >                 } catch (InterruptedException e) {
   >                     e.printStackTrace();
   >                 }
   >             }
   >             mBuf.remove();
   >             notifyAll();
   >         }
   >     }
   > 
   >     private class Buffer {
   >         private static final int MAX_CAPACITY = 1;
   >         private List innerList = new ArrayList<>(MAX_CAPACITY);
   > 
   >         void add() {
   >             if (isFull()) {
   >                 throw new IndexOutOfBoundsException();
   >             } else {
   >                 innerList.add(new Object());
   >             }
   >             System.out.println(Thread.currentThread().toString() + " add");
   > 
   >         }
   > 
   >         void remove() {
   >             if (isEmpty()) {
   >                 throw new IndexOutOfBoundsException();
   >             } else {
   >                 innerList.remove(MAX_CAPACITY - 1);
   >             }
   >             System.out.println(Thread.currentThread().toString() + " remove");
   >         }
   > 
   >         boolean isEmpty() {
   >             return innerList.isEmpty();
   >         }
   > 
   >         boolean isFull() {
   >             return innerList.size() == MAX_CAPACITY;
   >         }
   >     }
   > 
   >     public static void main(String[] args) {
   >         Something sth = new Something();
   >         Runnable runProduce = new Runnable() {
   >             int count = 4;
   > 
   >             @Override
   >             public void run() {
   >                 while (count-- > 0) {
   >                     sth.produce();
   >                 }
   >             }
   >         };
   >         Runnable runConsume = new Runnable() {
   >             int count = 4;
   > 
   >             @Override
   >             public void run() {
   >                 while (count-- > 0) {
   >                     sth.consume();
   >                 }
   >             }
   >         };
   >         for (int i = 0; i < 2; i++) {
   >             new Thread(runConsume).start();
   >         }
   >         for (int i = 0; i < 2; i++) {
   >             new Thread(runProduce).start();
   >         }
   >     }
   > }
   > ```

## Mark word

Synchronized在Java JVM里的实现是基于进入和退出Monitor对象来实现方法同步和代码块同步的。monitor enter指令是在编译后插入到同步代码块的开始位置，而monitor exit是插入到方法结束处和异常处，JVM要保证每个monitor enter必须有对应的monitor exit与之配对。

任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitor enter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁，锁对象的地址存在Java对象头的Mark word中。

Java对象存储在堆（Heap）内存。那么一个Java对象到底包含什么呢？概括起来分为对象头、对象体和对齐字节。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20211005085404qZCuAF.png)

对象头中的Mark Word（标记字）主要用来表示对象的线程锁状态，另外还存有对象被GC的次数、存放该对象的hashCode；

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20211005090230oBRNlh.jpg)

由于正常锁和偏向锁的锁标识都是 01，没办法区分，这里引入一位的偏向锁标识位。

* identity_hashcode：对象的hashcode，运行期间调用System.identityHashCode()来计算，延迟计算，并把结果赋值到这里
* age：表示对象被GC的次数，当该次数到达阈值的时候，对象就会转移到老年代。
* thread：偏向锁的线程ID， 当某个线程持有对象的时候，对象这里就会被置为该线程的ID。 在后面的操作中，就无需再进行尝试获取锁的动作。
* epoch：偏向锁撤销判断标识位
* ptr_to_lock_record：轻量级锁状态下，指向栈中锁记录的指针。当锁获取是无竞争的时，JVM使用原子操作而不是OS互斥。这种技术称为轻量级锁定。在轻量级锁定的情况下，JVM通过CAS操作在对象的标题字中设置指向锁记录的指针。
* ptr_to_heavyweight_monitor：重量级锁状态下，指向对象监视器Monitor（就是管程）的指针。如果两个不同的线程同时在同一个对象上竞争，则必须将轻量级锁定升级到Monitor以管理等待的线程。在重量级锁定的情况下，JVM在对象的ptr_to_heavyweight_monitor设置指向Monitor的指针。

> Mark Word中可以存储对象的identity hash code值。当对象的hashCode()方法（非用户自定义）第一次被调用时，JVM会生成对应的identity hash code值，并将该值存储到Mark Word中。后续如果该对象的hashCode()方法再次被调用则不会再通过JVM进行计算得到，而是直接从Mark Word中获取。只有这样才能保证多次获取到的identity hash code的值是相同的（以jdk8为例，JVM默认的计算identity hash code的方式得到的是一个随机数，因而我们必须要保证一个对象的identity hash code只能被底层JVM计算一次）。
> 我们还知道，对于轻量级锁，获取锁的线程栈帧中有锁记录（Lock Record）空间，用于存储Mark Word的拷贝，官方称之为Displaced Mark Word，该拷贝中可以包含identity hash code，所以轻量级锁可以和identity hash code共存；对于重量级锁，ObjectMonitor类里有字段可以记录非加锁状态下的mark word，其中也可以存储identity hash code的值，所以重量级锁也可以和identity hash code共存。
>
> 对于偏向锁，在线程获取偏向锁时，会用Thread ID和epoch值覆盖identity hash code所在的位置。如果一个对象的hashCode()方法已经被调用过一次之后，这个对象还能被设置偏向锁么？答案是不能。因为如果可以的话，那Mark Word中的identity hash code必然会被偏向线程Id给覆盖，这就会造成同一个对象前后两次调用hashCode()方法得到的结果不一致。
>
> HotSpot VM的锁实现机制是：
>
> * 当一个对象已经计算过identity hash code，它就无法进入偏向锁状态；
> * 当一个对象当前正处于偏向锁状态，并且需要计算其identity hash code的话，则它的偏向锁会被撤销，并且锁会膨胀为轻量级锁或者重量锁；
> * 轻量级锁的实现中，会通过线程栈帧的锁记录存储Displaced Mark Word；重量锁的实现中，ObjectMonitor类里有字段可以记录非加锁状态下的mark word，其中可以存储identity hash code的值。
>
> ![在这里插入图片描述](https://raw.githubusercontent.com/syllr/image/main/uPic/20211005091650ocmAjC.png)

## 锁升级

Java 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：**无锁状态**、**偏向锁状态**、**轻量级锁状态**和**重量级锁状态**，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级（要看JVM实现，有的JVM可以降级）。

* 无锁状态：当一个对象没有被syncronized修饰，或者被syncronizied修饰的对象没有被任何线程访问时，对象是无锁状态

* 偏向锁：偏向锁获取和升级的过程比较复杂

  * 首先当线程通过对象的mark word上的标志位发现当前对象是偏向锁时，先判断mark word中的线程id是不是和自己的id一样，如果一样线程就进入临界区

  * 如果不一样，说明偏向锁已经被别的线程持有过了，这个时候分两种情况，1：持有锁的线程已经退出临界区，2：持有锁的线程还在临界区中，那怎么区分这两种情况呢

  * 对象的mark word中有一个epoch字段，通过epoch字段可以判断出上次持有锁的线程是否还在临界区（具体算法我还没弄清楚，相当复杂，但是逻辑上是这样的），如果已经不在临界区内，则进行偏向锁撤回（即把mark word中的线程id置为null），然后通过CAS操作把thread id设置为当前线程的，如果还在临界区，则会重试，重试超过一定次数（默认是20）就会升级为轻量级锁

    > 替换线程的CAS操作的期望值为null，也就是说只有当mark word中的thread id为null才会CAS替换线程成功，这也是为什么很多文章上说的CAS成功就获取到偏向锁的原因
    >
    > 轻量级锁进入临界区的时候把thread id设置为当前id，然后在退出临界区的时候把thread id设置为null，但是因为偏向锁的使用场景是一个线程重复进入临界区，所以出现多个线程**串形**交替进入临界区的情况比较少，所以不用每次退出临界区都删除threa id，而是通过当发生线程串行交替进入临界区的时候被动触发偏向锁撤回，利用epoch字段记录线程执行状态，这样如果只有一个线程重复进入临界区，每次就只会进行一次thread id的比较，速度非常快，偏向锁本质上是一种对于轻量级锁空间换时间（多了一个epoch字段）的性能优化。

* 轻量级锁：会在线程栈帧中分配一个lock record空间储存对象的原来的mark word信息，然后通过CAS操作用当前线程的lock record地址替换对象mark word中的指针，替换成功当前线程获取轻量级锁，替换失败，进行**自旋**（多次cas：1.6以前10次，1.6以后自适应自旋，根据上一次自旋获取锁的时间，决定当前自旋的次数），**自旋失败超过次数，锁升级为重量级锁**

  > 这里的通过CAS操作将mark word中的指针替换为lock record的地址，CAS的期望值也是null，轻量级锁在进去临界区的时候会用CAS把mark word中lock record的指向设置为当前线程中的lock record，在退出临界区的时候会使用CAS把mark word中的lock record的指向设置为null，对比偏向锁轻量级锁，加入了自旋的逻辑，但是多了一次到两次的CAS操作，耗时更长一点

* 重量级锁：通过对象监视器monitor获取锁，monitor是单条件变量模型的java实现，monitor中的线程互斥其实依赖的是操作系统的信号量和PV操作，PV操作是内核操作，需要进行用户态和内核态的切换，以及线程的切换，同时monitor的操作也更复杂，所以效率对比偏向锁和轻量级锁更差，结构如下图：

  ![img](https://raw.githubusercontent.com/syllr/image/main/uPic/202110051002419PzYp8.jpg)

总体的锁升级流程如下图

![492727-20180401091538784-840321121](https://raw.githubusercontent.com/syllr/image/main/uPic/202110051615055lnlG1.png)

总结

* 偏向锁对应了同一段时间内只有一个线程重复进入临界区，或者多个线程串形地交替进入临界区的场景
* 轻量级锁是对应了多个线程并行的进入临界区但是竞争不是特别强的场景（自旋锁可以避免线程切换的开销，但是要占用处理器时间，如果锁被锁定比较段，自旋锁效果非常好，但是如果锁被占用非常长，自旋锁会造成非常大的浪费）
* 重量级锁是对应了多个线程并行的进入临界区且竞争特别强的场景

# 线程

## 线程状态

<img src="/Users/yutao/Library/Application Support/typora-user-images/image-20211004185417294.png" alt="image-20211004185417294" style="zoom:50%;" />

其实在操作系统层面，Java 线程中的 BLOCKED、 WAITING、TIMED_WAITING 是一种状态，即上面我们提到的休眠状态。也就是说只要 Java 线程处于这三种状态之一，那么这个线程就永远没有 CPU 的使用权，Java把系统中的休眠状态映射成三种状态主要是为了区别条件变量的等待队列，入口的等待队列的线程状态，以及调用join函数之后的状态。

## 线程中断

在java中，线程的中断(interrupt)只是改变了线程的中断状态，至于这个中断状态改变后带来的结果，那是无法确定的，有时它更是让停止中的线程继续执行的唯一手段。不但不是让线程停止运行，反而是继续执行线程的手段。

对于执行一般逻辑的线程，如果调用它的interrupt()方法，那么对这个线程没有任何影响

其它线程调用a.interrupt()；那么并不会影响a对象上运行的线程，但中断标志会变为true。如果在其它线程里再次测试a的中断状态，则中断标志为true，但并不会停止这个线程的运行。

### 中断标志位的作用

中断标志位其实是线程中的一个被volatile修饰的变量，用来通知线程中断信息的，当主线程向目标线程发起interrupt中断命令后，目标线程的中断标志位被置为true，目标线程通过查询中断标志位自行决定是否停止当前线程的执行。

### InterruptedException

调用Thread.sleep()时都需要捕获InterruptedException异常。这个异常的作用是什么？

如果目标线程正在执行阻塞方法(sleep、join)，而其他线程恰好调用了目标线程的interrupt方法试图中断目标线程，sleep、join这类阻塞方法会检查线程的中断标志位，并抛出InterruptedException异常，也就是说中断会唤醒正在阻塞的线程，**InterruptedException清空中断标志位**。

## ThreadLocal

ThreadLocal是一个关于创建线程局部变量的类。

通常情况下，我们创建的成员变量都是线程不安全的。因为他可能被多个线程同时修改，此变量对于多个线程之间彼此并不独立，是共享变量。而使用ThreadLocal创建的变量只能被当前线程访问，其他线程无法访问和修改。也就是说：将线程公有化变成线程私有化。

### 使用例子

![image-20211004204931502](https://raw.githubusercontent.com/syllr/image/main/uPic/20211004204932v1wPy6.png)

![image-20211004204941136](https://raw.githubusercontent.com/syllr/image/main/uPic/20211004204942JXoGnm.png)

在使用threadLocal对象的get方法时，会先获取当前线程，然后获取当前线程保存的ThreadLocalMap，再把自己（threadLocal对象）作为参数，从ThreadLocalMap查询出数据

```java
//JDK中threadLocal的get方法源代码
	public T get() {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null) {
          	//注意这里的this指的是当前的threadLocal对象
            ThreadLocalMap.Entry e = map.getEntry(this);
            if (e != null) {
                @SuppressWarnings("unchecked")
                T result = (T)e.value;
                return result;
            }
        }
        return setInitialValue();
    }
```

### ThreadLocalMap

每个Thread对象都持有一个ThreadLocalMap的成员变量。每个ThreadLocalMap内部又维护了N个Entry节点，也就是Entry数组，每个Entry代表一个完整的对象，key是ThreadLocal本身，value是ThreadLocal的泛型值

```java
// java.lang.Thread类里持有ThreadLocalMap的引用
public class Thread implements Runnable {
    ThreadLocal.ThreadLocalMap threadLocals = null;
}

// java.lang.ThreadLocal有内部静态类ThreadLocalMap
public class ThreadLocal<T> {
    static class ThreadLocalMap {
        private Entry[] table;
        
        // ThreadLocalMap内部有Entry类，Entry的key是ThreadLocal本身，value是泛型值
        static class Entry extends WeakReference<ThreadLocal<?>> {
            Object value;
            Entry(ThreadLocal<?> k, Object v) {
                super(k);
                value = v;
            }
        }
    }
}
```

![preview](https://raw.githubusercontent.com/syllr/image/main/uPic/202110042057135YVE8T.jpg)

从上图可以看出ThreadLocal的本质是在每个线程中维护一个map，这个map的key为threadLocal对象，value为threadLocal对象的泛型值

### ThreadLocal与弱引用

ThreadLocal.Entry继承自弱引用

```java
static class Entry extends WeakReference<ThreadLocal<?>> {
    Object value;
    Entry(ThreadLocal<?> k, Object v) {
        super(k);
        value = v;
    }
}
```

key直接是交给了父类处理`super(key)`，父类是个弱引用，所以key完全不存在内存泄漏问题，因为他不是强引用，当除了TheadLocalMap之外引用threadLocal的对象被销毁了之后，这个threadLocal就只剩一个来自ThreadLocalMap的弱引用，它可以被GC回收的。

> 弱引用的特点：如果这个对象只被弱引用关联，没有任何强引用关联，那么这个对象就可以被GC回收掉。弱引用不会阻止GC回收。这是jvm知识。

再看value，发现value是个强引用，但是想了下也没问题的呀，因为线程终止了，我管你强引用还是弱引用，都会被GC掉的，因为引用链断了（jvm用的可达性分析法，线程终止了，根节点就断了，下面的都会被回收）。

这么分析一点毛病都没有，但是忘了一个主要的角色，那就是**线程池**，线程池的存在核心线程是不会销毁的，只要创建出来他会反复利用，生命周期不会结束掉，但是key是弱引用会被GC回收掉，value强引用不会回收，所以形成了如下场面：

```java
Thread->ThreadLocalMap->Entry(key为null)->value
```

由于value和Thread还存在链路关系，还是可达的，所以不会被回收，这样越来越多的垃圾对象产生却无法回收，造成内存泄漏，时间久了必定OOM。

解决方案`ThreadLocal`已经为我们想好了，提供了`remove()`方法，这个方法是将value移出去的。所以用完后记得`remove()`。

## CountDownLatch

CountDownLatch是一个非常实用的多线程控制工具类。常用的就下面几个方法：

```java
CountDownLatch(int count) //实例化一个倒计数器，count指定计数个数
countDown() // 计数减一
await() //等待，当计数减到0时，所有线程并行执行
```

对于倒计数器，一种典型的场景就是火箭发射。在火箭发射前，为了保证万无一失，往往还要进行各项设备、仪器的检测。只有等到所有的检查完毕后，引擎才能点火。那么在检测环节当然是多个检测项可以同时进行的。代码实现：

```java
public class CountDownLatchDemo implements Runnable{

    static final CountDownLatch latch = new CountDownLatch(10);
    static final CountDownLatchDemo demo = new CountDownLatchDemo();

    @Override
    public void run() {
        // 模拟检查任务
        try {
            Thread.sleep(new Random().nextInt(10) * 1000);
            System.out.println("check complete");
        } catch (InterruptedException e) {
            e.printStackTrace();
        } finally {
            //计数减一
            //放在finally避免任务执行过程出现异常，导致countDown()不能被执行
            latch.countDown();
        }
    }


    public static void main(String[] args) throws InterruptedException {
        ExecutorService exec = Executors.newFixedThreadPool(10);
        for (int i=0; i<10; i++){
            exec.execute(demo);
        }

        // 等待检查
        latch.await();

        // 发射火箭
        System.out.println("Fire!");
        // 关闭线程池
        exec.shutdown();
    }
}
```

### CountDownLatch实现原理

CountDownLatch一个同步辅助工具，基于 AQS 实现

<img src="https://raw.githubusercontent.com/syllr/image/main/uPic/20211006181510Ltapej.jpg" alt="img" style="zoom:50%;" />

通过类图可以看出，CountDownLatch 内部存在一个静态类 Sync，而 Sync 继承了 AbstractQueuedSynchronizer

 CountDownLatch 是基于 AQS 共享模式实现的，在初始化时必须传入计数，该计数实际上是 AQS 的 state 值。在 countDown 时对 state 进行递减，在 当 state 为 0 时 会唤醒 AQS 队列中的所有等待的节点 （因为是共享模式）。而 await 方法是判断 state 的值，如果不是 0 ，则所有线程在队列中阻塞，等待唤醒。

# 线程池

线程是一个重量级的对象，应该避免频繁创建和销毁

目前业界线程池的设计，普遍采用的都是**生产者-消费者模式**。线程池的使用方是生产者，线程池本身是消费者，既然是生产者-消费者模式，就需要有一个队列保存任务。

### 线程池参数

* corePoolSize：表示线程池保有的最小线程数
* maximumPoolSize：表示线程池创建的最大线程数
* keepAliveTime & unit：如果“一段时间内都没有执行任务”，如果当前线程池的线程数大雨corePoolSize，那么这个线程就会被回收，而keepAlive & unit就是用来定义这个“一段时间”的
* workQueue：工作队列，工作队列的选择非常重要，不同的工作队列决定线程池不同的性质
* thredFactory：通过这个参数你可以自定义如何创建线程，例如你可以给线程指定一个有意义的名字
* handler：通过这个参数你可以自定义任务的拒绝策略。如果线程池中所有的线程都在忙碌，并且工作队列也满了（前提是工作队列是有界队列），那么此时提交任务，线程池就会拒绝接收。至于拒绝的策略，你可以通过handler这个参数来指定。ThreadPoolExecutor已经提供了以下4种策略。
  * CallerRunsPolicy：提交任务的线程自己去执行该任务
  * AbortPolicy：默认的拒绝策略，会throws RejectedExecutionException
  * DiscardPolicy：直接丢弃任务，没有任何异常抛出，用这个策略一般会打印出任务信息再丢弃
  * DiscardOldestPolicy：丢弃最老的任务，其实就是把最早进入工作队列的任务丢弃，然后把新任务加入到工作队列

### 线程池的类型

考虑到ThreadPoolExecutor的构造函数实在是有些复杂，所以Java并发包里提供了一个线程池的静态工厂类Executors，利用Executors你可以快速创建线程池。不过不建议使用Executors，因为Executors提供的很多方法默认都是无界的`LinkedBlockingQueue`，高负载情境下，无界队列很容易导致OOM，而OOM会导致所有请求都无法处理，这是致命问题。所以**强烈建议使用有界队列**。

> 总结一点就是使用ArrayBlockingQueue作为有界队列（另一类是有界的优先级队列常用的是PriorityBlockingQueue），然后根据业务的需要选择一个拒绝提交策略

线程池的执行逻辑如下图：

![WechatIMG44](https://raw.githubusercontent.com/syllr/image/main/uPic/202110042238113TxHpo.png)

# 死锁

竞争锁可能会造成死锁（一组相互竞争资源的线程因相互等待，导致‘永久’阻塞）

<img src="/Users/yutao/Library/Application Support/typora-user-images/image-20211005081822414.png" alt="image-20211005081822414" style="zoom: 50%;" />

## 预防死锁

只要破坏死锁发生的条件就能预防死锁，死锁发生的条件又以下几种：

1. 互斥，共享资源X和Y只能被一个线程占用（这个条件无法破坏，锁本来定义就是互斥的）
2. 占有等待，线程1已经取得共享资源X，在等待共享资源Y的时候，不是放共享资源X
3. 不可抢占：其他线程不能强行抢占T1占有的资源
4. 循环等待：线程T1扽带线程T2占有资源，线程T2等待线程T1占有资源

对于上面的2，3，4点，有以下解决办法

* 对于占有等待：可以一次性申请所有的资源，比如我需要锁A和锁B，我就一次性申请锁A和锁B，如果只能申请到其中一个，就不申请
* 对于不可抢占：占用部分资源的线程进一步申请其他资源时，如果超过一定的时间申请不到，可以主动释放它的占有条件
* 循环等待：可以按序申请资源，为资源指定一个顺序，先申请顺序小的资源，再申请顺序大的资源，保证所有的线程申请资源的顺序是一样的

## 活锁

```java
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.TimeUnit;

public class Account {
    public Account(int balance, String card) {
        this.balance = balance;
        this.card = card;
    }
    
    private int balance;
    private String card;
    
    public void addMoney(int amount) {
        balance += amount;
    }
    // 省略 get set 方法
}

public class AccountLiveLock {
    
    public static void transfer(Account from, Account to, int amount) throws InterruptedException {
        // 模拟正常的前置业务
        TimeUnit.SECONDS.sleep(1);
        // 保证转帐必定成功
        while (true) {
            if (from.lock.tryLock(1, TimeUnit.SECONDS)) {
                try {
                    System.out.println(Thread.currentThread().getName() + " lock from account " + from.getCard());
                    if (to.lock.tryLock(1, TimeUnit.SECONDS)) {
                        try {
                            System.out.println(Thread.currentThread().getName() + " lock to account " + to.getCard());
                            // 转出帐号扣钱
                            from.addMoney(-amount);
                            // 转入帐号加钱
                            to.addMoney(amount);
                            break;
                        } finally {
                            to.lock.unlock();
                        }
                        
                    }
                } finally {
                    from.lock.unlock();
                }
            }
        }
        System.out.println("transfer success");
        
    }
    
    public static void main(String[] args) {
        Account from = new Account(100, "A");
        Account to = new Account(100, "B");
        
        ExecutorService threadPool = Executors.newFixedThreadPool(2);
        
        // 线程 1
        threadPool.execute(() -> {
            try {
                transfer(from, to, 50);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
        
        // 线程 2
        threadPool.execute(() -> {
            try {
                transfer(to, from, 30);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        });
    }
}
```

上面的代码中两个线程都先获取自己的账号的锁，再获取对方账号的锁，因为使用的是tryLock()非阻塞API，每次获取不到锁就会释放已经获取到的锁，然后尝试重新开始获取两把锁，但是可能每次两个线程都是先获取自己的锁，然后再尝试获取对方的锁，线程不断重复一样的操做，但也却执行不成功。

活锁并不会一直获取不到锁，在重试的过程中，可能有一次两个线程的获取锁的顺序发生了变化，就可以都获取到自己想要的锁，但是在尝试获取锁的过程中，一直重试会严重浪费时间，占用CPU

活锁的主要原因是锁超时时间都同样，致使两个线程几乎同时释放锁，重试时又同时上锁，而后陷入死循环。解决这个问题，咱们可使超时时间不同，引入必定的随机性。

发生活锁的条件和发生死锁是一样的，只不过活锁是因为用了非阻塞的API比如tryLock()，导致一直重试。所以用来解决死锁的方法也可以用来解决活锁，除此之外，活锁还有一种解决办法，就是在获取锁的时候加上一个随机的超时时间，比如在上面的例子中使用`tryLock(randomTime)`来获取锁。

# 读写锁

三条基本原则

* 读锁和读锁兼容
* 读锁和写锁互斥
* 写锁和读锁和写锁都互斥

# JUC

## 并发容器

在java1.5之后JUC包提供了一些支持并发的数据结构，我们称之为并发容器

* Queue（接口）
  * BlockingDequeue（接口）
    * LinkedBlockingDeque（实现）
  * BlockingQueue（接口）
    * ArrayBlockingQueue（实现）
    * LinkedBlockingQueue（实现）
    * SynchronousQueue（实现）
    * LinkedTransferQueue（实现）
    * PriorityBlockingQueue（实现）
    * DelayQueue（实现）
  * ConcurrentLinkedQueue（实现）
  * ConcurrentLinkedQueue（实现）
* Map（接口）
  * ConcurrentHashMap（实现）
  * ConcurrentSkipListMap（实现）
* List（接口）
  * CopyOnWriteArrayList（实现）
* Set（接口）
  * ConcurrentSkipListSet（实现）
  * CopyOnWriteArraySet（实现）

## 原子类

JUC中还提供了一些基于CAS无锁方案的数据结构

* 基本数据类型
  * AtomicInteger
  * AtomicLong
  * AtomicBoolean

* 数组
  * AtomicIntegerArray
  * AtomicLongArray
  * AtomicReferenceArray
* 累加器
  * LongAccumulator
  * LongAdder（分段思想）
  * DoubleAccumutor
  * DoubleAdder（分段思想）
* 引用类型
  * Atomic Reference
  * AtomicStampedReference
  * AtomicMarkableReference
* 对象属性更新器
  * AtomicIntegerFieldUpdater
  * AtomicLongFieldUpdater
  * AtomicReferenceFieldUpdater

## CAS

比较和交换（Compare And Swap），是用于实现多线程同步的原子指令。它将内存位置的内容与给定值进行比较，只有在相同的情况下，将该内存位置的内容修改为新的给定值。这是作为**单个原子操作**完成的。 

原子性保证新值基于最新信息计算; 如果该值在同一时间被另一个线程更新，则写入将失败。操作结果必须说明是否进行替换; 这可以通过一个简单的布尔响应（这个变体通常称为比较和设置），或通过返回从内存位置读取的值来完成。

**一个 CAS 涉及到以下操作：** 我们假设内存中的原数据V，旧的预期值A，需要修改的新值B。

> 比较 A 与 V 是否相等。（比较） 如果比较相等，将 B 写入 V。（交换） 返回操作是否成功。 当多个线程同时对某个资源进行CAS操作，只能有一个线程操作成功，但是并不会阻塞其他线程,其他线程只会收到操作失败的信号。可见 CAS 其实是一个乐观锁。

### CAS在java中的实现

对 java.util.concurrent.atomic 包下的原子类 AtomicInteger 中的 compareAndSet 方法进行分析，就能发现最终调用的是 sum.misc.Unsafe 这个类。 看名称 Unsafe 就是一个不安全的类，这个类是利用了 Java 的类和包在可见性的的规则中的一个恰到好处处的漏洞。Unsafe 这个类为了速度，在Java的安全标准上做出了一定的妥协。

* java 的 cas 利用的的是 unsafe 这个类提供的 cas 操作。
* unsafe 的cas 依赖了的是 jvm 针对不同的操作系统实现的 Atomic::cmpxchg，**保证了cas操作是的原子性**
* Atomic::cmpxchg 的实现使用了汇编的 cas 操作，并使用 cpu 硬件提供的 lock信号保证其原子性

### ABA问题

CAS 由三个步骤组成，分别是“读取->比较->写回”。 考虑这样一种情况，线程1和线程2同时执行 CAS 逻辑，两个线程的执行顺序如下：

```
时刻1：线程1执行读取操作，获取原值 A，然后线程被切换走 时刻2：线程2执行完成 CAS 操作将原值由 A 修改为 B 时刻3：线程2再次执行 CAS 操作，并将原值由 B 修改为 A 时刻4：线程1恢复运行，将比较值（compareValue）与原值（oldValue）进行比较，发现两个值相等。 然后用新值（newValue）写入内存中，完成 CAS 操作
```

如上流程，线程1并不知道原值已经被修改过了，在它看来并没什么变化，所以它会继续往下执行流程。对于 ABA 问题，通常的处理措施是对每一次 CAS 操作设置版本号。java.util.concurrent.atomic 包下提供了一个可处理 ABA 问题的原子类 AtomicStampedReference（使用了时间戳作为版本号）

## AQS

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20211006154416Hy2XLn.png)

AQS就是基于CLH队列，用volatile修饰共享变量state，线程通过CAS去改变状态符，成功则获取锁成功，失败则进入等待队列，等待被唤醒

### State

被volatile修饰，保证线程间可见性，是线程间的共享变量，各个线程通过cas修改State的状态进行锁占用和锁释放，一般情况下对state变量的修改是要通过cas的，但是当当前线程独占地持有锁时，可以直接给state变量赋值

### CLH锁队列是什么

AQS是多条件变量的管程模型，其中的入口等待队列就是用CLH锁队列实现的（AQS中的入口等待队列是CLH锁队列的一个变种，原来的CLH锁队列里面的线程是自旋等待，而AQS的CLH里面的线程是阻塞）

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20211005232204EzEZj0.jpg)

如上图所示，获取不到锁的线程，会进入队尾，然后自旋（AQS里面是阻塞），直到其前驱线程释放锁，也就是说只有当前驱节点释放了锁，后面的节点才可能获取到锁。

这样做的好处：假设有1000个线程等待获取锁，锁释放后，只会通知队列中的第一个线程去竞争锁，减少了并发冲突。（ZK的分布式锁，为了避免惊群效应，也使用了类似的方式：获取不到锁的线程只监听前一个节点）

为什么说JUC中的实现是基于CLH的“变种”，因为原始CLH队列，一般用于实现自旋锁。而JUC中的实现，获取不到锁的线程，如果是头节点的后继节点会自旋获取锁获取不到就阻塞，如果是后面的节点会直接阻塞。

### AQS中的CLH锁队列

AQS中的CLH队列中的每个节点都存储的是线程信息，其中还有当前线程的等待状态waitStatus

```java
// CANCELLED：由于超时或中断，此节点被取消。节点一旦被取消了就不会再改变状态。特别是，取消节点的线程不会再阻塞。
static final int CANCELLED =  1;
// SIGNAL:此节点后面的节点已（或即将）被阻止（通过park），因此当前节点在释放或取消时必须断开后面的节点
// 为了避免竞争，acquire方法时前面的节点必须是SIGNAL状态，然后重试原子acquire，然后在失败时阻塞。
static final int SIGNAL    = -1;
// 此节点当前在条件队列中。标记为CONDITION的节点会被移动到一个特殊的条件等待队列（此时状态将设置为0），直到条件时才会被重新移动到同步等待队列 。（此处使用此值与字段的其他用途无关，但简化了机制。）
static final int CONDITION = -2;
//传播：应将releaseShared传播到其他节点。这是在doReleaseShared中设置的（仅适用于头部节点），以确保传播继续，即使此后有其他操作介入。
static final int PROPAGATE = -3;

//0:以上数值均未按数字排列以简化使用。非负值表示节点不需要发出信号。所以，大多数代码不需要检查特定的值，只需要检查符号。
//对于正常同步节点，该字段初始化为0；对于条件节点，该字段初始化为条件。它是使用CAS修改的（或者在可能的情况下，使用无条件的volatile写入）
```

从上面的注释介绍可以明白，**只有上一个节点是SIGNAL**，当前节点才有可能被上一个节点唤醒，SIGNAL表示当前节点释放锁的时候需要唤醒下一个节点

* 如果只有一个线程进来不会初始化CHL同步得带队列
* 第二个线程来加锁失败(竞争)时，会帮头节点初始化一个节点，并将自己的节点挂再头节点后面
* **每个等待的节点会将上一个节点的状态改为SIGNAL(-1)，用来提醒上一个节点在释放锁之后必须唤醒后面的节点**
* 节点入队和唤醒的时候都会跳过ws>0 即CANCELLED(取消)的节点
* 头节点一定表示当前获取锁的线程节点

### 独占模式

* acquire：AQS获取锁的模版方法，先调用tryAcquire方法获取锁，获取不到就把线程从尾部加入到CLH队列，然后阻塞，等待当前线程获取到锁之后返回

  ```java
      public final void acquire(int arg) {
          //尝试获取锁
          if (!tryAcquire(arg) &&
              //获取不到,从队尾加入CLH，acquireQueued是一个阻塞的方法，会一直阻塞到当前线程获取到锁
              acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
              //如果返回中断，则调用当前线程的interrupt()方法
              selfInterrupt();
      }
  ```

* **tryAcquire**：AQS的默认实现是抛出异常，意味着子类一定要重写这个方法，尝试获取锁，独占式地获取同步状态，如果没有获取到（返回为false），就把线程加入到CLH队列中，ReentryLock重写tryAcquire实现了公平锁和非公平锁，以及锁的可重用功能

  * 非公平锁

    ```java
            final boolean nonfairTryAcquire(int acquires) {
                final Thread current = Thread.currentThread();
                int c = getState();
                if (c == 0) {
                  	//当stage == 0说明资源已经被释放，当前线程可以利用cas设置state，如果设置成功，则获取锁成功
                    if (compareAndSetState(0, acquires)) {
                      //CAS设置成功，把锁的独占线程设置为当前线程
                        setExclusiveOwnerThread(current);
                        return true;
                    }
                }
    	          //判断当前线程是否持有锁
                else if (current == getExclusiveOwnerThread()) {
    	              //如果持有锁，state = state + 这次获取的资源数，实现锁的可重用功能
                    int nextc = c + acquires;
                    if (nextc < 0) // overflow
                        throw new Error("Maximum lock count exceeded");
                    setState(nextc);
                    return true;
                }
                return false;
            }
    ```

  * 公平锁

    ```java
            protected final boolean tryAcquire(int acquires) {
                final Thread current = Thread.currentThread();
                int c = getState();
                if (c == 0) {
                  	//同样判断state是否为0，如果为0说明资源已经被释放，当前线程可以利用cas设置stage，如果设置成功，则获取锁成功
    	              //先判断当前线程是否是第一个等待的线程（CLH中头节点代表正在执行的线程，头节点的next节点就是第一个等待的线程），只有是第一个等待的线程才能去参与锁竞争，从这里可以看出和非公平锁的区别了，非公平锁是只要线程开始准备进入临界区就可以通过cas来进行一次锁竞争。
                    if (!hasQueuedPredecessors() &&
                        compareAndSetState(0, acquires)) {
                        setExclusiveOwnerThread(current);
                        return true;
                    }
                }
                else if (current == getExclusiveOwnerThread()) {
                    int nextc = c + acquires;
                    if (nextc < 0)
                        throw new Error("Maximum lock count exceeded");
                    setState(nextc);
                    return true;
                }
                return false;
            }
    ```

* addWaiter：AQS内部方法，通过cas的方式把节点放入到CLH队列的末尾，无论是在互斥模式还是共享模式都是使用addWaiter方法

  ```java
      private Node addWaiter(Node mode) {
          Node node = new Node(Thread.currentThread(), mode);
          // Try the fast path of enq; backup to full enq on failure
          Node pred = tail;
          if (pred != null) {
              node.prev = pred;
            	//CAS设置队尾
              if (compareAndSetTail(pred, node)) {
                  pred.next = node;
                  return node;
              }
          }
          enq(node);
          return node;
      }
  ```

  

* acquireQueued：AQS从队列中获取锁的模版方法，如果当前节点是头节点后面的节点就自旋进行锁竞争，竞争失败就阻塞，如果不是头节点就直接阻塞

  ```java
      final boolean acquireQueued(final Node node, int arg) {
          boolean failed = true;
          try {
              boolean interrupted = false;
              for (;;) {
                	//获取前驱节点
                  final Node p = node.predecessor();
  	              //如果前驱节点是头节点，就尝试获取锁（模版方法）
                  if (p == head && tryAcquire(arg)) {
                      setHead(node);
                      p.next = null; // help GC
                      failed = false;
                      return interrupted;
                  }
                	//能走到这里要么是获取锁失败，要么前驱节点不是头节点，直接阻塞
                  if (shouldParkAfterFailedAcquire(p, node) &&
                      parkAndCheckInterrupt())
                      interrupted = true;
              }
          } finally {
              if (failed)
                  cancelAcquire(node);
          }
      }
  ```

* release：AQS释放锁的模版方法，释放锁成功之后如果有后续节点就唤醒后续节点

  ```java
      public final boolean release(int arg) {
        	//尝试释放锁
          if (tryRelease(arg)) {
  	          //释放成功之后，如果后续节点不为空，唤醒后续节点
              Node h = head;
              if (h != null && h.waitStatus != 0)
                  unparkSuccessor(h);
              return true;
          }
          return false;
      }
  ```

* **tryRelease**：AQS的默认实现是抛出异常，意味着子类一定要重写这个方法，独占式地释放同步状态，ReentryLock的公平锁和非公平锁的释放锁的逻辑都是一样的

  ```java
          protected final boolean tryRelease(int releases) {
  	          //首先将state的值减少（因为可能是重用锁，所以每次释放的时候释放一部分资源）
              int c = getState() - releases;
  	          //检查当前线程是否是拥有锁的线程，如果不是抛出异常，这点和synchronized一样
              if (Thread.currentThread() != getExclusiveOwnerThread())
                  throw new IllegalMonitorStateException();
              boolean free = false;
              if (c == 0) {
                  free = true;
                  setExclusiveOwnerThread(null);
              }
            	//设置state的值，因为现在state != 0,只有当前线程可以设置state，所以直接设置 不用cas
              setState(c);
              return free;
          }
  ```

### 共享模式

* acquireShared：AQS共享地获取锁的模版方法，先执行tryAcquireShared获取共享锁，如果获取失败，则执行doAcquireShared把当前线程送入等待队列

  ```java
     public final void acquireShared(int arg) {
          //尝试获取共享锁，返回值小于0表示获取失败
          if (tryAcquireShared(arg) < 0)
              //执行获取锁失败以后的方法
              doAcquireShared(arg);
      }
  ```

* **tryAcquireShared**：AQS默认实现是抛出异常，意味着子类一定要重写这个方法，共享地获取锁，与互斥模式下的tryAcquire方法做对比，tryAcquire的返回值是boolean，ture表示获取锁成功，false表示获取锁失败，而tryAcquireShared的返回值是int类型

  * tryAcquireShared返回小于0说明获取共享锁失败
  * tryAcquireShared等于0说明获取共享锁成功，但是它的后续线程是无法继续获取共享锁的
  * tryAcquireShared大于0说明获取共享锁成功，并且获取锁之后要唤醒后续的节点让后续的节点也可以获取共享锁，注意这里有两个重要的点
    * 是在获取锁之后就唤醒后续节点，并不是释放锁的时候才唤醒，这体现了共享的特点
    * tryAcquireShared的返回值大于0就会唤醒后续节点，和具体的值没有关系，并不是返回2就会唤醒后续两个线程，事实上只要大于0，都只会固定唤醒后面的一个节点

  ```java
          protected int tryAcquireShared(int acquires) {
            	//判断state是否为0，如果是0返回1，说明要唤醒后面的节点；如果不是0，返回-1，则说明获取共享锁失败
              return (getState() == 0) ? 1 : -1;
          }
  ```

* doAcquireShared：AQS在共享模式中把线程加入到CLH队列，并且尝试获取共享锁的模版方法

  ```java
      private void doAcquireShared(int arg) {
        	//调用addWaiter加入队列加入到CLH中，注意节点的类型是SHARED
          final Node node = addWaiter(Node.SHARED);
          boolean failed = true;
          try {
              boolean interrupted = false;
              for (;;) {
                  final Node p = node.predecessor();
                  if (p == head) {
                      int r = tryAcquireShared(arg);
                    	//判断是否获取共享锁成功
                      if (r >= 0) {
                        	//和互斥模式最大的不同，就是如果获取锁成功之后，要判断是否还要继续唤醒后续节点
                        	//setHeadAndPropagate方法内部会判断tryAcquireShared方法的返回值是否>1，如果大于1就会唤醒后续节点
                          setHeadAndPropagate(node, r);
                          p.next = null; // help GC
                          if (interrupted)
                              selfInterrupt();
                          failed = false;
                          return;
                      }
                  }
  	              //后续阻塞的逻辑和互斥模式是一样的
                  if (shouldParkAfterFailedAcquire(p, node) &&
                      parkAndCheckInterrupt())
                      interrupted = true;
              }
          } finally {
              if (failed)
                  cancelAcquire(node);
          }
      }
  ```

* setHeadAndPropagate：AQS内部方法，判断tryAcquireShared方法返回值是否大于1，如果大于1就会唤醒后续节点

  ```java
      private void setHeadAndPropagate(Node node, int propagate) {
          Node h = head; // Record old head for check below
          setHead(node);
          /*
           * Try to signal next queued node if:
           *   Propagation was indicated by caller,
           *     or was recorded (as h.waitStatus either before
           *     or after setHead) by a previous operation
           *     (note: this uses sign-check of waitStatus because
           *      PROPAGATE status may transition to SIGNAL.)
           * and
           *   The next node is waiting in shared mode,
           *     or we don't know, because it appears null
           *
           * The conservatism in both of these checks may cause
           * unnecessary wake-ups, but only when there are multiple
           * racing acquires/releases, so most need signals now or soon
           * anyway.
           */
  	      //这里的propagate就是tryAcquireShared方法返回的值，只有大于1且有后续节点才会唤醒后续节点
          if (propagate > 0 || h == null || h.waitStatus < 0 ||
              (h = head) == null || h.waitStatus < 0) {
              Node s = node.next;
              if (s == null || s.isShared())
                	//唤醒后续节点
                  doReleaseShared();
          }
      }
  ```

* releaseShared：AQS释放共享锁的模版方法，先调用releaseShared释放锁，释放成功之后再唤醒后续线程

  ```java
      public final boolean releaseShared(int arg) {
        	//尝试释放共享锁
          if (tryReleaseShared(arg)) {
              doReleaseShared();
              return true;
          }
          return false;
      }
  ```

* **tryReleaseShared**：AQS默认实现是抛出异常，意味着子类一定要重写这个方法，尝试释放共享锁，和互斥模式不同的是，互斥模式下释放锁直接set state的变量值就可以，共享模式下会有多个线程并发释放共享锁，所以必须通过cas设置state的值

  ```java
          protected boolean tryReleaseShared(int releases) {
              // Decrement count; signal when transition to zero
              for (;;) {
                  int c = getState();
                  if (c == 0)
                      return false;
                  int nextc = c-1;
                	//共享模式下必须通过cas设置state的值
                  if (compareAndSetState(c, nextc))
                      return nextc == 0;
              }
          }
  ```

### Condition

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20211006142959o1BAjf.png)

AQS中的Condition就是管程模型中的条件变量，AQS是支持多条件变量的，每个条件变量都会有一个对应的条件变量等待队列

不过Condition的等待队列并不是CLH队列，只是一个单向链表，因为Condition等待队列中的线程都是阻塞的线程，并不需要参与锁竞争，只有当，Condition的等待队列中的节点被加入到CLH队列中的时候该线程才有可能会被唤醒参与锁竞争

Condition持有这个队列的头尾节点，await和signal以及signalAll就是对等待队列的操作

* await：将当前线程加入到Condition的等待队列中并阻塞
* signal：从Condition的等待队列中选择一个线程加入到CLH队列中参加到锁竞争
* signalAll：将Condition的等待队列中所有线程都加入到CLH队列中参加锁竞争

#### 源码

* await：当条件没有满足时将线程阻塞方法，会先将当前线程加入到Condition等待队列中，然后释放锁，最后阻塞该线程，当线程被唤醒的时候线程就已经在CLH中了，这个时候从CLH中获取锁

  ```java
          public final void await() throws InterruptedException {
              if (Thread.interrupted())
                  throw new InterruptedException();
  	          //当前线程加入到Condition的等待队列
              Node node = addConditionWaiter();
  	          //释放线程持有的锁
              int savedState = fullyRelease(node);
              int interruptMode = 0;
              while (!isOnSyncQueue(node)) {
                	//阻塞线程
                  LockSupport.park(this);
                  if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)
                      break;
              }
            	//这个地方线程已经从阻塞中恢复，已经是在CLH中了，调用acquireQueued从CLH队列中获取锁
              if (acquireQueued(node, savedState) && interruptMode != THROW_IE)
                  interruptMode = REINTERRUPT;
              if (node.nextWaiter != null) // clean up if cancelled
                  unlinkCancelledWaiters();
              if (interruptMode != 0)
                  reportInterruptAfterWait(interruptMode);
          }
  
  ```

* signal：从Condition的等待队列中取出一个线程加入到CLH中

  ```java
          public final void signal() {
            	//判断当前线程是否是获取锁的线程，如果不是不能执行唤醒线程的逻辑
              if (!isHeldExclusively())
                  throw new IllegalMonitorStateException();
              Node first = firstWaiter;
              if (first != null)
                	//如果当前Condition等待队列中还有线程就进行唤醒，唤醒队列中的第一个线程
                  doSignal(first);
          }
  ```

* isHeldExclusively：当实现条件变量时需要重写，判断当前线程是否独占锁

* transferForSignal：把Condition中的节点转移到CLH中的方法，基本逻辑和addWaiter一样，不过因为节点类型是CONDITION，所以要做一些节点状态转换

  ```java
      final boolean transferForSignal(Node node) {
          /*
           * If cannot change waitStatus, the node has been cancelled.
           */
          if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))
              return false;
  
          /*
           * Splice onto queue and try to set waitStatus of predecessor to
           * indicate that thread is (probably) waiting. If cancelled or
           * attempt to set waitStatus fails, wake up to resync (in which
           * case the waitStatus can be transiently and harmlessly wrong).
           */
          Node p = enq(node);
          int ws = p.waitStatus;
          if (ws > 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))
              LockSupport.unpark(node.thread);
          return true;
      }
  ```

* signalAll：逻辑和signal一样，只不过调用的doSignal换成了doSignalAll，doSignalAll内部的逻辑是while循环执行doSignalAll

  ```java
          public final void signalAll() {
              if (!isHeldExclusively())
                  throw new IllegalMonitorStateException();
              Node first = firstWaiter;
              if (first != null)
                  doSignalAll(first);
          }
  ```

### LockSupport

LockSupport类可以阻塞当前线程以及唤醒指定被阻塞的线程。主要是通过park()和unpark(thread)方法来实现阻塞和唤醒线程的操作的。

### AQS总结

AQS是一个实现了多条件变量的管程模型，AQS在内部负责对CLH队列的维护，然后提供了几个重写的方法，让用户只需要编写简单的逻辑。

* AQS实现互斥锁：需要重写tryAcquire和tryRelease方法
* AQS实现共享锁：需要重写tryAcquireShared和tryReleaseShared方法
* 实现条件变量：需要重写isHeldExclusively方法

