# 雪崩效应

复杂分布式架构的应用程序有许多依赖，其中每一个在某些时候都会不可避免的发生失败。如果这个主应用没有从那些外部失败隔离，那么就会有被拖垮的风险。

简单的来说就是由于服务提供者A不可用，导致服务调用者B对A的请求阻塞，没有相关的机制通知或解决请求阻塞，导致在服务调用者B对A请求的阻塞越来越多，阻塞请求变多并且不断对A进行请求重试导致服务调用者B所在的系统的资源会被耗尽，而服务调用者B所在的系统可能并不会只有对A的调用，还有存在对其他服务提供者的调用，因为调用A把系统资源已经耗尽了，导致也无法处理对非A请求，而且这种不可用可能沿请求调用链向上传递，比如说服务调用者C会调用B的服务，因为B所在的系统不可用，导致C也不可用，这样级联导致阻塞请求越来越多，表现为多个系统都不可用了，这种现象被称为**"雪崩效应"**。

根据上面的描述，概括一下雪崩效应的过程：服务提供者不可用->服务调用者请求重试->服务调用者所在的系统资源耗尽，服务调用者不可用。

这个过程再概括一下分为三个阶段：

1. 服务提供者不可用
2. 服务调用者重试
3. 服务调用者不可用

服务雪崩的每个阶段都可能由不同的原因造成，下面逐一说明。

**服务提供者不可用**

服务提供者不可用产生的原因可能有以下几点：

- 硬件故障
   如服务器宕机，机房断电，光纤被挖断等。
- 程序Bug
   如程序逻辑导致内存泄漏，JVM长时间FullGC等。
- 缓存击穿
   缓存击穿一般发生在缓存应用重启, 所有缓存被清空时,以及短时间内大量缓存失效时. 大量的缓存不命中, 使请求直击后端,造成服务提供者超负荷运行,引起服务不可用.
- 流量激增（系统过载）
   流量激增导致服务提供者无法承受这样的高负载，激增的原因有异常流量，重试加大流量等。

**服务调用者重试**

在服务提供者出现不可用的情况下，服务调用者重试加大了流量，服务调用者重试又可以分为两种：

- 用户重试
   在服务提供者不可用后，用户由于忍受不了界面上长时间的等待，而不断刷新页面甚至提交表单。
- 代码逻辑重试
   在代码中请求远端服务时，在出现请求异常的时候，代码逻辑都会有重试的功能，这在因为网路抖动导致请求超时的情况下是很有用的。但是如果本身服务提供者就不可用了，这种不断地重试会加大对服务器提供者的请求流量。

**服务调用者不可用**

服务调用者不可用产生的原因主要是：

- 同步等待造成的资源耗尽

当服务调用者使用同步调用时, 会产生大量的等待线程占用系统资源。一旦线程资源被耗尽，服务调用者提供的服务也将处于不可用状态。

# 雪崩效应应对策略

应对策略从造成雪崩的原因出发，提供不同的原因下的解决方案。

- 硬件故障：多机房容灾、异地多活等。
- 程序BUG：修改程序bug、及时释放资源等。
- 缓存穿透：缓存预加载、缓存异步加载等。
- 流量激增：服务自动扩容、流量控制（限流、关闭重试）等。
- 同步等待：资源隔离、MQ解耦、不可用服务调用快速失败等。资源隔离通常指不同服务调用采用不同的线程池；不可用服务调用快速失败一般通过熔断器模式结合超时机制实现。

总结一下就是几个关键词：扩容（自动）、流控（流量控制）、隔离、熔断。

# 系统容错

## 限流

限流，也称流量控制。是指系统在面临高并发，或者**大流量请求**的情况下，**限制新的请求对系统的访问**，从而**保证系统的稳定性**。

一般服务的调用链路为

```
H5/客户端` -> `Nginx` -> `Tomcat` -> `业务系统` -> `DB
```

可以简单梳理为

- 网关限流
  - Nginx 限流
  - Tomcat 限流
- 服务端限流
  - 单机限流
  - 分布式限流

### **常见的限流算法**

#### **固定窗口限流算法**

首先维护一个计数器，将单位时间段当做一个窗口，计数器记录这个窗口接收请求的次数。

- 当次数少于限流阀值，就允许访问，并且计数器+1
- 当次数大于限流阀值，就拒绝访问。
- 当前的时间窗口过去之后，计数器清零。

假设单位时间是1秒，限流阀值为3。在单位时间1秒内，每来一个请求,计数器就加1，如果计数器累加的次数超过限流阀值3，后续的请求全部拒绝。等到1s结束后，计数器清0，重新开始计数。如下图：

![固定窗口限流法](https://gitee.com/syllr/images/raw/master/uPic/HA/%E5%9B%BA%E5%AE%9A%E7%AA%97%E5%8F%A3%E9%99%90%E6%B5%81%E6%B3%95.jpg)

但是，这种算法有一个很明显的**临界问题**：假设限流阀值为5个请求，单位时间窗口是1s,如果我们在单位时间内的前0.8-1s和1-1.2s，分别并发5个请求。虽然都没有超过阀值，但是如果算0.8-1.2s,则并发数高达10，已经**超过单位时间1s不超过5阀值**的定义啦。

```java
public class CounterRateLimiter extends MyRateLimiter {
    /**
     * 每秒限制请求数
     */
    private final long permitsPerSecond;
    /**
     * 上一个窗口的开始时间
     */
    public long timestamp = System.currentTimeMillis();
    /**
     * 计数器
     */
    private int counter;

    public CounterRateLimiter(long permitsPerSecond) {
        this.permitsPerSecond = permitsPerSecond;
    }

    @Override
    public synchronized boolean tryAcquire() {
        long now = System.currentTimeMillis();
        // 窗口内请求数量小于阈值，更新计数放行，否则拒绝请求
        if (now - timestamp < 1000) {
            if (counter < permitsPerSecond) {
                counter++;
                return true;
            } else {
                return false;
            }
        }
        // 时间窗口过期，重置计数器和时间戳
        counter = 0;
        timestamp = now;
        return true;
    }
}
```



#### **滑动窗口限流算法**

滑动窗口限流解决固定窗口临界值的问题。它将单位时间周期分为n个小周期，分别记录每个小周期内接口的访问次数，并且根据时间滑动删除过期的小周期。

一张图解释滑动窗口算法，如下：

![滑动窗口限流法](https://gitee.com/syllr/images/raw/master/uPic/HA/%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3%E9%99%90%E6%B5%81%E6%B3%95.jpg)

假设单位时间还是1s，滑动窗口算法把它划分为5个小周期，也就是滑动窗口（单位时间）被划分为5个小格子。每格表示0.2s。每过0.2s，时间窗口就会往右滑动一格。然后呢，每个小周期，都有自己独立的计数器，如果请求是0.83s到达的，0.8~1.0s对应的计数器就会加1。

我们来看下滑动窗口是如何解决临界问题的？

假设我们1s内的限流阀值还是5个请求，0.8~1.0s内（比如0.9s的时候）来了5个请求，落在黄色格子里。时间过了1.0s这个点之后，又来5个请求，落在紫色格子里。如果**是固定窗口算法，是不会被限流的**，但是**滑动窗口的话，每过一个小周期，它会右移一个小格**。过了1.0s这个点后，会右移一小格，当前的单位时间段是0.2~1.2s，这个区域的请求已经超过限定的5了，已触发限流啦，实际上，紫色格子的请求都被拒绝啦。

**TIPS:** 当滑动窗口的格子周期划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。

滑动窗口算法虽然解决了**固定窗口的临界问题**，但是一旦到达限流后，请求都会直接暴力被拒绝。酱紫我们会损失一部分请求，这其实对于产品来说，并不太友好。

```java
public class SlidingWindowRateLimiter extends MyRateLimiter {
    /**
     * 每分钟限制请求数
     */
    private final long permitsPerMinute;
    /**
     * 计数器, k-为当前窗口的开始时间值秒，value为当前窗口的计数
     */
    private final TreeMap<Long, Integer> counters;

    public SlidingWindowRateLimiter(long permitsPerMinute) {
        this.permitsPerMinute = permitsPerMinute;
        this.counters = new TreeMap<>();
    }

    @Override
    public synchronized boolean tryAcquire() {
        // 获取当前时间的所在的子窗口值； 10s一个窗口
        long currentWindowTime = LocalDateTime.now().toEpochSecond(ZoneOffset.UTC) / 10 * 10;
        // 获取当前窗口的请求总量
        int currentWindowCount = getCurrentWindowCount(currentWindowTime);
        if (currentWindowCount >= permitsPerMinute) {
            return false;
        }
        // 计数器 + 1
        counters.merge(currentWindowTime, 1, Integer::sum);
        return true;
    }
    /**
     * 获取当前窗口中的所有请求数（并删除所有无效的子窗口计数器）
     *
     * @param currentWindowTime 当前子窗口时间
     * @return 当前窗口中的计数
     */
    private int getCurrentWindowCount(long currentWindowTime) {
        // 计算出窗口的开始位置时间
        long startTime = currentWindowTime - 50;
        int result = 0;

        // 遍历当前存储的计数器，删除无效的子窗口计数器，并累加当前窗口中的所有计数器之和
        Iterator<Map.Entry<Long, Integer>> iterator = counters.entrySet().iterator();
        while (iterator.hasNext()) {
            Map.Entry<Long, Integer> entry = iterator.next();
            if (entry.getKey() < startTime) {
                iterator.remove();
            } else {
                result += entry.getValue();
            }
        }
        return result;
    }
}
```



#### **漏桶算法**

漏桶算法面对限流，就更加的柔性，不存在直接的粗暴拒绝。

它的原理很简单，可以认为就是**注水漏水**的过程。往漏桶中以任意速率流入水，以固定的速率流出水。当水超过桶的容量时，会被溢出，也就是被丢弃。因为桶容量是不变的，保证了整体的速率。

![漏桶算法](https://gitee.com/syllr/images/raw/master/uPic/HA/%E6%BC%8F%E6%A1%B6%E7%AE%97%E6%B3%95.jpg)

- 流入的水滴，可以看作是访问系统的请求，这个流入速率是不确定的。
- 桶的容量一般表示系统所能处理的请求数。
- 如果桶的容量满了，就达到限流的阀值，就会丢弃水滴（拒绝请求）
- 流出的水滴，是恒定过滤的，对应服务按照固定的速率处理请求。

伪代码如下

```java
public class LeakyBucketRateLimiter extends MyRateLimiter {
    // 桶的容量
    private final int capacity;
    // 漏出速率
    private final int permitsPerSecond;
    // 剩余水量
    private long leftWater;
    // 上次注入时间
    private long timeStamp = System.currentTimeMillis();

    public LeakyBucketRateLimiter(int permitsPerSecond, int capacity) {
        this.capacity = capacity;
        this.permitsPerSecond = permitsPerSecond;
    }

    @Override
    public synchronized boolean tryAcquire() {
        //1. 计算剩余水量
        long now = System.currentTimeMillis();
        long timeGap = (now - timeStamp) / 1000;
        leftWater = Math.max(0, leftWater - timeGap * permitsPerSecond);
        timeStamp = now;
        
        // 如果未满，则放行；否则限流
        if (leftWater < capacity) {
            leftWater += 1;
            return true;
        }
        return false;
    }
}
```

这并不是一个完整的漏桶算法的实现，以上代码中只是对流量是否会被抛弃进行校验，即tryAcquire返回true表示漏桶未满，否则表示漏桶已满丢弃请求。

想要以恒定的速率漏出流量，通常还应配合一个FIFO队列来实现，当tryAcquire返回true时，将请求入队，然后再以固定频率从队列中取出请求进行处理。示例代码如下：

```java
@Test
public void testLeakyBucketRateLimiter() throws InterruptedException {
    ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();
    ExecutorService singleThread = Executors.newSingleThreadExecutor();

    LeakyBucketRateLimiter rateLimiter = new LeakyBucketRateLimiter(20, 20);
    // 存储流量的队列
    Queue<Integer> queue = new LinkedList<>();
    // 模拟请求  不确定速率注水
    singleThread.execute(() -> {
        int count = 0;
        while (true) {
            count++;
            boolean flag = rateLimiter.tryAcquire();
            if (flag) {
                //如果漏桶没有满，就往队列里面添加请求
                queue.offer(count);
                System.out.println(count + "--------流量被放行--------");
            } else {
                System.out.println(count + "流量被限制");
            }
            try {
                Thread.sleep((long) (Math.random() * 1000));
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    });
  
    // 模拟处理请求 固定速率漏水
    scheduledExecutorService.scheduleAtFixedRate(() -> {
        if (!queue.isEmpty()) {
            System.out.println(queue.poll() + "被处理");
        }
    }, 0, 100, TimeUnit.MILLISECONDS);

    // 保证主线程不会退出
    while (true) {
        Thread.sleep(10000);
    }
}
```

漏桶算法存在目的主要是用来**平滑突发的流量**，提供一种机制来确保网络中的突发流量被整合成平滑稳定的流量。

不过由于漏桶对流量的控制过于严格，在有些场景下**不能充分使用系统资源**，因为漏桶的漏出速率是固定的，即使在某一时刻下游能够处理更大的流量，漏桶也不允许突发流量通过。

#### 令牌桶

如何在够限制流量速率的前提下，又能够允许突发流量呢？令牌桶算法了解一下！令牌桶算法是以恒定速率向令牌桶发送令牌，请求到达时，尝试从令牌桶中拿令牌，只有拿到令牌才能够放行，否则将会被拒绝。

![令牌桶算法](https://gitee.com/syllr/images/raw/master/uPic/HA/%E4%BB%A4%E7%89%8C%E6%A1%B6%E7%AE%97%E6%B3%95.jpg)

令牌桶具有以下特点：

1. 以恒定的速率发放令牌，假设限流速率为v/s，则表示每1/v秒发放一个令牌
2. 假设令牌桶容量是b，如果令牌桶已满，则新的令牌会被丢弃
3. 请求能够通过限流器的前提是令牌桶中有令牌

令牌桶算法中值得关注的参数有两个，即限流速率v/s，和令牌桶容量b；速率a表示限流器一般情况下的限流速率，而b则是burst的简写，表示限流器允许的最大突发流量。

比如b=10，当令牌桶满的时候有10个可用令牌，此时允许10个请求同时通过限流器（**允许流量一定程度的突发**），这10个请求瞬间消耗完令牌后，后续的流量只能按照速率r通过限流器。

需要主意的是，非常容易被想到的实现是生产者消费者模式；用一个生产者线程定时向阻塞队列中添加令牌，而试图通过限流器的线程则作为消费者线程，只有从阻塞队列中获取到令牌，才允许通过限流器。

由于**线程调度的不确定性**，在高并发场景时，定时器误差非常大，同时定时器本身会创建调度线程，也会对**系统的性能**产生影响。

```java
public class TokenBucketRateLimiter extends MyRateLimiter {
    /**
     * 令牌桶的容量「限流器允许的最大突发流量」
     */
    private final long capacity;
    /**
     * 令牌发放速率
     */
    private final long generatedPerSeconds;
    /**
     * 最后一个令牌发放的时间
     */
    long lastTokenTime = System.currentTimeMillis();
    /**
     * 当前令牌数量
     */
    private long currentTokens;

    public TokenBucketRateLimiter(long generatedPerSeconds, int capacity) {
        this.generatedPerSeconds = generatedPerSeconds;
        this.capacity = capacity;
    }

    /**
     * 尝试获取令牌
     *
     * @return true表示获取到令牌，放行；否则为限流
     */
    @Override
    public synchronized boolean tryAcquire() {
          /**
           * 计算令牌当前数量
           * 请求时间在最后令牌是产生时间相差大于等于额1s（为啥时1s？因为生成令牌的最小时间单位时s），则
           * 1. 重新计算令牌桶中的令牌数
           * 2. 将最后一个令牌发放时间重置为当前时间
           */
        long now = System.currentTimeMillis();
        if (now - lastTokenTime >= 1000) {
          	//通过计算时间差*每秒生成的令牌数来计算新的令牌数
            long newPermits = (now - lastTokenTime) / 1000 * generatedPerSeconds;
            currentTokens = Math.min(currentTokens + newPermits, capacity);
            lastTokenTime = now;
        }
        if (currentTokens > 0) {
            currentTokens--;
            return true;
        }
        return false;
    }
}

```

#### 单机限流

在单机的情况一下一般使用guava的RateLimiter进行限流

RateLimiter使用的是令牌桶算法，RateLimiter会按照一定的频率往桶里扔令牌，线程拿到令牌才能执行，比如你希望自己的应用程序QPS不要超过1000，那么RateLimiter设置1000的速率后，就会每秒往桶里扔1000个令牌。

#### 分布式限流

以上几种限流算法的实现都仅适合单机限流。虽然给每台机器平均分配限流配额可以达到限流的目的，但是由于机器性能，流量分布不均以及计算数量动态变化等问题，单机限流在分布式场景中的效果总是差强人意。

分布式限流最简单的实现就是利用中心化存储，即将单机限流存储在本地的数据存储到同一个存储空间中，如常见的Redis等。

比较出名的分布式限流中间件有Alibaba Sentinel，采用滑动窗口来实现实时数据的统计。

## 熔断

服务熔断也称服务隔离或过载保护。在微服务应用中，服务存在一定的依赖关系，形成一定的依赖链，如果某个目标服务调用慢或者有大量超时，造成服务不可用，间接导致其他的依赖服务不可用，最严重的可能会阻塞整条依赖链，最终导致业务系统崩溃(又称雪崩效应)。此时，对该服务的调用执行熔断，对于后续请求，不再继续调用该目标服务，而是直接返回，从而可以快速释放资源。等到目标服务情况好转后，则可恢复其调用，熔断是调用方进行系统容错的一种机制。

### 定义一个识别是否处于“不正常”状态的策略

识别一个系统是否正常，无非是两个点。

- 是不是能调通
- 如果能调通，耗时是不是超过预期的长

但是，由于分布式系统被建立在一个并不是100%可靠的网络上，所以上述的情况总有发生，因此我们不能将偶发的瞬时异常等同于系统“不可用”（避免以偏概全）。由此我们需要引入一个「**时间窗口**」的概念，这个时间窗口用来“放宽”判定“不可用”的区间，也意味着多给了系统几次证明自己“可用”机会。但是，如果系统还是在这个时间窗口内达到了你定义“不可用”标准，那么我们就要“断臂求生”了。

 这个标准可以有两种方式来指定。

- 阈值。比如，在10秒内出现100次“无法连接”或者出现100次大于5秒的请求。
- 百分比。比如，在10秒内有30%请求“无法连接”或者30%的请求大于5秒。

### **切断联系**（fastFail机制）

* failover：失效转移
  Fail-Over的含义为“失效转移”，是一种备份操作模式，当主要组件异常时，其功能转移到备份组件。其要点在于有主有备，且主故障时备可启用，并设置为主。如Mysql的双Master模式，当正在使用的Master出现故障时，可以拿备Master做主使用

* failfast：快速失败
  从字面含义看就是“快速失败”，尽可能的发现系统中的错误，使系统能够按照事先设定好的错误的流程执行，对应的方式是“fault-tolerant（错误容忍）”。以JAVA集合（Collection）的快速失败为例，当多个线程对同一个集合的内容进行操作时，就可能会产生fail-fast事件。例如：当某一个线程A通过iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程A访问集合时，就会抛出ConcurrentModificationException异常（发现错误执行设定好的错误的流程），产生fail-fast事件。

* failback：失效自动恢复
  Fail-over之后的自动恢复，在簇网络系统（有两台或多台服务器互联的网络）中，由于要某台服务器进行维修，需要网络资源和服务暂时重定向到备用系统。在此之后将网络资源和服务器恢复为由原始主机提供的过程，称为自动恢复

切断联系要尽可能的“果断”，既然已经认定了对方“不可用”，那么索性就默认“失败”，避免做无用功，也顺带能缓解对方的压力。分布式系统中的程序间调用，一般都会通过一些RPC框架进行。

![RPC调用流程图](https://gitee.com/syllr/images/raw/master/uPic/HA/RPC%E8%B0%83%E7%94%A8%E6%B5%81%E7%A8%8B%E5%9B%BE.png)

那么，这个时候作为客户端一方，**在自己进程内通过代理发起调用之前就可以直接返回失败，不走网络**。

![RPC调用fastFail流程图](https://gitee.com/syllr/images/raw/master/uPic/HA/RPC%E8%B0%83%E7%94%A8fastFail%E6%B5%81%E7%A8%8B%E5%9B%BE.png)

这就是常说的「**fail fast**」机制，代码如下

```java
if(isOpenCircuitBreaker == true){
    return fail;
}

//do some thing...
```

### **重新恢复正常**

一旦通过了衡量是否“可用”的验证，整个系统就恢复到了“正常”状态，此时需要重新开启识别“不可用”的策略。就这样，系统会形成一个循环。

![熔断恢复正常](https://gitee.com/syllr/images/raw/master/uPic/HA/%E7%86%94%E6%96%AD%E6%81%A2%E5%A4%8D%E6%AD%A3%E5%B8%B8.png)

![熔断流程图](https://gitee.com/syllr/images/raw/master/uPic/HA/%E7%86%94%E6%96%AD%E6%B5%81%E7%A8%8B%E5%9B%BE.png)

### 哪些场景适合做熔断

- 所依赖的服务容易被别的服务影响（比如所依赖的服务和一个mysql实例共同部署在一台容器里面，如果mysql资源紧张会使被依赖的服务响应变慢）。
- 所依赖的系统是一个经常会迭代更新的服务。这点也意味着，越“敏捷”的系统越需要“熔断”。
- 当前所在的系统流量大小是不确定的。比如，一个电商网站的流量波动会很大，你能抗住突增的流量不代表所依赖的后端系统也能抗住。这点也反映出了我们在软件设计中带着“面向怀疑”的心态的重要性。

**熔断往往应作为最后的选择，我们应优先使用一些「降级」或者「限流」方案**。因为“部分胜于无”，虽然无法提供完整的服务，但尽可能的降低影响是要持续去努力的。

## 降级

### 降级策略分类

降级按照是否可以自动化分为：自动开关降级和人工开关降级。按照读写功能可以分为：读服务降级和写服务降级。当从用户访问的整条链路来看，将会有以下多级降级策略：

* 页面降级：当在大促时，某些页面占用了稀缺资源，可以对整个页面进行降级；当页面上会异步加载推荐信息等一些非核心的业务时，此时如果响应变慢，则可以进行降级处理。

* 服务读降级：一般情况下，分布式应用当中都会有缓存，查询频率比较高的数据，一般都会从缓存中获取。但是有一些数据，如果直接从缓存中获取的话，有可能造成客户的投诉。比如用户账户余额，这个一般只从DB里面获取，而且是主库里面去读取。当大促来临时，此时可以降级为从库里面或者缓存里面去获取余额信息。

* 服务写降级：在秒杀抢购业务中，由于并发的数量比较大。除了在各个层面上限流、使用队列等方式应对，还可以对写库进行降级，可以将库存扣减操作在内存中进行，当高峰过去之后，再异步的同步至DB中做扣减操作。
  其他类型：如在系统繁忙时，可以将爬虫的流量直接丢弃。当高峰过后，再自动恢复。秒杀业务中，风控系统可以识别刷子/机器人，然后可以直接对这些用户执行拒绝服务。

降级行为，为了保证服务的可用性，我们必须舍取一些东西比如：

- 数据的一致性，无需绝对的一致性，而保障最终一致即可；
- 系统功能的降级，例如把一些不重要的功能，或是非关键路径的功能暂时关闭；
- 用户体验降级，分多种方案给用户不同的体验；

总结下来如果用户对数据不敏感即可以舍弃一部分数据一致性，或者如果用户对某些功能不敏感就可以把某些功能设置为异步执行或者延迟执行，批量执行，再其次甚至可以砍掉某些对用户体验不重要的功能。

### 降级一致性

#### 缓存的使用

在数据库之上，添加一层缓存是降低一致性的一种做法。

缓存的访问速度、包括可承载的访问qps都要远远高于数据库。用户请求到达时优先访问缓存，如果缓存命中，则直接返回缓存中的数据。如果缓存为空，则查询数据库，并且进行缓存的更新。使用缓存要注意的问题是：

- 缓存的更新机制，是失效过期被动更新，还是主动refresh，策略如何选择；
- 缓存过期时间。缓存最长可以保存多长的时间？
- 热点问题，例如“商品库存”这个值，在每次查询商品列表的时候都会进行查询，很容易就会成为热点key。热点key会造成redis集群的流量倾斜。解决热点key，可以将缓存key进行hash打散。或是在缓存之上再构建一层本地内存cache，例如使用Guava cache来做本地缓存。
- 缓存击穿问题，当数据在数据库中不存在时，如何避免用户的请求每次都穿过缓存打到数据库上。
- 添加缓存开关，当缓存的数据有问题时，有没有手段快速让缓存失效 或是 临时关闭缓存。

除了在数据库之上添加缓存之外，对下游的接口也可以添加缓存。

例如某个接口提供了查询数据的功能，这些数据并不会经常改变；或是业务上对数据变动的敏感度并不高，那么这时候可以牺牲一点数据变动同步的要求，在对下游接口调用上增加一层缓存。

### 流程异步化

通过将流程异步化，将结果延迟给用户，也能够让系统扛住更大的请求。

举个例子，在打款这样的环节中，如果所有的步骤都是同步的，那么整个流程会非常长，并且通常来说，打款接口对qps都有限制， 例如限制一个平台每秒只能有200的转账打款的qps。如果整个转账业务逻辑都是同步的，很有可能因为这些下游接口的限制（尤其是支付环节）导致流程中止，无法继续往下走。

因此，当类似的场景有高qps出现时，就可以将流程中的同步逻辑用异步来实现。例如告知用户正在打款中，到账信息请等待通知等。用户的请求可以使用消息队列先缓存起来，再根据系统的消费能力慢慢消化掉。

### 行为聚集化

同样是利用异步的思想，在某些特殊的场景下可以将用户的请求聚合起来进行更新。

这个思想在很多中间件中都有，例如kafka中为了减少网络带来的系统开销，可以通过batch.size这个参数来设置批量提交的数据大小，当积压的消息达到这个值的时候就会统一发送。

也可以将这种思维使用在业务上。例如像一款在线种菜的游戏，用户有多块土地可以种植作物，作物统一收成为积分。一般用户在收获的时候会点击多块土地同时进行收获，用户积分账户属于重要数据，可以每次收获时都进行累计。但是其他关注用户累计积分的非关键分支，则可以进行聚合后再统一累计。例如下游有一个任务服务，专门负责收集用户的收集积分行为，让用户达成某个成就完成任务，这个服务也关心用户积分的累计行为。这种情况下，可以不必用户的每次行为都去调用任务服务，而是上游做聚集后统一发送。

具体做法 可以使用类似kafka延时队列的组件，在用户第一次收集积分时，上游服务便发送一个延时2秒的消息出去。上游服务本身会消费这个延时消息，消费后将延时期间的累计值再传给下游的任务服务。虽然用户的成就累计会延迟2秒，但这种聚集行为的做法，会大大降低下游服务的压力。

### 体验降级

#### 简化流程

功能降级在不得已的一些情况下也可以使用，例如某个流程有非常多的校验逻辑，举个例子，还是使用上面QQ农场的例子。QQ农场用户是可以互相偷菜的，偷菜的时候是否要去校验偷取与被偷取用户之间是否是好友关系。当好友关系校验服务成为一个瓶颈时，能否将好友关系校验去掉？而为了避免这样做带来的风险，可以同时启用一个限制，就是限制在降级的期间，每个用户仅能偷取其他用户1次，避免有黑产用户不断偷取其他用户的菜。

#### 分级体验

当流量过大时，甚至可以只保留种、偷、收的基本功能，其他的模块暂时屏蔽掉入口，例如成就系统、任务系统等暂时下线。又如电商系统，在拉取商品列表的时候，将商品推荐模块移除掉，商品推荐属于锦上添花的东西，去掉了也不影响用户的正常使用。又如在拉取评论列表时，可以只拉取用户的首次评论，追评信息不再拉取，等等。

在类似相册这种场景下，可以将体验细分为正常访问图片、不预拉取图片、用中图代替大图、用默认图代替大图、只允许访问小图或封面、不允许访问相册等多个层级，根据不同的资源状况和场景为不同的用户提供差异化服务。依据不同的服务压力切换到不同的用户体验级别上。

#### 降级服务要点

首先要明确的是降级达到的目的是什么，有些降级是降低对下游的压力，有些降级是降低读压力，有些则是降低写压力。例如上文提到的加缓存是降低读压力，行为聚集、异步是降低写压力。不同的降级方案所针对的场景应该要明确。

第二是进行业务上的梳理，哪些是必须有的基本功能，例如农场的种菜；哪些是锦上添花的功能，例如商品详情页的“好物推荐”；哪些是可以牺牲的体验，例如相册的多个体验分级，这些简化达到的目的都需要梳理出来。

降级的时间段，有些系统存在流量尖刺的情况，例如商品兑换系统，0点可能是更新库存的时候，用户来兑换商品的请求会形成一个流量高峰。又例如QQ相册，可能在晚上20:00 - 21:00是用户浏览的一个高峰时间段。在不同的时间段，可以选择不同的降级方案。

降级也要注意和前端的配合，例如商品抢购列表 高峰时间段降级，不展示具体的剩余数量，只展示“商品抢购中”的文案，需要前端配合一起做降级。

降级可以做到自动化、半自动化、或完全的手动。应该预留手动调整的能力，避免系统会误判，紧急情况下可以人工介入操作。因为降级的功能不总是会真正进行，所以方案都要事先预演好。

## 隔离

在一个高度服务化的系统中,我们实现的一个业务逻辑通常会依赖多个服务,比如: 商品详情展示服务会依赖商品服务, 价格服务, 商品评论服务。 如图所示:

![系统中服务隔离1](https://gitee.com/syllr/images/raw/master/uPic/HA/%E7%B3%BB%E7%BB%9F%E4%B8%AD%E6%9C%8D%E5%8A%A1%E9%9A%94%E7%A6%BB1.jpeg)

调用三个依赖服务会共享商品详情服务的线程池。如果其中的商品评论服务不可用, 就会出现线程池里所有线程都因等待响应而被阻塞, 从而造成服务雪崩，如图所示:

![未进行隔离造成的系统雪崩](https://gitee.com/syllr/images/raw/master/uPic/HA/%E6%9C%AA%E8%BF%9B%E8%A1%8C%E9%9A%94%E7%A6%BB%E9%80%A0%E6%88%90%E7%9A%84%E7%B3%BB%E7%BB%9F%E9%9B%AA%E5%B4%A9.jpeg)

通过将每个依赖服务分配独立的线程池进行资源隔离, 从而避免服务雪崩。

如下图所示, 当商品评论服务不可用时, 即使商品服务独立分配的20个线程全部处于同步等待状态,也不会影响其他依赖服务的调用。

![隔离之后服务不可用不会造成雪崩效应](https://gitee.com/syllr/images/raw/master/uPic/HA/%E9%9A%94%E7%A6%BB%E4%B9%8B%E5%90%8E%E6%9C%8D%E5%8A%A1%E4%B8%8D%E5%8F%AF%E7%94%A8%E4%B8%8D%E4%BC%9A%E9%80%A0%E6%88%90%E9%9B%AA%E5%B4%A9%E6%95%88%E5%BA%94.jpeg)

**隔离设计：**

隔离的方式一般使用两种：

（1）线程池隔离模式：使用一个线程池来存储当前的请求，线程池对请求作处理，设置任务返回处理超时时间，堆积的请求堆积入线程池队列。这种方式需要为每个依赖的服务申请线程池，有一定的资源消耗，好处是可以应对突发流量（流量洪峰来临时，处理不完可将数据存储到线程池队里慢慢处理）

（2）信号量隔离模式：使用一个原子计数器（或信号量）来记录当前有多少个线程在运行，请求来先判断计数器的数值，若超过设置的最大线程个数则丢弃改类型的新请求，若不超过则执行计数操作请求来计数器+1，请求返回计数器-1。这种方式是严格的控制线程且立即返回模式，无法应对突发流量（流量洪峰来临时，处理的线程超过数量，其他的请求会直接返回，不继续去请求依赖的服务）

在服务接口设计时应该遵循建立单一接口，不要建立臃肿庞大的接口的原则，即：

- 客户端不应该依赖它不需要的接口
- 类间的依赖关系应该建立在最小的接口上

## 削峰填谷

通过削去流量尖刺，让请求流量趋向平稳，以保障服务的稳定性。

- 客户端削峰
- 服务端削峰

![削峰填谷时间图](https://gitee.com/syllr/images/raw/master/uPic/HA/%E5%89%8A%E5%B3%B0%E5%A1%AB%E8%B0%B7%E6%97%B6%E9%97%B4%E5%9B%BE.png)

- 削峰： 为保证服务可用，剔除部分流量。 –业务有损
- 填谷： 在服务能力盈余的情况下，提供补偿操作。 –业务补偿

#### 削峰

通过削去流量尖刺，让请求流量趋向平稳，以保障服务的稳定性。

- 客户端削峰
- 服务端削峰

##### 限流削峰（业务有损）

- 网关限流
- 容器限流
- 服务器限流

在服务器限流中， 主要介绍了，使用`Sentinel` 来做流量控制，通过下面的流量图可以看到，流量控制在了 `2 qps` ，峰值流量通过`快速失败`的方式返回。 那么，对于这部分被拒绝的流量，我们从业务角度来看的话，是有损的。

##### MQ削峰

在`消息队列`的架构中，有 `pull` 和 `push` 两种消息同步的方式，我们可以通过下游系统 `订单系统` 主动拉取`pull` 的方式，来保障下游服务的流量稳定。

mq削峰引入了mq中间件因此可能会有以下问题：

- `中间件可用性`：MQ队列不可用，会导致整个链路不可用，严重会造成雪崩
- `消息可靠性`：消息发送，消费需要得到保障
- `消息堆积`：消息生产过快，导致MQ中间件压力过大
- `消息重复`：消费幂等能力支撑
- `消息顺序`：部分场景要求消费按照顺序执行

#### 填谷

从上面的`削峰策略`可以看到，大部分的`削峰` 都是业务有损的，从`客户端发起请求限流` ,到服务端的`中间件限流`。对于这部分的请求，都是直接丢弃的。而在 `MQ削峰` 的场景下，我们可以通过将`请求缓存` 的方式，减缓流量压力，有下游服务来控制请求压力，从而达到`削峰`的效果。

脱离了削峰，就不存在填谷了

在 `MQ削峰` 的场景中，我们主要保障的是 `订单系统` 的流量稳定性, 如果 秒杀系统的消息流量为 `100tps`，订单系统的处理能力为 `200tps`，那么，对于下游系统来说，就不存在峰值流量了！

##### 填谷补偿

在`峰值`流量阶段，出现部分流量无法得到马上的处理，通过峰值流量过去后，在`消费能力盈余`的情况下，对之前的请求做补偿操作，使整体流量趋向于平稳。