# 架构

![Mysql逻辑架构图](https://raw.githubusercontent.com/syllr/image/main/uPic/20210926220615NbOzHy.png)

大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。

* Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。

* 而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。

从图中不难看出，不同的存储引擎共用一个 Server 层，也就是从连接器到执行器的部分。

## Server层

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210926222015hPerY2.jpg)

### 缓存

因为mysql的缓存的维度是以表 作为基本单位的，如果一张表里面的任意一行数据有变更，整个表的缓存都会被清空，如果出现频繁的数据变更操作，就会影响性能，所以mysql在8.0之后删除了这个缓存模块。

### 连接器

第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接

数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。

### 分析器

对 SQL 语句做解析。

分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。

MySQL 从你输入的"select"这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。

做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。

### 优化器

经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。

优化器主要进行两种优化：

* 在存在多个索引的时候判断使用哪一个索引
* 在多表连接的时候判断表的连接顺序

最后生成执行计划

> 一条语句在执行之前需要生成所谓的执行计划，也就是该语句将采用什么方式来执行（使用什么索引，采用什么连接顺序等等），我们可以通过Explain语句来查看这个执行计划。

### 执行器

1、调用存储引擎的API操作数据。

2、优化器完成sql优化后，向执行器提供执行计划，执行器开始执行执行计划来操作数据。

打开表时，执行器会根据表的引擎定义使用该引擎提供的接口。

当你开始执行的时候，首先要判断你是否有权执行这个表T的查询。如果没有，你会回到没有权限的错误。

```sql
mysql> select * from T where ID=10;
```

当ID这个字段没有索引的时候

1. 调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；
2. 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
3. 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。

没有索引，查询就是全表扫描。 而且执行全表扫描这个动作是由执行器来做的，因为引擎层读取数据都是按照B+树的叶子结点一页一页读取的，相当于把批量的数据都放在引擎层的内存中，然后执行器一行一行来取。

对于有索引的表，执行的逻辑也差不多，

* 引擎层通过索引把所有**满足索引条件**的数据查出来，全部返回给server层

* 因为满足索引条件的数据并不一定是最终的结果数据，所以server 层对于返回的数据，使用后面的where条件进行过滤

  > ```java
  > select * from table where name = "yutao" and age > 10;//只有age有索引，name没有索引
  > ```
  >
  > 假设age是索引，name不是索引，对于上面这个查询语句引擎层会通过索引把所有age>10的数据都返回给server层，server层拿到数据之后会再使用name = 'yutao'对所拿到的数据进行过滤。

## 引擎层

#### MyISAM

* 不支持事务（最新版本好像支持了）

* 不支持外键

* 不支持行锁，只支持表锁

* 文件物理结构：索引文件和表数据文件是分开的两个文件

  * .frm文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等。

  * .myd文件：myisam存储引擎专用，用于存储myisam表的数据

  * .myi文件：myisam存储引擎专用，用于存储myisam表的索引相关信息

    > 因为索引和表数据不在同一个文件，所以不管主键还是普通索引都指向磁盘上数据行的位置，其实myisam就没有主键索引和二级索引的区别了相当于都是二级索引，无论哪个索引都需要回表查询数据

#### InnoDB

* 支持事务

* 支持外键

* 支持行锁

* 文件物理结构：表数据和索引存放在同一个文件中

  * .frm与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等。 

  * .ibd文件和.ibdata文件存放表数据和索引数据，这两种文件都是存放innodb数据的文件，之所以用两种文件来存放innodb的数据，是因为innodb的数据存储方式能够通过配置来决定是使用共享表空间存放存储数据，还是用独享表空间存放存储数据

    > 因为索引和表数据都在同一个文件，所以主键索引可以直接和数据放在一起不用回表，二级索引要先找到主键再回表

#### MEMORY

基于内存，速度很快，但不能持久化

## 索引下推 Index Condition Pushdown(ICP)

### 为什么会有索引下推？

MySQL 联合索引仅支持按「最左匹配」原则使用索引。在遇到范围查询情况时，会停止利用后面的索引字段。

> 说明索引下推是针对联合索引的

#### 联合索引存储原理

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927002148yETYby.png)

> 联合索引 bcd , 在索引树中的样子如图 ， 在比较的过程中 ，先判断 b 再判断 c 然后是 d 

表T1有字段a,b,c,d,e，其中a是主键，除e为varchar其余为int类型，并创建了一个联合索引idx_t1_bcd(b,c,d)，然后b、c、d三列作为联合索引，在B+树上的结构正如上图所示。

联合索引的所有索引列都出现在索引数上，并依次比较三列的大小。上图树高只有两层不容易理解，下面是假设的表数据以及我对其联合索引在B+树上的结构图的改进。PS：基于InnoDB存储引擎。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927002244Fi314L.png)

T1表如下图

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927002312uSg0hu.png)



我们先看T1表，他的主键暂且我们将它设为整型自增的，InnoDB会使用主键索引在B+树维护索引和数据文件，然后我们创建了一个联合索引（b，c，d）也会生成一个索引树，同样是B+树的结构，只不过它的data部分存储的是联合索引所在行的主键值（上图叶子节点紫色背景部分）

对于联合索引来说只不过比单值索引多了几列，而这些索引列全都出现在索引树上。

对于联合索引，存储引擎会首先根据第一个索引列排序，如上图我们可以单看第一个索引列，如，1 1 5 12 13....他是单调递增的；

如果第一列相等则再根据第二列排序，依次类推就构成了上图的索引树，上图中的1 1 4 ，1 1 5以及13 12 4,13 16 1,13 16 5就可以说明这种情况。

#### 联合索引的查找方式

* 等值查询：当我们的SQL语言可以应用到索引的时候，比如 `select * from T1 where b = 12 and c = 14 and d = 3;` 也就是T1表中a列为4的这条记录

  * 存储引擎首先从根节点（一般常驻内存）开始查找，第一个索引的第一个索引列为1,12大于1，第二个索引的第一个索引列为56,12小于56，于是从这俩索引的中间读到下一个节点的磁盘文件地址，从磁盘上Load这个节点，通常伴随一次磁盘IO，然后在内存里去查找。
  * 当Load叶子节点的第二个节点时又是一次磁盘IO，比较第一个元素，b=12,c=14,d=3完全符合，于是找到该索引下的data元素即ID值，再从主键索引树上找到最终数据。

  ![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927002704KRkx0v.png)

  从上面可以看出，对于联合索引的等值查询可以完全利用到联合索引存储的每一个值

* 范围查询：当`select * from T1 where b > 12 and c > 14 and a > 3`时，mysql只会根据b > 12查找到数据

  之所以会有**最左前缀匹配原则**和联合索引的**索引构建方式及存储结构**是有关系的。首先我们创建的idx_t1_bcd(b,c,d)索引，**相当于创建了(b)、（b、c）（b、c、d）三个索引**，而在范围查询b>12的时候其实只用到了（b）这一个索引

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927003323VT8wY4.png)

索引的第一列也就是b列可以说是从左到右单调递增的，但我们看c列和d列并没有这个特性，它们只能在b列值相等的情况下这个小范围内递增，如第一叶子节点的第1、2个元素和第二个叶子节点的后三个元素。

由于联合索引是上述那样的**索引构建方式及存储结构**，所以联合索引只能从多列索引的第一列开始查找。所以如果你的查找条件不包含b列如（c,d）、(c）、(d)是无法应用缓存的，以及跨列也是无法完全用到索引如(b,d)，只会用到b列索引。

> 这就像我们的电话本一样，有名和姓以及电话，名和姓就是联合索引。在姓可以以姓的首字母排序，姓的首字母相同的情况下，再以名的首字母排序。

如：

**M**  

　　**毛 不易  178\**\**\**\****  

　　**马 化腾  183\**\**\**\****  

　　**马 云    188\**\**\**\****

**Z**  

　　**张 杰   189\**\**\**\****  

　　**张 靓颖  138\**\**\**\****  

　　**张 艺兴  176\**\**\**\**** 

我们知道名和姓是很快就能够从姓的首字母索引定位到姓，然后定位到名，进而找到电话号码，因为所有的姓从上到下按照既定的规则（首字母排序）是有序的，而名是在姓的首字母一定的条件下也是按照名的首字母排序的，但是整体来看，所有的名放在一起是无序的，所以如果只知道名查找起来就比较慢，因为无法用已排好的结构快速查找。

#### 联合索引的优化

**当我们创建联合索引时应该把离散度比较大的字段放在前面，离散度比较小的放在后面**

举个例子：当对一个班级里面的分数和年龄做联合索引时，应该把分数放在前面，年龄放在后面，应该一个班级的同学的分数离散程度很高，但是年龄的离散程度不高，所以索引应该是(score, age)

当我们的执行`select * from table where score =80 and age = 20，`或者是范围搜索时，可以减少扫描的行数。

### 索引下推的作用

Index Condition Pushdown(ICP)是MySQL 5.6中新特性，是一种在存储引擎层使用索引过滤数据的一种 优化方式。ICP可以减少存储引擎访问基表的次数以及MySQL服务器访问存储引擎的次数。

不使用索引下推的过程

* 引擎层
  1. 当使用联合索引(b, c, d)范围查找时`select * from T1 where b > 12 and c >10 and d >5;`，只通过索引查找b > 12的数据
  2. 找到第一条b > 12的数据之后（拿到了索引记录的b,c,d字段还有主键ID），进行回表（**回表是在引擎层回的**），拿回这一条记录的所有字段数据
  3. 把这个字段的所有数据返回给server层
  4. 重复步骤2，3直到把所有b > 12的数据找完

* server 层：对返回的数据，使用后面的where条件过滤。

使用索引下推的过程

* 引擎层：
  1. 当使用联合索引(b, c, d)范围查找时`select * from T1 where b > 12 and c >10 and d >5;`，只通过索引查找b > 12的数据
  2. 找到第一条b > 12的数据之后（拿到了索引记录的b,c,d字段还有主键ID），通过索引中的c，d字段判断`c > 10 and d >5`，满足则回表，不满足直接丢弃数据，也不会返回server层
  3. 第二步满足要求，就回表，然后把拿到的数据返回给server
  4. 重复步骤2，3直到把所有b > 12的数据找完

* server 层：对返回的数据，使用where条件做最后的过滤。

可以看出索引下推对于联合索引的优化在于，利用了联合索引中c，d的值，进行了数据的过滤（内存中过滤，速度很快），优点有

* 减少回表
* 减少server层和引擎层之间的交互

# 日志

## WAL

WAL(Write Ahead Log)预写日志，是数据库系统中常见的一种手段，用于保证数据操作的原子性和持久性。

原理：**磁盘顺序读写**效率远高于随机读写。

- 通过cache合并多条写操作为一条，减少IO次数
- 日志顺序追加性能远高于数据随机写.
- 随机内存处理性能远高于数据随机处理.

WAL日志写入过程

```
1.在user buffer的日志中写入”Begin Tran”记录
2.在user buffer的日志页写入要修改的信息
3.在user buffer将要修改的数据写入page cache
4.在user buffer的日志中写入”Commit”记录,将user buffer的日志写入platter
5.发送确认信息到客户端(SMSS,ODBC等）
6.将data page cache写入到磁盘(1.2.3)
```

使用 WAL 的数据库系统不会再每执行一条 WAL 操作就将数据刷入数据库文件中，一般积累一定的量然后批量写入，通常使用页为单位，这是磁盘的写入单位。 同步页缓存和数据库文件的行为被称为 checkpoint（检查点），一般在 page cache积累到一定页数修改的时候；

当然，有些系统也可以手动执行 checkpoint。执行 checkpoint 之后，page cache可以被清空，这样可以保证page cache不会因为太大而性能下降。Checkpoint目的是减少数据库的恢复时间(服务奔溃或重启服务后的恢复)

## BIN log,REDO log,UNDO log

### BIN log

bin log是server层的日志（和引擎无关，所有引擎都可以使用）被称为归档日志，默认情况下，binlog日志是二进制格式的，不能使用查看文本工具的命令（比如，cat，vi等）查看，而使用mysqlbinlog解析查看

**bin log记录操作的方法是逻辑性的语句。即便它是基于行格式的记录方式，其本质也还是逻辑的SQL设置**，如该行记录的每列的值是多少，比如"给ID=2这一行的c字段加1 "。

#### 日志的格式

* statement：基于SQL语句的模式，某些语句中含有一些函数，例如 UUID NOW 等在复制过程可能导致数据不一致甚至出错。
* row：基于行的模式，记录的是行的变化，很安全。但是 binlog 的磁盘占用会比其他两种模式大很多，在一些大表中清除大量数据时在 binlog 中会生成很多条语句，可能导致从库延迟变大。
* mixed：混合模式，根据语句来选用是 statement 还是 row 模式。

#### 刷盘流程

Mysql为每个线程都维护了一个binlog cache，通过sync_binlog参数来判断多久把binlog cache中的数据写入到磁盘，一个事务的 binlog 是不能被拆开的，因此不论这个事务多大，也要确保一次性写入，**所以bin log刷盘的基本单位是一个事务产生的所有bin log**，这就涉及到了 binlog cache 的保存问题。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210928182926JeMm36.png)

每个线程有自己 binlog cache，但是共用同一份 binlog 文件。

* 图中的 write，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。
* 图中的 fsync，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。

write 和 fsync 的时机，是由参数 sync_binlog 控制的，sync_binlog取值范围是 0-N

* 0：不去强制要求，由系统自行判断何时写入磁盘
* 1：每次 commit 的时候都要将 binlog 写入磁盘
* N：每N个事务，才会将 binlog 写入磁盘

bin log作用仅仅只是归档，并不保证数据的持久性

如果仅仅依靠bin log恢复是会有数据丢失的风险，一是因为sync_binlog设置为0或大于1的数的时候，binlog数据记录不全，二是因为innodb内部存在redo log，加上redo log才能保证数据恢复准确，因为redo log也有刷盘的机制，**要想完全保证crash-safe，必须bin log和redo log的刷盘时机都设置为每次事务提交都刷盘，这种设置被称为双1**

### REDO log

#### 为什么需要记录REDO

* crash-safe（崩溃安全）：为了取得更好的读写性能，InnoDB会将数据缓存在内存中（InnoDB Buffer Pool），对磁盘数据的修改也会落后于内存，这时如果进程或机器崩溃，会导致内存数据丢失，为了保证数据库本身的一致性和持久性，InnoDB维护了REDO LOG。修改Page之前需要先将修改的内容记录到REDO中，并保证REDO LOG早于对应的Page落盘，也就是常说的WAL，Write Ahead Log。当故障发生导致内存数据丢失后，InnoDB会在重启时，通过重放REDO，将Page恢复到崩溃前的状态。

#### REDO的存储格式

REDO的维护增加了一份写盘数据，同时为了保证数据正确，事务只有在他的REDO全部落盘才能返回用户成功，REDO的写盘时间会直接影响系统吞吐，显而易见，**REDO的数据量要尽量少**。其次，系统崩溃总是发生在始料未及的时候，当重启重放REDO时，系统并不知道哪些REDO对应的Page已经落盘，因此REDO的重放必须可重入，即**REDO操作要保证幂等**。最后，为了便于通过并发重放的方式加快重启恢复速度，REDO应该是**基于Page**的，即一个REDO只涉及一个Page的修改。

数据量小是**Logical Logging**的优点，而幂等以及基于Page正是**Physical Logging**的优点，因此InnoDB采取了一种称为**Physiological Logging**的方式，来兼得二者的优势。所谓Physiological Logging，就是以Page为单位，但在Page内以逻辑的方式记录。举个例子，MLOG_REC_UPDATE_IN_PLACE类型的REDO中记录了对Page中一个Record的修改，方法如下：

```sql
（Page ID，Record Offset，(Filed 1, Value 1) … (Filed i, Value i) … )
```

#### REDO的存储文件

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927155208H8dhTj.png)

InnoDB 的 redo log 是固定大小的，在逻辑上构成一个环，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么总共就可以记录 4GB 的操作。

* write pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。
* checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。

> 为什么redo log是固定大小，在逻辑上是一个环？
>
> redo log实际上记录的是事务从开启到提交或回滚之间的中间状态，是一个临时的状态，所以redo log是固定的，当write pos追上了checkpoint就类似于缓冲区已经满了，redo log满了和缓冲区满了差不多，redo log会先把已经提交了的事物刷入磁盘，然后如果redo log中只剩下没有提交的事物记录，那就说明数据库中有大量待提交的事物，所以redo log的大小设置其实和当前数据库的事务大小还有事务完成间隔时间有关系。

#### 怎么保证crash-safe（两阶段提交）

1. MySQL Server 层的执行器调用 InnoDB 存储引擎的数据更新接口；
2. 存储引擎更新 Buffer Pool 中的缓存页，
3. 同时存储引擎记录一条 redo log 到 redo log buffer 中，并将该条 redo log 的状态标记为 prepare 状态；
4. 接着存储引擎告诉执行器，可以提交事务了。执行器接到通知后，会写 binlog 日志，然后提交事务；
5. 存储引擎接到提交事务的通知后，将 redo log 的日志状态标记为 commit 状态；
6. 接着根据 innodb_flush_log_at_commit 参数的配置，决定是否将 redo log buffer 中的日志刷入到磁盘

以一个简单的update语句为例

```sql
mysql> update T set c=c+1 where ID=2;
```

1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。

这里给出这个 update 语句的执行流程图，图中浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927161331jd6pjI.png)

Mysql将 redo log 的写入拆成了两个步骤：prepare 和 commit，这就是"两阶段提交"，两阶段提交保证了先写bin log再提交redo log。

当发生crash的时候两阶段提交是怎么保证crash-safe的

* crash发生在redo log prepare之前：只是修改了内存数据，没有记录redo log和bin log，事务没有提交，crash之后重新从磁盘读取数据，内存数据丢失，因为没有记录redo log和bin log，所以mysql什么也不用做。

* crash发生在redo log prepare之后，写bin log之前：修改了内存的数据，同时记录了redo log，但是没有记录bin log，crash之后读取redo log发现事务没有提交，进行回滚（由于没有写bin log，回滚就是删除redo log而已）

* crash发生在redo log prepare之后，写bin log之后，但是redo log没有commit：修改了内存的数据，同时记录了redo log，也记录了bin log，crash之后读取redo log发现事务没有提交，会先去检查bin log的完整性，根据bin log的完整性分为两种情况

  * binlog完整：对redo log进行提交
  * binlog不完整：进行回滚（**因为写了bin log，回滚就是在bin log后面再加上一条记录，比如原来的bin log是set id = id + 1，后面加的bin log就是set id = id -1，保持同一行数据的前后一致性**）

  > 问题1：Mysql怎么知道bin log是完整的
  >
  > 一个事务的Bin log是有完整格式的，statement格式的Bin log，最后会有COMMIT，Row格式的Bin log，最后会有一个XID event
  >
  > 问题2：Redo log和Bin log是怎么关联起来的
  >
  > 它们有一个共同的字段XID，相当于Redo log和Bin log的外键关联，当崩溃恢复的时候，会按照顺序扫描redo log

* crash发生在redo log commit之后：crash之后读取redo log发现事务已经提交，直接重放redo log（redo log记录的是mysql Page的变更信息，**或者说是内存和磁盘之间的数据差**）

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927163651niM5fs.png)

#### REDO log刷盘

innodb在引擎层也为redo log做了一个缓冲区 log buffer，通过innodb_flush_log_at_trx_commit参数控制redo log刷盘的时间点

* 0表示每秒将"log buffer"同步到"os buffer"且从"os buffer"刷到磁盘日志文件中
* 1表示每事务提交都将"log buffer"同步到"os buffer"且从"os buffer"刷到磁盘日志文件中
* 2表示每事务提交都将"log buffer"同步到"os buffer"但每秒才从"os buffer"刷到磁盘日志文件中

![buffer刷新配置示意图](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927164312IYGxmB.png)

## RELAY log（中继日志）

relay log是在mysql主从同步的时候，负责传输数据的文件

relay log很多方面都跟binary log差不多

从服务器I/O线程将主服务器的二进制日志（bin log）读取过来记录到从服务器本地文件（relay log），然后SQL线程会读取relay-log日志的内容并应用到从服务器，从而使从服务器和主服务器的数据保持一致

## UNDO log与MVCC

* UNDO log也是innodb为了实现事务而专有的一种日志，属于引擎层，UNDO log最主要的作用有两个
  * 实现MVCC
  * 当事务失败时依靠UNDO log进行回滚

* MVCC: Multiversion Concurrency Control,翻译为多版本并发控制，其目标就是为了提高数据库在高并发场景下的性能。**MVCC最大的优势：读不加锁，读写不冲突。在读多写少的场景下极大的增加了系统的并发性能**

### UNDO log与REDO log

当数据发生改变，REDO log会记录下数据的改变值（新值，也就是改变之后的值），而当事务执行发生异常，需要回滚数据的时候需要把数据设置为以前的值（旧值），UNDO log就是用来记录旧值的，可以看到

* REDO log存储的是改变之后的记录，只关心未来
* UNDO log存储的是改变之前的旧值只关心过去

### UNDO log数据格式（版本链）

B+ 索引树上对应的记录只会有一个最新版本，只不过 InnoDB 可以**根据 undo log 得到数据的历史版本**，从而实现多版本控制。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927190543rMePfp.png)

undo log 是如何和某条行记录产生联系的呢？换句话说，我怎么能通过这条行记录找到它拥有的 undo log 呢？

InnoDB 存储引擎中每条行记录其实都拥有三个隐藏的字段：`DB_TRX_ID` 和 `DB_ROLL_PT，`还有一个`DB_ROW_ID(隐含id,6byte，由innodb自动产生)`

* DB_TRX_ID：就是最近更新这条行记录的事务 ID，
* DB_ROLL_PT：回滚指针，就是指向之前生成的 undo log
* DB_ROW_ID：如果未声明主键，InnoDB 会自动生成一个隐藏主键，说的就是`DB_ROW_ID`

UNDO log版本链和MVCC的实现都是通过DB_TRX_ID和DB_ROLL_PT这两个字段，为了描述方便下面用trx_id和roll_pointer做替代

假设 id = 100 的事务 A 向user表插入一条行记录（id = 1, username = "Jack", age = 18），那么，这行记录的两个隐藏字段 `trx_id = 100` 和 `roll_pointer` 指向一个空的 undo log，因为在这之前并没有事务操作 id = 1 的这行记录。如图所示：

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/202109271914587nW8d9.png)

然后，id = 200 的事务 B 修改了这条行记录，把 age 从 18 修改成了 20，于是，这条行记录的 `trx_id` 就变成了 200，`rooll_pointer` 就指向事务 A 生成的 undo log ：

![20210924000838](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927191555nPbRdW.png)

接着，id = 300 的事务 C 再次修改了这条行记录，把 age 从 20 修改成了 30，如下图：

![20210924000726](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927191622NEEOkO.png)

可以看到，每次修改行记录都会更新 trx_id 和 roll_pointer 这两个隐藏字段，之前的多个数据快照对应的 undo log 会通过 roll_pointer 指针串联起来，从而形成一个**版本链**。

需要注意的是，**select 查询操作不会生成 undo log**！在 InnoDB 存储引擎中，undo log 只分为两种：

- insert undo log：在 insert 操作中产生的 undo log
- update undo log：对 delete 和 update 操作产生的 undo log

事实上，由于事务隔离性的要求，insert 操作的记录，只对事务本身可见，对其他事务不可见，对吧，所以也就不存在并发情况下的问题。所以，也就是说，**MVCC 这个机制，其实就是靠 update undo log 实现的**，和 insert undo log 基本上没啥关系，我们上面说的 undo log 版本链上的其实就是 update undo log。

### ReadView（一致性视图）机制

MVCC是如何实现高并发下`RC`和`RR`的隔离性呢，这就是在MVCC机制下基于生成的Undo log链和一致性视图ReadView来实现的。

要实现`read committed`在另一个事务提交之后其他事务可见和`repeatable read`在一个事务中SELECT操作一致，就是依靠ReadView，对于`read uncommitted`，直接读取最新值即可，而`serializable`采用加锁的策略通过牺牲并发能力而保证数据安全，因此只有`RC`和`RR`这两个级别需要在MVCC机制下通过ReadView来实现。

**在read committed级别下，readview会在事务中的每一个SELECT语句查询发送前生成**（也可以在声明事务时显式声明`START TRANSACTION WITH CONSISTENT SNAPSHOT`），因此每次SELECT都可以获取到当前已提交事务和自己修改的最新版本。

而在`repeatable read`级别下，每个事务只会在第一个SELECT语句查询发送前或显式声明处生成，其他查询操作都会基于这个ReadView，这样就保证了一个事务中的多次查询结果都是相同的，因为他们都是基于同一个ReadView下进行MVCC机制的查询操作。

InnoDB为每一个事务构造了一个数组`m_ids`用于保存一致性视图生成瞬间当前所有`活跃事务`(开始但未提交事务)的ID，将数组中事务ID最小值记为低水位`m_up_limit_id`，当前系统中已创建事务ID最大值+1记为高水位`m_low_limit_id`

- `m_ids`：生成 ReadView 时有哪些事务在执行但是还没提交的（称为 ”**活跃事务**“），这些活跃事务的 id 就存在这个字段里
- `min_trx_id`：m_ids 里最小的值
- `max_trx_id`：生成 ReadView 时 InnoDB 将分配给下一个事务的 ID 的值（事务 ID 是递增分配的，越后面申请的事务 ID 越大）
- `creator_trx_id`：当前创建 ReadView 事务的 ID

假设表中已经被之前的事务 A（id = 100）插入了一条行记录（id = 1, username = "Jack", age = 18），如图所示：

![20210923234807](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927192545CVkhTZ.png)

接下来，有两个事务 B（id = 200） 和 C（id = 300）过来**并发执行**，事务 B 想要更新（update）这行 id = 1 的记录，而事务 C（select）想要查询这行数据，这两个事务都执行了相应的操作但是还没有进行提交：

![20210924183516](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927192809YtYZti.png)

如果现在事务 B 开启了一个 ReadView，在这个 ReadView 里面：

- `m_ids` 就包含了当前的活跃事务的 id，即事务 B 和事务 C 这两个 id，200 和 300
- `min_trx_id` 就是 200
- `max_trx_id` 是下一个能够分配的事务的 id，那就是 301
- `creator_trx_id` 是当前创建 ReadView 事务 B 的 id 200

![20210924183529](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927192924mz5zDL.png)

现在事务 B 进行第一次查询（上面说过 select 操作不会生成 undo log 的哈），会**把这行记录的隐藏字段 `trx_id` 和 ReadView 的 `min_trx_id` 进行下判断**，此时，发现 trx_id 是 100，小于 ReadView 里的 `min_trx_id`（200），这说明在事务 B 开始之前，修改这行记录的事务 A 已经提交了，所以**开始于事务 A 提交之后的事务 B、是可以查到事务 A 对这行记录的更新的**。

```sql
row.trx_id < ReadView.min_trx_id
```

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927193004JdsEet.png)

接着事务 C 过来修改这行记录，把 age = 18 改成了 age = 20，所以这行记录的 `trx_id` 就变成了 300，同时 `roll_pointer` 指向了事务 C 修改之前生成的 undo log：

![20210924183846](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927193039LC2Lub.png)

那这个时候事务 B 再次进行查询操作，会发现**这行记录的 `trx_id`（300）大于 ReadView 的 `min_trx_id`（200），并且小于 `max_trx_id`（301）**。

```sql
row.trx_id > ReadView.min_trx_id && row.trx_id < max_trx_id
```

这说明一个问题，就是更新这行记录的事务很有可能也存在于 ReadView 的 m_ids（活跃事务）中。所以事务 B 会去判断下 ReadView 的 m_ids 里面是否存在 `trx_id = 300` 的事务，显然是存在的，这就表示这个 id = 300 的事务是跟自己（事务 B）在同一时间段并发执行的事务，也就说明这行 age = 20 的记录事务 B 是不能查询到的。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927193146CVWbI8.png)

既然无法查询，那该咋整？事务 B 这次的查询操作能够查到啥呢？

没错，undo log 版本链！

这时事务 B 就会顺着这行记录的 roll_pointer 指针往下找，就会找到最近的一条 `trx_id = 100` 的 undo log，而自己的 id 是 200，即说明这个 trx_id = 100 的 undo log 版本必然是在事务 B 开启之前就已经提交的了。所以事务 B 的这次查询操作读到的就是这个版本的数据即 age = 18。

通过上述的例子，我们得出的结论是，**通过 undo log 版本链和 ReadView 机制，可以保证一个事务不会读到并发执行的另一个事务的更新**。

**那自己修改的值，自己能不能读到呢？**

是可以读到的。不过上面的例子我们只涉及到了 ReadView 中的前三个字段，而 `creator_trx_id` 就与自己读自己的修改有关

假设事务 C 的修改已经提交了，然后事务 B 更新了这行记录，把 age = 20 改成了 age = 66，如下图所示：

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927193242ASZJyK.png)

然后，事务 B 再来查询这条记录，发现 `trx_id = 200` 与 ReadView 里的 `creator_trx_id = 200` 一样，这就说明这是我自己刚刚修改的啊，当然可以被查询到。

```sql
row.trx_id = ReadView.creator_trx_id
```

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927193315pPyBLm.png)

那如果在事务 B 的执行期间，突然开了一个 id = 400 的事务 D，然后更新了这行记录的 age = 88 并且还提交了，然后事务 B 再去读这行记录，能读到吗？

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927193335c30jV6.png)

答案是不能的。

因为这个时候事务 B 再去查询这行记录，就会发现 `trx_id = 500` 大于 ReadView 中的 `max_trx_id = 301`，这说明事务 B 执行期间，有另外一个事务更新了数据，所以不能查询到另外一个事务的更新。

```sql
row.trx_id > ReadView.max_trx_id
```

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/202109271934234NyQQ2.png)



最后做一个总结：

- 事务以排他锁的形式修改原始数据
- 把修改前的数据存放于undo log，通过回滚指针与主数据关联
- 修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback）

- 版本链和ReadView可以保证一个事务不会读到并发执行的另一个事务的更新
- 版本链和ReadView可以保证一个事务只可以读到该事务自己修改的数据或该事务开始之前的数据

> 上面画的图把磁盘记录和undo log组成了一个链表，但实际InnoDB采用表空间 + 回滚段的方式来存储undo log，回滚段定义了UNDO文件的组织方式（但是逻辑上仍然可以看作一个链表）。

# 事务

## 事务4大特性（ACID）

* 原子性(Atomicity)：事务是数据库的逻辑工作单位，事务中包括的诸操作要么全做，要么全不做，这一点Mysql通过redo log和undo log实现

* 隔离性(Isolation)：一个事务的执行不能被其他事务干扰程度，MVCC实现

* 持续性/永久性(Durability)：一个事务一旦提交，它对数据库中数据的改变就应该是永久性的，通过bin log实现

* 一致性(Consistency)：**这里的一致性是指系统从一个正确的状态,迁移到另一个正确的状态。**

  > "ensuring the consistency is the responsibility of user, not DBMS.", "DBMS assumes that consistency holds for each transaction"
  >
  > 一致性并不是由数据库来保证的，而ACID就是说事务能够通过AID来保证这个C的过程.C是目的,AID都是手段。程序员应该利用AID三个属性来保证一致性。

## 事务的隔离级别

* 读未提交（Read uncommitted）

* 读已提交（Reda committed）

* 可重复读（Repeatable read）（Mysql默认隔离级别）

* 串行化（Serial）

## 脏读

1、在事务A执行过程中，事务A对数据资源进行了修改，事务B读取了事务A修改后的数据。

2、由于某些原因，事务A并没有完成提交，发生了RollBack操作，则事务B读取的数据就是脏数据。

这种读取到另一个事务未提交的数据的现象就是脏读(Dirty Read)。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927214140uwRrZN.jpg)

Mysql的RU（读未提交会有脏读）其他更高的隔离级别不会有脏读

## 不可重复读

事务B读取了两次数据资源，在这两次读取的过程中事务A修改了数据，导致事务B在这两次读取出来的数据不一致。

这种在同一个事务中，前后两次读取的数据不一致的现象就是不可重复读(Nonrepeatable Read)。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927214216TKJyJV.jpg)

RU（读未提交）RC（读已提交）会有不可重复读，RR和Serial不会有不可重复读情况

**RC与RR在生成一致性视图的时候的逻辑不一样**

* RC是每次普通的select查询（加锁的查询逻辑不一样）的时候都会生成新的一致性视图（就是新的m_ids数组），这样当两次select查询之间有事务提交，第二次查询就会读到别的事务提交的记录

* RR是在事务期间只生成一次一致性视图（第一次select普通查询开始的时候，不是事务开始的时候 如果有start transaction with consistent snapshot;语句一致性视图就是在执行该语句时创建的），而后面事务中所有select普通查询都会用这个一致性视图，即使在两次查询之间有别的事务提交，也不会读取到别的事务提交的记录

## 幻读

### 什么是幻读

幻读，并不是说两次读取获取的结果集不同，幻读侧重的方面是某一次的 select 操作得到的结果所表征的数据状态无法支撑后续的业务操作。更为具体一些的情况：

1. select 某记录是否存在，不存在，准备插入此记录，但执行 insert 时发现此记录已存在，无法插入，此时就发生了幻读。
2. select  where age = 20，发现有2条记录，update set name=‘upadte’ whre age = 20，结果显示影响行数为3

情况1

| 时间点 | 事务A                  | 事务B          |
| :----- | :--------------------- | :------------- |
| 1      | 开启事务               |                |
| 2      |                        | 开启事务       |
| 3      | 查询数据“张三”，不存在 |                |
| 4      |                        | 插入数据“张三” |
| 5      |                        | 提交事务       |
| 6      | 查询数据“张三”，不存在 |                |
| 7      | 插入数据“张三”，不成功 |                |

情况2

![image-20210928103358580](https://raw.githubusercontent.com/syllr/image/main/uPic/20210928103400Kobtsz.png)

需要搞清楚RC和RR级别对幻读的处理，需要知道三个知识点：当前读，快照读（又叫一致性读），Next-key lock，下面都会提到

## 第一类更新丢失

事务A和事务B都对数据进行更新，但是事务A由于某种原因事务回滚了，把已经提交的事务B的更新数据给覆盖了。这种现象就是第一类更新丢失。



![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927214230nnnNVS.jpg)

在Mysql的任意隔离级别都不会出现第一类更新丢失，如上图，事务A和事物B生成的undo log版本链为

(null|1000) ----->(B|1100)------>(A|900)

> 括号左边是事务ID，右边是记录的数据，如果B事务提交，A事务撤销，那么undo log中所有A事务的记录都将无效（后台会有purge线程删除，同步线程会暂时标记所有事务A的记录为无效），所以等下一个事务来读取的时候会跳过（A｜900）这条记录，读取最新有效的记录，也就是(B|1100)，所以通过MVCC和版本链，MYSQL在任意隔离级别都不会出现第一类更新丢失。

## 第二类更新丢失

其实跟第一类更新丢失有点类似，也是两个事务同时对数据进行更新，但是事务A的更新把已提交的事务B的更新数据给覆盖了。这种现象就是第二类更新丢失。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210927214238Qmwnb1.jpg)

* 在mysql中不会存在上图所说的第二类更新丢失的情况，原因是事务A和B同时开启，事务B先更新数据，在RC级别下更新数据会为数据加上行锁，在RR级别下会为数据加上Next-key lock，一直等待事务B提交之后才会释放锁，也就是说，在事务B修改余额为1100之后到事务B提交之前，事务A是无法获取到锁来修改余额的。

* 如果上图中事务A修改余额发生在事务B提交之后，分两种情况

  1. 事务A的更新语句为update table set amount = 900
  2. 事务A的更新语句为update table set amount = amount - 100；

  如果是情况1，会直接更新余额为900，这种情况会覆盖掉事务B的更新数据，如果是情况2，会根据当前记录的最新数据进行更新，也就是amount=1100-1000，这种情况不会丢失事务B的更新

## 当前读和快照读

### 快照读

select查询的时候会通过事务生成的一致性视图来查询，使用的是MVCC机制读取undo中的已经提交的数据。所以它的读取是**非阻塞**的。

快照读和事物的一致性视图有很大的关系，在不同级别下一致性视图的生成逻辑是不同的

* RC：在每次快照读的时候都会生成一致性视图
* RR：在事务中第一条快照读语句执行的时候生成一致性视图，也可以通过start transaction with consistent snapshot语句在事务开始的时候手动生成

> 其实生成一致性视图的关键就是修改用于保存一致性视图生成瞬间当前所有`活跃事务`的`m_ids`，RC就是在每次快照读的时候更新m_ids，而RR在事务中不能修改m_ids

普通的查询语句比如`select * from table where xxxx`都是快照读

### 当前读

当前读是在每次读取的时候都去读取最新的数据（没有提交的也会被读取到），因为mysql中事务对原始数据和undo log版本链的修改逻辑是：以排他锁的形式修改原始数据，**当前读需要获取锁**，所以当前读是会被**阻塞的**

* 在每次更新之前，innodb都会隐式的区查询一次数据，所有更新之前的查询都是当前读`update t set k = k + 1 where id = 1`，这条语句在update之前其实先取查询了一次where id = 1的记录，这次查询就是当前读

* select语句显式加锁的话也是当前读

  ```sql
  //这两个都是显式加锁，当前读
  mysql> select k from t where id=1 lock in share mode;
  mysql> select k from t where id=1 for update;
  ```

无论在RC还是RR级别下当前读都需要获取锁，但是在不同级别下获取到的锁是不一样的

* RC级别获取行锁
* RR级别获取Next-key lock

> 不论获取到的是什么锁，当前读获取到的锁不会因为当前读语句被执行而释放，锁的释放会等到事务提交之后才释放，这就是两阶段锁（下面会讲）

## 例子

```sql
mysql> CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `k` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB;
insert into t(id, k) values(1,1),(2,2);
```

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210928113849oLuZKI.png)

begin/start transaction 命令并不是一个事务的起点，在执行到它们之后的第一个操作 InnoDB 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 start transaction with consistent snapshot 这个命令。

* 第一种启动方式，一致性视图是在执行第一个快照读语句时创建的；
* 第二种启动方式，一致性视图是在执行 start transaction with consistent snapshot 时创建的。

在这个例子中，事务 C 没有显式地使用 begin/commit，表示这个 update 语句本身就是一个事务，语句完成的时候会自动提交。事务 B 在更新了行之后查询 ; 事务 A 在一个只读事务中查询，并且时间顺序上是在事务 B 的查询之后。

**结果：**

* **在RR级别下事务B查到的k的值是3，而事务A查到的k的值是 1**
* **在RC级别下事务B查到的K的值是3，而事务A查到的K的值是2**

下面是分析过程

* 在RR级别下
  * 在上面的例子中事务B的`select k from t where id = 1`语句是发生在`update t set k = k+1 where id = 1`之后的，update语句会触发当前读，读到的数据是事务C已经更新过了的数据K=2，update语句在K=2的基础上进行更新把数据更新成3。
  * 事务A在最开始用了`start transaction with consistent snapshot`手动生成了一致性视图，因为在RR级别下，一致性视图不会得到更新，所以查找到的数据还是一致性视图生成时候的值K=1
* 在RC级别下
  * 在上面的例子中事务B的`select k from t where id = 1`语句是发生在`update t set k = k+1 where id = 1`之后的，update语句会触发当前读，读到的数据是事务C已经更新过了的数据K=2，update语句在K=2的基础上进行更新把数据更新成3。
  * 虽然事务A在最开始用了`start transaction with consistent snapshot`手动生成了一致性视图，因为在RC级别下，每次查询都会更新一致性视图，所以查找到的数据是事务C提交之后的数据（事务B这时候还没有提交）K=2；

## RR是怎么解决幻读的

### RC和RR的不同

RC和RR隔离级别的不同主要体现在对快照读和当前读的处理不同

* 快照读：在RC级别下每次快照读都会更新一致性视图，读取最新已提交的数据，RR会在第一次快照读的时候生成一致性视图，并且在事务中不再修改该视图，用此方法来解决不可重复读问题
* 当前读：当前读是要获取锁的，在RC和RR下获取的锁是不同的，在RC下获取到的是行锁，在RR下获取到的是NEXT-KEY lock（NEXT-key lock = 间隙锁+行锁），其实对比RC就是多了一个间隙锁

### 幻读与NEXT-key lock

NEXT-key lock = 间隙锁 + 行锁，RR对比RC获取到的锁就是多了一个间隙锁，而**间隙锁可以锁住记录间的间隙，使别的事务的插入操作阻塞**，

以幻读的情况1为例

| 时间点 | 事务A                  | 事务B          |
| :----- | :--------------------- | :------------- |
| 1      | 开启事务               |                |
| 2      |                        | 开启事务       |
| 3      | 查询数据“张三”，不存在 |                |
| 4      |                        | 插入数据“张三” |
| 5      |                        | 提交事务       |
| 6      | 查询数据“张三”，不存在 |                |
| 7      | 插入数据“张三”，不成功 |                |

在RC的级别下，我们让事务A在步骤3用当前读加锁

| 时间点 | 事务A                                                | 事务B          |
| :----- | :--------------------------------------------------- | :------------- |
| 1      | 开启事务                                             |                |
| 2      |                                                      | 开启事务       |
| 3      | 用当前读查询数据“张三”<br />（为了加锁），数据不存在 |                |
| 4      |                                                      | 插入数据“张三” |
| 5      |                                                      | 提交事务       |
| 6      | 查询数据“张三”，不存在                               |                |
| 7      | 插入数据“张三”，不成功                               |                |

在步骤3事务A尝试为张三这条记录加锁，但是因为张三这条记录不存在，无法加锁，所以事务B可以插入张三这条记录，还是会发上幻读

在RR的级别下，我们让事务A在步骤3用当前读加锁

| 时间点 | 事务A                                                | 事务B                                                        |
| :----- | :--------------------------------------------------- | :----------------------------------------------------------- |
| 1      | 开启事务                                             |                                                              |
| 2      |                                                      | 开启事务                                                     |
| 3      | 用当前读查询数据“张三”<br />（为了加锁），数据不存在 |                                                              |
| 4      |                                                      | 插入数据“张三”，无法插入，阻塞                               |
| 5      | 查询数据“张三”，不存在                               |                                                              |
| 6      | 插入数据“张三”，成功                                 |                                                              |
| 7      | 提交                                                 |                                                              |
| 8      |                                                      | 因为事务A提交，获取到对应间隙的锁<br />尝试插入，发现已经有张三的数据<br />插入失败 |

* RR和RC的区别就是在RR下面为`select * from where name = '张三' for update`这条语句加的锁为next-key lock，锁住了表之间的间隙（next-key lock锁的范围后面会提到）

* 导致事务B在插入张三数据的时候，无法获取到对应间隙的锁，一直被阻塞到事务A提交释放锁之后（锁的二阶段释放）
* 事务B再进行插入的时候发现已经有张三的记录，所以插入失败

综上所述，RR级别是通过在当前读中加Next-key lock来锁住表中的间隙来防止数据插入间隙中，产生幻读。

### RR解决幻读了吗

`RR` 级别下存在幻读的可能，但也是可以使用对**记录和间隙手动加拍他锁**的方法消除`幻读`，从这一点来说RR和RC的其中一点差别就是RR可以对间隙加锁。

`SERIALIZABLE`相当于是给所有事务都加了表锁，既锁住了表中所有记录，也锁住了表中所有间隙，从而消除了`幻读`

但很多场景下我们的业务 `sql` 并不会存在 `幻读` 的风险。`SERIALIZABLE` 的一刀切虽然事务绝对安全，但性能会有很多不必要的损失。

故可以在 `RR` 下根据业务需求决定是否加锁，存在幻读风险我们加锁，不存在就不加锁，事务安全与性能兼备，这也是 `RR` 作为 `mysql` 默认隔是个事务离级别的原因。

# 锁

数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。

MYSQL的锁和事务是有关联的，MYSQL的事务隔离级别是通过加锁来实现的

## 锁的行为

mysql中大部分的锁按照锁的范围和行为其实都可以分成两类

* S锁（共享锁，读锁）
* X锁（排他锁，写锁）

## 全局锁

全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。

全局锁的典型使用场景是，做全库逻辑备份

## 表级别的锁

MySQL 里面表级别的锁有三种：一种是表锁，一种是元数据锁（meta data lock，MDL)，意向锁。

* 表锁的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

  > myisam就只支持表锁
  >
  > ## 表锁是不会有死锁的
  > >因为MYSQL总是会一次性获取该语句所需的所有表锁
  > >
  > >占有等待，一次性获取所有所需的资源，如果只能获取一部分的资源，就不申请

* 另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。

  > 在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。

* 意向锁：表示事务有意对表中某些行加共享锁或者排他锁

  * 意向共享锁（intention shared lock, IS）：事务有意向对表中的某些行加共享锁（S锁）

  >> 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。
  >> SELECT column FROM table ... LOCK IN SHARE MODE; 

  * 意向排他锁（intention exclusive lock, IX）：事务有意向对表中的某些行加排他锁（X锁）

  >> 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。
  >> SELECT column FROM table ... FOR UPDATE; 

### 意向锁

需要强调一下，意向锁是一种**不与行级锁冲突**的表级锁，这一点非常重要。意向锁分为两种：

- **意向共享锁**（intention shared lock, IS）：事务有意向对表中的某些行加**共享锁**（S锁）

```sql
-- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。
SELECT column FROM table ... LOCK IN SHARE MODE; 
```

- **意向排他锁**（intention exclusive lock, IX）：事务有意向对表中的某些行加**排他锁**（X锁）

```sql
-- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。
SELECT column FROM table ... FOR UPDATE; 
```

即：意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。

### 意向锁要解决的问题

设想这样一张 users 表： **MySql**，**InnoDB**，**Repeatable-Read**：users（id PK，name）

| id   | name      |
| ---- | --------- |
| 1    | ROADHOG   |
| 2    | Reinhardt |
| 3    | Tracer    |
| 4    | Genji     |
| 5    | Hanzo     |
| 6    | Mccree    |

事务 A 获取了某一行的排他锁，并未提交：

```sql
SELECT * FROM users WHERE id = 6 FOR UPDATE;
```

事务 B 想要获取 users 表的表锁：

```sql
LOCK TABLES users READ;
```

因为共享锁与排他锁互斥，所以事务 B 在视图对 users 表加共享锁的时候，必须保证：

- 当前没有其他事务持有 users 表的排他表锁。
- 当前没有其他事务持有 users 表中任意一行的排他行锁 。

为了检测是否满足第二个条件，事务 B 必须在确保 users表不存在任何排他锁的前提下，去检测表中的每一行是否存在排他锁。很明显这是一个效率很差的做法，但是有了**意向锁**之后，情况就不一样了

#### 意向锁的兼容互斥性

|                  | 意向共享锁（IS） | 意向排他锁（IX） |
| ---------------- | ---------------- | ---------------- |
| 意向共享锁（IS） | 兼容             | 兼容             |
| 意向排他锁（IX） | 兼容             | 兼容             |

即**意向锁之间是互相兼容的**

虽然意向锁和自家兄弟互相兼容，但是它会与普通的**排他表锁 / 共享表锁**互斥：

|               | 意向共享锁（IS） | 意向排他锁（IS） |
| ------------- | ---------------- | ---------------- |
| 共享表锁（S） | 兼容             | 互斥             |
| 排他表锁（X） | 互斥             | 互斥             |

注意：意向锁是表级锁，和行级别的锁是不会有共享/互斥的关系的，意向锁主要是为了和共享表锁/排他表锁做联系

现在我们回到刚才 users 表的例子：

事务 A 获取了某一行的排他锁，并未提交：

```sql
SELECT * FROM users WHERE id = 6 FOR UPDATE;
```

此时 users 表存在两把锁：users 表上的**意向排他锁**与 id 为 6 的数据行上的**排他锁**。

事务 B 想要获取 users 表的共享锁：

```sql
LOCK TABLES users READ;
```

此时事务 B 检测事务 A 持有 users 表的**意向排他锁**，就可以得知事务 A 必然持有该表中某些数据行的**排他行锁**，那么事务 B 对 users 表的加表锁请求就会被排斥（阻塞），而无需去检测表中的每一行数据是否存在排他锁。

#### 总结

1. InnoDB 支持多粒度锁，特定场景下，行级锁可以与表级锁共存。
2. 意向锁在保证并发性的前提下，实现了行锁和表锁共存且满足事务隔离性的要求。

意向锁主要是innoDB为了兼容行锁和表锁而提出的一种机制，可以加快表锁的上锁速度，如果没有意向锁，在加表锁的时候就必须要判断表中的每一行记录，看是否存在行锁，如果存在就不能加表锁，而有了意向锁之后，在加表锁的时候判断下是否有意向锁就可以快速的判断能不能加表锁，意向锁统一了行锁和表锁之间的逻辑，实现了InnoDB对锁的多粒度支持，让行级锁可以和表级锁共存。

### Myisam并发锁

在一定条件下，MyISAM也支持查询和操作的并发进行。

MyISAM存储引擎有一个系统变量concurrent_insert，专门用以控制其并发插入的行为，其值分别可以为0、1或2

* 当concurrent_insert设置为0时，不允许并发插入。
* 当concurrent_insert设置为1时，MyISAM允许在一个读表的同时，另一个进程从表尾插入记录。这也是MySQL的默认设置。
* 当concurrent_insert设置为2时，无论MyISAM表中有没有空洞，都允许在表尾插入记录，都允许在表尾并发插入记录。

> 插入都是从表尾插入的，不影响已有数据的读取

可以利用MyISAM存储引擎的并发插入特性，来解决应用中对同一表查询和插入锁争用。例如，将concurrent_insert系统变量为2，总是允许并发插入；同时，通过定期在系统空闲时段执行OPTIONMIZE TABLE语句来整理空间碎片，收到因删除记录而产生的中间空洞。

## 行锁

InnoDB的行锁是和隔离级别有关系的，但凡是谈行锁一定要先确定隔离级别，不同的隔离级别锁的行为也不同。

可以这样理解

* 对于写（当前读）：RU，RC，RR都会加锁，但是不同级别加的锁不一样

  * RR：Next-key lock
  * RC，RU：行锁

* 对于读（普通的读，没有加锁）：RR和RC都是快照读，RU没有加锁，直接读取版本链的最新记录（串行化也是直接读取最新记录，因为串行化不会产生版本链）

* 串行化

  * 读：串行化的读都是当前读，也就是读都会加锁，而且是Next-key lock
  * 写：串行化的写加的锁是Next-key lock

  > 从上面可以看出来，串行化和RR的区别就是RR有快照读和当前读，而串行化的读都是要加锁的（相当于都是当前读）

### 行锁和索引

InnoDB的行锁是通过给索引上的索引项加锁来实现的，在RR级别下可以总结为

```sql
CREATE TABLE `user` (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `intname` int NOT NULL,
  `name` varchar(10) COLLATE utf8mb4_unicode_ci DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `nameIndex` (`intname`)
) ENGINE=InnoDB AUTO_INCREMENT=22 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_unicode_ci
```

* 如果是等值查询Next-key lock就会退化成行锁

* 对于唯一所以和非唯一索引，等值查询/范围查询，索引扫描的逻辑不同，而**所有被扫描的记录和间隙都会加锁**

* 如果没有索引，就会退化成表锁

  > ```sql
  > select * from user where name = 'test' for update ;
  > ```
  >
  > 这条语句中name并不是索引，只是一个普通的字段，这条语句会把整个表锁住

* 主键索引：如果走的是主键索引就会锁住主键的间隙和记录

  > ```sql
  > select * from user where id > 11 for update ;
  > ```
  >
  > id是主键索引，范围查询走主键，会把(11, 下一条记录ID]的范围全部加上锁

* 二级索引：如果走的是二级索引会锁住二级索引的间隙和记录，**同时还会锁住主键的对应记录**

  > ```sql
  > select * from user where intname > 110 for update ;
  > ```
  >
  > intname是二级索引，范围查询走二级索引，会把(110, 下一条intname]的范围全部加上锁，并且把对应主键记录也加上锁

### Next-key lock

Next-key lock是RR级别的默认加锁单位，Next-lock = 间隙锁+行锁，范围是左开右闭（因为在范围查询中需要找到第一个不符合条件的记录）

### 两阶段锁（重要）

先举个例子。在下面的操作序列中，事务 B 的 update 语句执行时会是什么现象呢？假设字段 id 是表 t 的主键。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/202109281636430O1VdB.jpg)

这个问题的结论取决于事务 A 在执行完两条 update 语句后，持有哪些锁，以及在什么时候释放：实际上事务 B 的 update 语句会被阻塞，直到事务 A 执行 commit 之后，事务 B 才能继续执行。事务 A 持有的两个记录的行锁，都是在 commit 的时候才释放的。

也就说**在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。**

> 关于两阶段锁，mysql还有一个优化，实际上在rc模式下，不满足条件的记录锁会被提前释放。

# 索引

## 索引的结构

Mysql的索引的数据结构是B+树

## B树和AVL树以及红黑树比较

B树的结构

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/202109281613219V9LMU.png)

相对于二叉平衡树（AVL和红黑树）而言，B树的实现确实复杂，所以如果纯粹使用内存比较的话，B树性能上肯定不如平衡二叉树。但是工程实践意义上来说，磁盘的读写比内存读写慢1000倍以上，所以针对减少磁盘上的读写在算法上优化，就使得整体性能有了大幅度提升。

B树最大的区别就是M阶的B树因为一个节点有[M/2, M]个元素，所以树的高度比AVL树和红黑树低得多，同时一个节点存储的数据多

* 高度低：要获取磁盘上数据，必须先通过磁盘移动臂移动到数据所在的柱面，然后找到指定盘面，接着旋转盘面找到数据所在的磁道，最后对数据进行读写。磁盘IO代价主要花费在查找所需的柱面上，树的深度过大会造成磁盘IO频繁读写。根据磁盘查找存取的次数往往由树的高度所决定。
* 节点数据多：在获取磁盘数据的时候因为B树一个节点可以存储多个元素，同一个节点中各个元素都是相邻的，可以一次IO就获取到。

通过以上两点B树减少了对与AVL树和红黑树的磁盘读取次数，并且一次可以读取多个数据，大大加快了IO速度。

## B+树和B树的区别

![preview](https://raw.githubusercontent.com/syllr/image/main/uPic/20210930092058LX0WHU.jpeg)

和B树做对比，在结构上B+树有两点主要的不同

* B+树的非叶子结点不存储数据，也就是说B+树的非叶子结点只有索引的左右
* B+树所有的叶子结点之间有指针做关联，类似于一个链表（这个看情况，有的B+树的实现是单向链表，有的是双向链表，**Mysql的索引就是双向链表B+树**）

从上面两个结构的不同，我们可以总结出为什么Mysql InnoDB的索引用B+树这种数据结构

* B+树的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了。
* B+树的所有数据都在叶子结点，有关键字查询的路径长度相同，导致每一个数据的查询效率相当，查询更稳定。
* B+树便于范围查询（最重要的原因，范围查找是数据库的常态）：B+树的叶子结点组成了链表，所以B+树的范围查询是在遍历链表，而B树是在遍历树（要查找数据要用中序遍历，因为中序遍历有序）

### 自适应hash

Mysql的索引结构只有B+树一种，但是当B+树中的数据离散度比较大的时候，Mysql提供了一种机制可以加快B+树索引的搜索，这个机制就是自适应Hash

存储引擎会自动对个索引页上的查询进行监控，如果能够通过使用自适应哈希索引来提高查询效率，其便会自动创建自适应哈希索引，不需要开发人员或运维人员进行任何设置操作。

**自适应哈希索引是对innodb的缓冲池的B+树页进行创建，不是对整张表创建，因此速度很快（可以理解成热点的数据才会进入这个哈希表，相当于缓存）。**

#### 哪些页会被自动构造成哈希索引

* 对这个页的连续访问模式必须是一致的，也就是查询的条件必须是一致的。
* 以同一查询条件进行了100次以上的访问

自适应hash只会对热点数据建立，而且是建立在内存中，并不是一种新的索引格式，当B+树中的一个数据被大量访问，并且访问该数据会经过多次IO（深度比较高的情况），Mysql会考虑为该数据建立Hash缓存，这个过程是由代码自动判断的。

自适应hash可以看作是B+树索引的缓存，只不过这个缓存是Hash格式的，当然因为开启了自适应hash之后mysql还需要维护索引数据和hash数据的一致性，需要额外的性能开销，具体是否开启hash就看mysql内部自己对于性能的判断。

## 索引的内容

```sql
mysql> create table T(id int primary key, k int not null, name varchar(16),index (k))engine=InnoDB;
```

表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210928164303dc5vFY.png)

从图中不难看出，根据叶子节点的内容，索引类型分为主键索引（左边）和非主键索引（右边）。

* 主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。
* 非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。

### 基于主键索引和普通索引的查询有什么区别？

* 如果语句是 select * from T where ID=500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；
* 如果语句是 select * from T where k=5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为**回表**。

也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

那么，非主键索引的查询就一定会回表吗？

其实不是的，当索本身已经包含要查询的数据的时候，是不用回表的，例如

```sql
select k from T where k > 10;
```

要查询的数据本身就是索引，所以不用回表，或者说对于联合索引，要查询的数据就是索引中的某一项，这种情况被称作**索引覆盖**

总结一下

* 主键索引在叶子节点中存储的是记录
* 二级索引在叶子结点中存储的是主键索引的值
* 如果索引包含了查询的语句中需要查询的字段，这种情况叫做索引覆盖
* 如果有索引覆盖的情况，那么二级索引是不用回表通过主键查询数据的，没有索引覆盖，二级索引就需要进行回表再查询一次主键来获取数据

## 索引的维护

B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护

### 页分裂

如果数据所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为**页分裂**。在这种情况下，性能自然会受影响。

除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。

### 页融合

当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。

### 自增主键可以减少页的分裂和融合

自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。并且自增主键往往从0开始，占用空间更小

从性能和存储空间方面考量，自增主键往往是更合理的选择。

## 索引的形式

* 单键索引：索引中只有一个字段
* 联合索引：索引中有多个字段

### 联合索引

参考《架构-索引下推》章节对联合索引的描述（索引下推和最左前缀非常重要）

## 索引的查询

根据索引中是否允许存储相同数据的记录来判断可以把索引分为唯一索引和非唯一索引

* 唯一索引：索引中的数据不允许出现相同的，如有索引中已有数据再插入，会报错
* 非唯一索引：索引中的数据允许出现相同的，如果不指定索引的类型为unique，那么默认都是非唯一索引

### 扫描索引和加锁

需要记住一点锁和索引的关系是，**当mysql扫描索引的时候，扫到的所有记录都会加锁**，所以对于唯一索引和非唯一索引的查询也是不同的，而查询的语句是范围查询还是等值查询，查询的逻辑也是不同的，而等值查询也要看表中是否有记录，就算查询返回的都是空，可能对于不同形式的索引，加锁的记录也是不同的。

# 主备

![img](https://raw.githubusercontent.com/syllr/image/main/uPic/20210928194012JpERtF.png)

可以看到：主库接收到客户端的更新请求后，执行内部事务的更新逻辑，同时写 binlog。

* binlog写成功后就可以同步至备库，为什么不需要等到redologcommit成功后呢

  > 是因为binlog写盘成功，就算后续commit失败，数据库也是可以自己恢复重新commit的，而如果事务后续执行失败，需要回滚，bin log采用往后添加逆向逻辑的机制，也可以顺利回滚

备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：

1. 在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。
2. 在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread（后来由于多线程复制方案的引入，sql_thread 演化成为了多个线程）。其中 io_thread 负责与主库建立连接。
3. 主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。
4. 备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。
5. sql_thread 读取中转日志，解析出日志里的命令，并执行。

## 循环复制问题

binlog 的特性确保了在备库执行相同的 binlog，可以得到与主库相同的状态，实际生产上使用比较多的是一主一从结构，但是还有一种双M结构，双 M 结构和 M-S 结构，区别只是：节点 A 和 B 之间总是互为主备关系。这样在切换的时候就不用再修改主备关系。

双 M 结构还有一个问题需要解决：业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。

![循环复制](https://raw.githubusercontent.com/syllr/image/main/uPic/20210928200850arpDEY.jpg)

那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了，这个要怎么解决呢，在mysql5.7中引入了一个新的复制机制GTID。

## GTID

GTID 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。Mysql在5.7版本引入了GTID机制，在 GTID 模式下，每个事务都会跟一个 GTID 一一对应，由两部分组成，uuid和gnd

* server_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值，并且各个实例的server_uuid都是不同的，如果一个实例生成的server_uuid和别的实例相同，就会重新生成另一个server_uuid，直到不和集群中别的实例相同为止。
* gno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1

>  通过GTID可以很方便的知道哪一个事务是哪个实例产生的，每个实例各产生了多少事务

通过GTID来判断事务是由哪个实例所产生，可以阻止循环复制，流程如下

1. 在节点 A 更新的事务，binlog 里面记录的GTID有 A 的 server id；
2. 传到节点 B 执行一次以后，节点 B 生成的 binlog 中的GTID（GTID是不会变的）也有 A 的 server id；
3. 再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。

# 数据分片

## 分片键

在对表中的数据分片时，首先要选出一个分片键（Shard key），即用户可以通过这个字段进行数据的水平拆分

对于To C的业务来讲，最好的分片键应该是**用户ID**，比如要查询用户所有的订单，所有的优惠券，以及该用户的信息，使用用户ID作为分片键可以让和一个用户有关的所有信息都集中在同一个分片中，业务可以做到单元化，在设计到用户查询的时候可以在单个分片上进行所有操作，不用涉及到跨分片的访问。

## 分片方法

选择分片方法的时候要考虑到以下几点

* 性能可扩展，通过增加分片节点，性能可以线性提升
* 存储容量可扩展，通过增加分片节点，解决单点存储容量的数据瓶颈
* 分片中每个节点都要有实时访问
* 每个节点的负载都相对平衡

现在一般常用的分片方法有两种

1. range：可以方便在不同机器键进行数据迁移，但是无法做到，但是不方便做到负载均衡
2. hash：可以方便做到负载均衡，但是不方便数据迁移

互联网业务一般选择hash的分片方式，然后把分片的数量设置的很高，比如1024个分片（分片和mysql实例并不是一一对应的），这样可以保证各个节点数据的均衡，也可以最多兼容1024个 mysql实例，数据存储总量也有保证

## 分片与实例

分片其实是一张张表，而不是数据库实例，只是每个分片都在数据库实例中

比如有一张user表要进行分片，一共要分成1024个分片，而我们一共有4个数据库实例那么其实具体的分片为

| 实例       | 表（分片以表的形式存在）              | 表的个数 |
| ---------- | ------------------------------------- | -------- |
| mysql实例1 | user1, user2, ........., user256      | 256      |
| mysql实例2 | user257, user258, ........, user512   | 256      |
| mysql实例3 | user513, user514, ........., user768  | 256      |
| mysql实例4 | user769, user514, ........., user1024 | 256      |

可以看到并不是每一个分片都有一个mysql实例的，mysql实例和分片的个数并不是相等的，但是始终mysql实例个数小于分片的个数

mysql的分片只是讲数据打散，用户可以根据自己的需要添加或减少数据库实例，以此实现数据库性能和容量的伸缩性，比如对数据库进行1024个分片：

* 在平时业务少，对于1024个分片只用10个mysql实例
* 在双十一，618业务高峰期间对于1024个分片配置20个mysql实例

## 如何进行分片

Mysql没有自带的分片解决方案，所以要进行mysql的分片一般有两种途径

* 客户端代码添加分片逻辑
* 走代理中间件，让代理中间件进行分片

# 性能优化

使用explain命令对查询语句进行分析，explain主要有三个字段主要注意

* type：扫描方式，是走的索引扫描，还是全表扫描，如果是索引扫描，那么是范围扫描还是等值扫描
* rows：扫描过的行数
* Extra：额外的优化信息

## Type

MySQL的官网解释非常简洁，只用了3个单词：**连接类型**(the join type)。它描述了找到所需数据使用的扫描方式。

- **system**：系统表，少量数据，往往不需要进行磁盘IO；
- **const**：常量连接，唯一索引或者主键（主键其实也是唯一索引），能确定单表中的数据只有一个的；
- **eq_ref**：主键索引(primary key)或者非空唯一索引(unique not null)等值扫描，但是必须要是连表查询；const和eq_ref都是走唯一索引，但是const是单表查询，eq_ref是联表查询（join）
- **ref**：非主键非唯一索引等值扫描；
- **range**：范围扫描；
- **index**：索引树扫描；
- **ALL**：全表扫描(full table scan)；

## Extra

在扫描索引的过程中Mysql可能还会用到其他的优化，extra里面会展示这些信息

* using index：代表使用了覆盖索引，不回表

* using where：表数据库引擎返回结果后mysql server还会再次筛选这个筛选的过程是需要回表的

  如果只有字段a有索引的话，`select * from table where a = 0 and b = 0`，innodb会首先把a这颗索引树中，a=0的记录找到，然后一条条返回给执行器，返回给执行器的其实是记录的主键，执行器再通过主键回表查询真实的记录，查到所有a=0所有真实记录之后，再判断记录里面的b=0，来进行过滤，最后把结果返回客户端

* using condition index：代表使用二级索引不够还要回表，但回表之前会过滤此二级索引能过滤的where条件

  (a,b )两个字段建立联合索引，如果是语句`select * from table where a = 0 and b = 0`会直接走联合索引，如果是`select * from table where a = 0 and b > 0`，这种范围查询是只能走一部分联合索引（因为a,b的联合索引相当于是建立了一个a的索引和一个a,b的索引，如果b是范围查询，只能走到a这个索引上来），innodb会将所有a=0的记录找到，然后再内存中只留下b>0的记录，然后返回给执行器，执行器回表查到真实记录。

  using condition index相比于using where利用索引减少了回表的次数