# 缓存特征

## 高性能，高并发

Mysql单机的qps极限是2000多，一般的mysql单机并发1000左右就差不多到极限了，而Redis单机qps十几万不成问题，从单机qps的角度上来说redis是mysql的一百多倍

## 命中率

命中率=返回正确结果数/请求缓存次数，命中率问题是缓存中的一个非常重要的问题，它是衡量缓存有效性的重要指标。命中率越高，表明缓存的使用率越高。

## 最大元素（或最大空间）

缓存中可以存放的最大元素的数量，一旦缓存中元素数量超过这个值（或者缓存数据所占空间超过其最大支持空间），那么将会触发缓存启动清空策略根据不同的场景合理的设置最大元素值往往可以一定程度上提高缓存的命中率，从而更有效的时候缓存。

## 淘汰策略

如上描述，缓存的存储空间有限制，当缓存空间被用满时，如何保证在稳定服务的同时有效提升命中率？这就由缓存清空策略来处理，设计适合自身数据特征的清空策略能有效提升命中率。

- **FIFO(first in first out)**

先进先出策略，最先进入缓存的数据在缓存空间不够的情况下（超出最大元素限制）会被优先被清除掉，以腾出新的空间接受新的数据。策略算法主要比较缓存元素的创建时间。在数据实效性要求场景下可选择该类策略，优先保障最新数据可用。

- **LFU(less frequently used)**

最少使用策略，无论是否过期，根据元素的被使用次数判断，清除使用次数较少的元素释放空间。策略算法主要比较元素的hitCount（命中次数）。在保证高频数据有效性场景下，可选择这类策略。

- **LRU(least recently used)**

最近最少使用策略，无论是否过期，根据元素最后一次被使用的时间戳，清除最远使用时间戳的元素释放空间。策略算法主要比较元素最近一次被get使用时间。在热点数据场景下较适用，优先保证热点数据的有效性。

除此之外，还有一些简单策略比如：

- 根据过期时间判断，清理过期时间最长的元素；
- 根据过期时间判断，清理最近要过期的元素；
- 随机清理；
- 根据关键字（或元素内容）长短清理等。

# 缓存介质

虽然从硬件介质上来看，无非就是内存和硬盘两种，但从技术上，可以分成内存、硬盘文件、数据库。

- **内存：**将缓存存储于内存中是最快的选择，无需额外的I/O开销，但是内存的缺点是没有持久化落地物理磁盘，一旦应用异常break down而重新启动，数据很难或者无法复原。
- **硬盘：**一般来说，很多缓存框架会结合使用内存和硬盘，在内存分配空间满了或是在异常的情况下，可以被动或主动的将内存空间数据持久化到硬盘中，达到释放空间或备份数据的目的。
- **数据库：**前面有提到，增加缓存的策略的目的之一就是为了减少数据库的I/O压力。现在使用数据库做缓存介质是不是又回到了老问题上了？其实，数据库也有很多种类型，像那些不支持SQL，只是简单的key-value存储结构的特殊数据库（如BerkeleyDB和Redis），响应速度和吞吐量都远远高于我们常用的关系型数据库等。

# 缓存类型

## 只读缓存

使用只读缓存时，是先把修改写到后端数据库中，再把缓存中的数据删除。当下次访问这个数据时，会以后端数据库中的值为准，重新加载到缓存中。这样做的优点是，数据库和缓存可以保证完全一致，并且缓存中永远保留的是经常访问的热点数据。缺点是每次修改操作都会把缓存中的数据删除，之后访问时都会先触发一次缓存缺失，然后从后端数据库加载数据到缓存中，这个过程访问延迟会变大。

## 读写缓存

使用读写缓存时，是同时修改数据库和缓存中的值。这样做的优点是，被修改后的数据永远在缓存中存在，下次访问时，能够直接命中缓存，不用再从后端数据库中查询，这个过程拥有比较好的性能，比较适合先修改又立即访问的业务场景。但缺点是在高并发场景下，如果存在多个操作同时修改同一个值的情况，可能会导致缓存和数据库的不一致。

## 区别

当使用只读缓存时，如果修改数据库失败了，那么缓存中的数据也不会被删除，此时数据库和缓存中的数据依旧保持一致。而使用读写缓存时，如果是先修改缓存，后修改数据库，如果缓存修改成功，而数据库修改失败了，那么此时数据库和缓存数据就不一致了。如果先修改数据库，再修改缓存，也会产生上面所说的并发场景下的不一致。

我个人总结，只读缓存是牺牲了一定的性能，优先保证数据库和缓存的一致性，它更适合对于一致性要求比较要高的业务场景。而如果对于数据库和缓存一致性要求不高，或者不存在并发修改同一个值的情况，那么使用读写缓存就比较合适，它可以保证更好的访问性能。

# 缓存分类和应用场景

缓存有各类特征，而且有不同介质的区别，那么实际工程中我们怎么去对缓存分类呢？在目前的应用服务框架中，比较常见的，时根据缓存雨应用的藕合度，分为local cache（本地缓存）和remote cache（分布式缓存）：

- **本地缓存**：指的是在应用中的缓存组件，其最大的优点是应用和cache是在同一个进程内部，请求缓存非常快速，没有过多的网络开销等，在单应用不需要集群支持或者集群情况下各节点无需互相通知的场景下使用本地缓存较合适；同时，它的缺点也是应为缓存跟应用程序耦合，多个应用程序无法直接的共享缓存，各应用或集群的各节点都需要维护自己的单独缓存，对内存是一种浪费。
- **分布式缓存**：指的是与应用分离的缓存组件或服务，其最大的优点是自身就是一个独立的应用，与本地应用隔离，多个应用可直接的共享缓存。

## 本地缓存

### 编程直接实现缓存

个别场景下，我们只需要简单的缓存数据的功能，而无需关注更多存取、清空策略等深入的特性时，直接编程实现缓存则是最便捷和高效的。

**a. 成员变量或局部变量实现**

简单代码示例如下：

```java
    public void UseLocalCache(){
     //一个本地的缓存变量
     Map<String, Object> localCacheStoreMap = new HashMap<String, Object>();
    
     List<Object> infosList = this.getInfoList();
    for(Object item:infosList){
        if(localCacheStoreMap.containsKey(item)){ //缓存命中 使用缓存数据
            // todo
        } else { // 缓存未命中  IO获取数据，结果存入缓存
            Object valueObject = this.getInfoFromDB();
            localCacheStoreMap.put(valueObject.toString(), valueObject);
            
        }
    }
		}
		//示例
		private List<Object> getInfoList(){
			return new ArrayList<Object>();
		}
		//示例数据库IO获取
		private Object getInfoFromDB(){
    	return new Object();
		}
```

以局部变量map结构缓存部分业务数据，减少频繁的重复数据库I/O操作。缺点仅限于类的自身作用域内，类间无法共享缓存。

**b. 静态变量实现**

最常用的单例实现静态资源缓存，代码示例如下：

```java
  public class CityUtils {
  private static final HttpClient httpClient = ServerHolder.createClientWithPool(); 
  private static Map<Integer, String> cityIdNameMap = new HashMap<Integer, String>();
  private static Map<Integer, String> districtIdNameMap = new HashMap<Integer, String>();

  static {
    HttpGet get = new HttpGet("http://gis-in.sankuai.com/api/location/city/all");
    BaseAuthorizationUtils.generateAuthAndDateHeader(get,
            BaseAuthorizationUtils.CLIENT_TO_REQUEST_MDC,
            BaseAuthorizationUtils.SECRET_TO_REQUEST_MDC);
    try {
        String resultStr = httpClient.execute(get, new BasicResponseHandler());
        JSONObject resultJo = new JSONObject(resultStr);
        JSONArray dataJa = resultJo.getJSONArray("data");
        for (int i = 0; i < dataJa.length(); i++) {
            JSONObject itemJo = dataJa.getJSONObject(i);
            cityIdNameMap.put(itemJo.getInt("id"), itemJo.getString("name"));
        }
    } catch (Exception e) {
        throw new RuntimeException("Init City List Error!", e);
    }
}
    static {
    HttpGet get = new HttpGet("http://gis-in.sankuai.com/api/location/district/all");
    BaseAuthorizationUtils.generateAuthAndDateHeader(get,
            BaseAuthorizationUtils.CLIENT_TO_REQUEST_MDC,
            BaseAuthorizationUtils.SECRET_TO_REQUEST_MDC);
    try {
        String resultStr = httpClient.execute(get, new BasicResponseHandler());
        JSONObject resultJo = new JSONObject(resultStr);
        JSONArray dataJa = resultJo.getJSONArray("data");
        for (int i = 0; i < dataJa.length(); i++) {
            JSONObject itemJo = dataJa.getJSONObject(i);
            districtIdNameMap.put(itemJo.getInt("id"), itemJo.getString("name"));
        }
    } catch (Exception e) {
        throw new RuntimeException("Init District List Error!", e);
    }
}

    public static String getCityName(int cityId) {
      String name = cityIdNameMap.get(cityId);
      if (name == null) {
        name = "未知";
      }
       return name;
     }

    public static String getDistrictName(int districtId) {
      String name = districtIdNameMap.get(districtId);
       if (name == null) {
         name = "未知";
        }
       return name;
     }
   }
```

O2O业务中常用的城市基础基本信息判断，通过静态变量一次获取缓存内存中，减少频繁的I/O读取，静态变量实现类间可共享，进程内可共享，缓存的实时性稍差。

为了解决本地缓存数据的实时性问题，目前大量使用的是结合ZooKeeper的自动发现机制，实时变更本地静态变量缓存：

美团内部的基础配置组件MtConfig，采用的就是类似原理，使用静态变量缓存，结合ZooKeeper的统一管理，做到自动动态更新缓存，如图2所示。

<img src="https://gitee.com/syllr/images/raw/master/uPic/202108182156570Dzxks.png" alt="ZK管理本地缓存流程图" style="zoom:150%;" />



> **这类缓存实现，优点是能直接在heap区内读写，最快也最方便；缺点同样是受heap区域影响，缓存的数据量非常有限，同时缓存时间受GC影响。主要满足单机场景下的小数据量缓存需求，同时对缓存数据的变更无需太敏感感知，如上一般配置管理、基础静态数据等场景。**

### Ehcache

Ehcache是现在最流行的纯Java开源缓存框架，配置简单、结构清晰、功能强大，是一个非常轻量级的缓存实现，我们常用的Hibernate里面就集成了相关缓存功能。

### Guava Cache

Guava Cache是Google开源的Java重用工具集库Guava里的一款缓存工具，其主要实现的缓存功能有：

- 自动将entry节点加载进缓存结构中；
- 当缓存的数据超过设置的最大值时，使用LRU算法移除；
- 具备根据entry节点上次被访问或者写入时间计算它的过期机制；
- 缓存的key被封装在WeakReference引用内；
- 缓存的Value被封装在WeakReference或SoftReference引用内；
- 统计缓存使用过程中命中率、异常率、未命中率等统计数据。

### Spring注解缓存

## 分布式缓存

memcached和Reids

# 缓存一致性

Cache Aside Pattern

最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。

- 读的时候，先读缓存，缓存没有的话，就读数据库，然后取出数据后放入缓存，同时返回响应。
- 更新的时候，**先更新数据库，然后再删除缓存**。
- 给缓存加一个过期时间，保证最终一致性

先更新数据库再删除缓存是因为在这种流程下发生缓存和db不一致的情况最少，但是缓存和数据库毕竟是两份数据，始终会出现缓存和db不一致的情况，所以一定要给缓存加上一个过期时间，来保证最终一致性

## 缓存设计模式

### Cache Aside Pattern

Cache aside pattern是最常用的方式，其具体逻辑如下：

失效：应用程序先从cache取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。

命中：应用程序从cache中取数据，取到后返回。

更新：先把数据存到数据库中，成功后，再让缓存失效。

为什么先更新数据库，再删除缓存 

按照排列组合当数据变更时一共有四种方式处理

1. 先更新缓存，再更新数据库

   > 无论是先更新缓存，再更新数据库，还是先更新数据库再更新缓存，在多线程并发的时候都容易发生更新丢失的问题，造成缓存和db数据不一致，可能存在缓存数据不断更新，但是没有读请求来请求数据，造成资源浪费，所以更愿意删除缓存，当有读请求时发现cache miss再通过查DB同步到缓存这种懒加载的方式

2. 先更新数据库，再更新缓存

   > 无论是先更新缓存，再更新数据库，还是先更新数据库再更新缓存，在多线程并发的时候都容易发生更新丢失的问题，造成缓存和db数据不一致，可能存在缓存数据不断更新，但是没有读请求来请求数据，造成资源浪费，所以更愿意删除缓存，当有读请求时发现cache miss再通过查DB同步到缓存这种懒加载的方式

3. 先删除缓存，再更新数据库

   > 在并发的情况下先删除缓存，线程顺序为A线程删除缓存，B线程删除缓存，A线程更新DB，B线程更新DB，当B线程删除完缓存之后如果有读操作，因为缓存被删除，cache miss，从DB中捞数据，这个时候刚好A线程更新DB完成，缓存更新成为A线程更新后的数据，但是DB最后的数据是B线程更新之后的数据，所以数据不一致
   >
   > 上面的问题可以采用延迟双删的方式解决
   >
   > - （1）先淘汰缓存
   > - （2）再写数据库（这两步和原来一样）
   > - （3）休眠1秒，再次淘汰缓存 这么做，可以将1秒内所造成的缓存脏数据，再次删除。

4. 先更新数据库，再删除缓存

   > 这种情况下依然可能会有脏数据产生
   >
   > （1）缓存刚好失效
   >
   > （2）请求A查询数据库，得一个旧值
   >
   > （3）请求B将新值写入数据库
   >
   > （4）请求B删除缓存
   >
   > （5）请求A将查到的旧值写入缓存 ok，如果发生上述情况，确实是会发生脏数据。
   >
   > **然而，发生这种情况的概率又有多少呢？**
   >
   > 发生上述情况有一个先天性条件，就是步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。
   >
   > 可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。 假设，有人非要抬杠，有强迫症，一定要解决怎么办？

   其实无论哪种方案在并发不同的时许下都会有脏数据产生，因为套用分布式中的观点redis和DB本来就是两分区，但是先更新数据库，然后删除缓存这种处理方式能够把脏数据出现的概率做到最低，或则直接用各种一致性协议（共识算法比如zab raft）来保证两个分区的一致性，所以我们选择先更新数据库，然后再删除缓存这种方法作为通用的处理方式，同时为了保证最终一致性，一定要为每个缓存数据加上过期时间。

   ### Read/Write Through Pattern

   ### 读写分离场景下的缓存一致性

   如果DB读写分离DB的同步延迟是造成数据不一致的主要原因，场景如下，A线程修改了主库数据，并且删除了缓存，这时主从同步还没有完成，B线程读取发现cache miss，到从库捞数据，捞到的数据就是脏数据

   对付这种情况解决方式主要有两种

   * 延迟删除缓存，当A线程更新了数据之后延迟一定的时间（和主从同步延迟有关，如果主从同步延迟是200ms，删除延迟就设置成250ms）再删除缓存
   * 订阅binLog，当拿到binLog之后如果是更新操作则在接受到消息之后睡一段时间然后删除缓存。

# 缓存引发的问题

## 缓存穿透

缓存穿透是指查询的数据在数据库是没有的，那么在缓存中自然也没有，所以，在缓存中查不到就会去数据库取查询，这样的请求一多，那么我们的数据库的压力自然会增大。缓存穿透可就是缓存没有数据，然后DB也没有数据，造成缓存穿透的主要原因有三个

* 批量重复请求，短时间内大量重复请求到一个缓存上，刚好这个缓存不存在，这部分请求都落在了DB上，同时DB也没有数据，造成数据一直空缺，当调用方设置了重试则可能出现这种情况（比如他出BUG了导致自己内部逻辑不停重试）
* 大量无效请求，比如我缓存的数据是1-1000的，请求1001的缓存应该被过滤

1. 如果缓存正确率低了是业务设计的问题，想办法提高缓存的正确率，毕竟衡量缓存系统设计的好不好的一个指标就是缓存命中率，如果命中率实在提不上去可以采用把空对象缓存起来的方法。当第一次从数据库中查询出来的结果为空时，我们就将这个空对象加载到缓存，并设置合理的过期时间，这样，就能够在一定程度上保障后端数据库的安全，但是牺牲了一定的缓存一致性。

2. 对付批量重复的请求可以采用缓存查询和缓存构建异步解耦的方式，流程如图：

   ![异步缓存构建流程图](https://gitee.com/syllr/images/raw/master/uPic/20210818215637JiTvcV.png)

3. 如果有很多的请求都是无效请求，则需要在请求查找缓存和DB之前先过滤掉这一部分无效的请求，比如在查询航班数据之前，先通过航线和班期数据过滤，如果没有的航班和班期数据，则不用去查询缓存直接返回空数据。或则使用布隆过滤器or位图来过滤一部分非法的请求。

还有一种应对缓存穿透的方式就是如果cache miss，先把缓存的值设置成一个特殊的值，表示缓存更新中，不可用，然后同步去从DB拿数据，等从DB中拿到数据之后再更新缓存

![同步缓存标识位](https://gitee.com/syllr/images/raw/master/uPic/20210818215713yaxGqM.png)

## 缓存击穿

缓存失效，DB上有数据，请求打到DB上，缓存穿透和缓存击穿都是缓存失效，但是缓存穿透是DB也没有数据，缓存击穿是DB有数据，缓存击穿的主要原因是因为缓存的命中率不高，一般情况下有部分缓存击穿请求落到DB是正常的业务逻辑但是有几种情况会造成大量的缓存击穿，最终导致缓存雪崩

* 大量的缓存拥有同时的过期时间，同时过期，导致大量请求打到DB（为每个缓存设置一个不同的过期时间，防止大量缓存同时过期）
* 热点数据失效，导致大量重复请求直接打到DB（可以给热点缓存不设置失效时间，或则每次更新修改失效时间不过这样会损失一部分一致性，最好的办法还是将缓存构建和缓存查询进行异步化）
* 缓存预热阶段，服务上线时，缓存内还没有数据，每个请求都会穿过缓存去访问底层数据库，如果并发大的话，很有可能在上线当天就会宕机

## 缓存雪崩

瞬时大量缓存击穿造成数据库压力激增，甚至有可能直接撑不住挂掉。然后有可能DBA会紧急重启DB，但是刚一恢复，新的请求立马又把DB打垮了，也有可能就是Redis挂了，缓存都不能用了，请求也是直接打到了DB上，然后DB也是扛不住压力，直接挂掉。再恢复，再挂掉。

雪崩的预防主要的方式其实就一个：流量控制

* 当突发流量过大时直接对请求进行限流控制，放弃一部分请求
* 更新锁机制，通过分布式锁将DB的更新做成串行的，这其实也是一种流量控制
* 缓存构建异步化（在异步的时候进行去重和流量控制）

![img](https://gitee.com/syllr/images/raw/master/uPic/20210910153844vzwwWu.jpg)

## 缓存预热

为了防止缓存雪崩就要先进行缓存预热，当缓存清空的时候可以对缓存构建进行流量控制，让缓存慢慢构建，如果是DB作为数据源那么在服务启动的时候设置钩子函数，在启动的时候预先进行缓存构建，等缓存构建完成之后再对外提供服务。
