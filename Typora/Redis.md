# 数据结构与对象

## 数据结构

Redis数据库里面的每个键值对（key-value pair）都是由对象（object）组成的。

其中：数据库键总是一个字符串对象（string object）；而数据库键的值则可以是字符串对象、列表对象（list object）、哈希对象（hash object）、集合对象（set object）、有序集合对象（sorted set object）这五种对象中的其中一种。

### 简单动态字符串（Simple Dynamic String）

Redis中主要有两种字符串，一种是C字符串，一种是Redis自己构建的SDS，在Redis里面，C字符串只会作为字符串字面量（string literal）用在一些无须对字符串值进行修改的地方，比如打印日志，在redis的数据库里面，包含字符串值的键值对在底层都是SDS实现的。

除了用来保存数据库中的字符串值之外，SDS还被用作缓冲区（buffer）：AOF模块中的AOF缓冲区，以及客户端状态中的输入缓冲区，都是由SDS实现的

#### 结构

#### redis5.0之前的结构图

<img src="https://gitee.com/syllr/images/raw/master/uPic/20210830094533uxtkSO.png" alt="没有未使用空间的SDS结构图" style="zoom:67%;" />

* free属性的值为0，表示这个SDS没有任何未使用的空间。
* len属性的值为5，表示这个SDS保存了一个五字节长的字符串。
* buf属性是一个char类型的数组，数组的前五个字节分别保存了'R'、'e'、'd'、'i'、's'五个字符，而最后一个字节则保存了空字符'\0'。

![带有未使用空间的SDS图](https://gitee.com/syllr/images/raw/master/uPic/202108300948444K4SvZ.png)

这个SDS和之前展示的SDS一样，都保存了字符串值“Redis”。这个SDS和之前展示的SDS的区别在于，这个SDS为buf数组分配了五字节未使用空间，所以它的free属性的值为5（图中使用五个空格来表示五字节的未使用空间）

#### redis5.0之后的结构图

<img src="https://gitee.com/syllr/images/raw/master/uPic/20210909080038nbza3h.jpg" alt="img" style="zoom: 33%;" />

* buf：字节数组，保存实际数据。为了表示字节数组的结束，Redis 会自动在数组最后加一个“\0”，这就会额外占用 1 个字节的开销
* len：占 4 个字节，表示 buf 的已用长度
* alloc：也占个 4 字节，表示 buf 的实际分配长度，一般大于 len。

#### SDS和传统C字符串的区别

* SDS使用len字段记录自己的长度，使用SDS而不是C字符串，可以直接获取字符串类型的长度。

* SDS不仅记录了自己的长度，还记录了可用的长度（free字段），使用拼接函数将两字符串拼接到一起的时候，可以直接判断字符串的可用长度free是否大于要拼接的字符串长度来选择是否要扩展长度，这样可以简化字符串拼接函数的操作。

* C字符串中字符串长度和内存占用量总是相对应的，SDS因为有free字段，解除了字符串长度和底层数据长度之间的关联“在SDS中，buf数组的长度不一定就是字符数量加一，数组里面可以包含未使用的字节，而这些字节的数量就由SDS的free属性记录，通过未使用空间，SDS实现了空间预分配和惰性空间释放两种优化策略

  * 空间预分配

    > 空间预分配用于优化SDS的字符串增长操作：当SDS的API对一个SDS进行修改，并且需要对SDS进行空间扩展的时候，程序不仅会为SDS分配修改所必须要的空间，还会为SDS分配额外的未使用空间

  * 惰性空间释放

    > 惰性空间释放用于优化SDS的字符串缩短操作：当SDS的API需要缩短SDS保存的字符串时，程序并不立即使用内存重分配来回收缩短后多出来的字节，而是使用free属性将这些字节的数量记录起来，并等待将来使用

* 二进制安全

  > C字符串中的字符必须符合某种编码（比如ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使得C字符串只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据。使用SDS来保存之前提到的特殊数据格式就没有任何问题，因为SDS使用len属性的值而不是空字符来判断字符串是否结束

* 兼容部分C字符串函数

### 链表（linkedlist）

C语言并没有内置链表这种数据结构，所以Redis构建了自己的链表实现

![Redis链表实现结构](https://gitee.com/syllr/images/raw/master/uPic/20210830104707b8Ax7b.png)

Redis的链表实现的特性如下

* 双端：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点的复杂度都是O（1）。
* 无环：表头节点的prev指针和表尾节点的next指针都指向NULL，对链表的访问以NULL为终点。
* 带表头指针和表尾指针：通过list结构的head指针和tail指针，程序获取链表的表头节点和表尾节点的复杂度为O（1）。
* 带链表长度计数器：程序使用list结构的len属性来对list持有的链表节点进行计数，程序获取链表中节点数量的复杂度为O（1）。
* 多态：链表节点使用void*指针来保存节点值，并且可以通过list结构的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。

### 字典

#### 结构

C语言并没有内置字典这种数据结构，因此Redis构建了自己的字典实现。

Redis的数据库就是使用字典来作为底层实现的，对数据库的增、删、查、改操作也是构建在对字典的操作之上的。

```c
typedef struct dict {
    // 类型特定函数
    dictType *type;
    // 私有数据
    void *privdata;
    // 哈希表
    dictht ht[2];
    // rehash索引，当rehash不在进行时，值为-1
    int rehashidx; /* rehashing not in progress if rehashidx == -1 */
} dict;
```

* 因为字典的键值可以是任意类型，所以dict中添加了type和privdata属性，可以实现键值类型的多态

* ht属性是一个包含两个项的数组，数组中的每个项都是一个dictht哈希表，一般情况下，字典只使用ht[0]哈希表，ht[1]哈希表只会在对ht[0]哈希表进行rehash时使用。

* rehashidx记录了rehash目前的进度，如果没有正在进行rehash，那么它的值为-1。

* dictht哈希表是真正存储数据的地方，数据结构如下

  > ```c
  > typedef struct dictht {
  >     //哈希表数组
  >     dictEntry **table;
  >     //哈希表大小
  >     unsigned long size;
  >     //哈希表大小掩码，用于计算索引值
  >     //总是等于size-1
  >     unsigned long sizemask;
  >     //该哈希表已有节点的数量
  >     unsigned long used;
  > } dictht;
  > ```
  > 
  > * table属性是一个数组，数组中的每个元素都是一个指向dict.h/dictEntry结构的指针，每个dictEntry结构保存着一个键值对。size属性记录了哈希表的大小，也即是table数组的大小，而used属性则记录了哈希表目前已有节点（键值对）的数量。sizemask属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放到table数组的哪个索引上面
  > * dictht的结构图如下![字典数据结构图](https://gitee.com/syllr/images/raw/master/uPic/20210830115037QxEnV4.png)
  > * table中使用链地址法解决hash冲突

综上所述dict的结构图如下：

![dict结构图](https://gitee.com/syllr/images/raw/master/uPic/2021083019242694ifIU.png)

#### rehash

Redis对字典的哈希表执行rehash的步骤如下

1. 为字典的ht[1]哈希表分配空间，这个哈希表的空间大小取决于要执行的操作，以及ht[0]当前包含的键值对数量（也即是ht[0].used属性的值）
2. 如果执行的是扩展操作，那么ht[1]的大小为第一个大于等于ht[0].used*2的2n（2的n次方幂）
3. 如果执行的是收缩操作，那么ht[1]的大小为第一个大于等于ht[0].used的2n（2的n次方幂）。
4. 将保存在ht[0]中的所有键值对rehash到ht[1]上面：rehash指的是重新计算键的哈希值和索引值，然后将键值对放置到ht[1]哈希表的指定位置上。
5. 当ht[0]包含的所有键值对都迁移到了ht[1]之后（ht[0]变为空表），释放ht[0]，将ht[1]设置为ht[0]，并在ht[1]新创建一个空白哈希表，为下一次rehash做准备。

##### rehash的时机

rehash的时机是通过负载因子和当前redis实例正在进行的工作来判断的

* 在负载因子小于0.1的时候自动进行收缩操作
* 服务器目前没有在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子大于等于1，执行rehash。
* 服务器目前正在执行BGSAVE命令或者BGREWRITEAOF命令，并且哈希表的负载因子大于等于5，执行rehash。

##### 渐进式rehash

当hash表中保存的数据非常的多时，如果一次rehash就把h[0]中的键值对全部rehash到h[1]，这么大的计算量会导致服务器阻塞（阻塞主线程），所以需要渐进式rehash

1. 为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。
2. 在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。
3. 在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，程序将**rehashidx**属性的值增一。
4. 随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。

因为在进行渐进式rehash的过程中，字典会同时使用ht[0]和ht[1]两个哈希表，所以在渐进式rehash进行期间，字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行。例如，要在字典里面查找一个键的话，程序会先在ht[0]里面进行查找，如果没找到的话，就会继续到ht[1]里面进行查找，诸如此类。
另外，在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作，这一措施保证了ht[0]包含的键值对数量会只减不增，并随着rehash操作的执行而最终变成空表。

### 跳跃表

和链表、字典等数据结构被广泛地应用在Redis内部不同，Redis只在两个地方用到了跳跃表，一个是在有序集合中存分值（score），另一个是在集群节点中用作内部数据结构，除此之外，跳跃表在Redis里面没有其他用途。

在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单，所以有不少程序都使用跳跃表来代替平衡树。

![跳表元素图片](https://gitee.com/syllr/images/raw/master/uPic/20210830225228ryLASp.png)

Redis的跳跃表由redis.h/zskiplistNode和redis.h/zskiplist两个结构定义，其中zskiplistNode结构用于表示跳跃表节点，而zskiplist结构则用于保存跳跃表节点的相关信息，比如节点的数量，以及指向表头节点和表尾节点的指针等等。

![Redis跳跃表](https://gitee.com/syllr/images/raw/master/uPic/20210830225911x1OICY.png)

上图展示了一个跳跃表示例,其中最左边的是 skiplist结构,该结构包含以下属性。

- header:指向跳跃表的表头节点，通过这个指针程序定位表头节点的时间复杂度就为O(1)
- tail:指向跳跃表的表尾节点,通过这个指针程序定位表尾节点的时间复杂度就为O(1)
- level:记录目前跳跃表内,层数最大的那个节点的层数(表头节点的层数不计算在内)，通过这个属性可以再O(1)的时间复杂度内获取层高最好的节点的层数。
- length:记录跳跃表的长度,也即是,跳跃表目前包含节点的数量(表头节点不计算在内)，通过这个属性，程序可以再O(1)的时间复杂度内返回跳跃表的长度。

结构右方的是四个 zskiplistNode结构,该结构包含以下属性

- 层(level):

    节点中用1、2、L3等字样标记节点的各个层,L1代表第一层,L代表第二层,以此类推。

    每个层都带有两个属性:前进指针和跨度。前进指针用于访问位于表尾方向的其他节点,而跨度则记录了前进指针所指向节点和当前节点的距离(跨度越大、距离越远)。在上图中,连线上带有数字的箭头就代表前进指针,而那个数字就是跨度。当程序从表头向表尾进行遍历时,访问会沿着层的前进指针进行。每次创建一个新跳跃表节点的时候,程序都根据幂次定律(powerlaw,越大的数出现的概率越小)随机生成一个介于1和32之间的值作为level数组的大小,这个大小就是层的“高度”。

- 后退(backward)指针：

    节点中用BW字样标记节点的后退指针,它指向位于当前节点的前一个节点。后退指针在程序从表尾向表头遍历时使用。与前进指针所不同的是每个节点只有一个后退指针，因此每次只能后退一个节点。

- 分值(score):

    各个节点中的1.0、2.0和3.0是节点所保存的分值。在跳跃表中,节点按各自所保存的分值从小到大排列。

- 成员对象(oj):

    各个节点中的o1、o2和o3是节点所保存的成员对象。在同一个跳跃表中,各个节点保存的成员对象必须是唯一的,但是多个节点保存的分值却可以是相同的:分值相同的节点将按照成员对象在字典序中的大小来进行排序,成员对象较小的节点会排在前面(靠近表头的方向),而成员对象较大的节点则会排在后面(靠近表尾的方向)。

  ![zskiplistNode](https://gitee.com/syllr/images/raw/master/uPic/20210830230021WeMni7.png)

  #### 跳表操作

  ##### 新增节点

  比如我们需要插入23这个节点，首先在链表中找到23这个节点的插入位置（这个和一般的链表的插入一样），然后确定23这个节点的层次是多少，可以用一个范围内随机数，Redis的做法是都根据幂次定律(powerlaw,越大的数出现的概率越小)随机生成一个介于1和32之间的值作为level数组的大小,这个大小就是层的“高度”（如图23生成的高度为3），插入了之后需要构建23节点的每一个高度的索引（即把23这个节点的第一层，第二层，第三层的前后节点赋值）

  ![跳表新增节点](https://gitee.com/syllr/images/raw/master/uPic/20210830230328SzDxTA.png)

  ##### 查找

  我们从虚拟头节点“Head”的最高maxLevel出发，如果当前节点的索引指向的下一个节点不为空且值比我们寻找的目标值小，就“向右移动”指针，否则就“向下移动”指针，直至我们找到该元素返回 true 或找不到该元素返回 false。

  ![跳表查找过程](https://gitee.com/syllr/images/raw/master/uPic/202108302302046e72Hh.png)

  ##### 删除

![删除节点](https://gitee.com/syllr/images/raw/master/uPic/20210830230809ZhTzJX.png)

删除节点的过程如图所示，首先查找到23这个节点的位置（和普通的链表的过程一样），然后重新维护23这个节点每个高度的前后指针。

### 整数集合（intset）

整数集合（intset）是Redis用于保存整数值的集合抽象数据结构，它可以保存类型为int16_t、int32_t或者int64_t的整数值，并且保证集合中不会出现重复元素。

```c
typedef struct intset {
  // 编码方式
    uint32_t encoding;
  // 集合包含的元素数量
    uint32_t length;
  // 保存元素的数组    
  int8_t contents[];
} intset;

```

* contents数组是整数集合的底层实现：整数集合的每个元素都是contents数组的一个数组项（item），**各个项在数组中按值的大小从小到大有序地排列，并且数组中不包含任何重复项**。
* length属性记录了整数集合包含的元素数量，也即是contents数组的长度。
* 虽然intset结构将contents属性声明为int8_t类型的数组，但实际上contents数组并不保存任何int8_t类型的值，contents数组的真正类型取决于encoding属性的值：
  * 如果encoding属性的值为INTSET_ENC_INT16，那么contents就是一个int16_t类型的数组，数组里的每个项都是一个int16_t类型的整数值
  * 如果encoding属性的值为INTSET_ENC_INT32，那么contents就是一个int32_t类型的数组，数组里的每个项都是一个int32_t类型的整数值

![image-20210831090657758](/Users/yutao/Library/Application Support/typora-user-images/image-20210831090657758.png)

#### 升级

contents数组中的元素都是一样的类型（C的数组要求数组中的所有元素的类型都一样），所以如果contents中有1，2，3，65535这四个元素，因为65535是32位整数，1，2，3这三个元素也会以32位的形式来存，如果新插入来的数据是64位的，则该数组中所有的元素都变成64位。

#### 查找

当需要查找一个元素的时候，通过enconding字段可以知道数组中每个元素的大小，通过length可以知道数组的长度，同时因为数组是有序的，所以可以很方便的使用二分查找法来进行查找。

#### 降级

inteset不会降级

### 压缩列表（ziplist）

压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个`字节数组`或者一个`整数值`。

压缩列表列表节省内存的主要原因是每个元素的长度都不一样，不用像数组一样每个元素都是同一种类型，避免了空间的浪费，但是数组是一片连续的内从空间可以很好的利用cpu的缓存访问数据，速度上有天然的优势，所以为了加快遍历的速度，redis在压缩列表的每个节点中加入了一个length属性。

压缩列表查询数据是通过遍历的方式，因为压缩列表的entry中加入了length属性可以像数组一样使用连续的内存（走了page cache）快速的遍历，同时也可以存储不同的类型的数据，节省了内存空间。

![压缩列表数据结构](https://gitee.com/syllr/images/raw/master/uPic/2021083110492729bS2I.png)

![压缩列表示例](https://gitee.com/syllr/images/raw/master/uPic/202108311050023BQf7D.png)

entry的数据结构如图

![压缩列表entry数据结构](https://gitee.com/syllr/images/raw/master/uPic/20210831105050HhYyOk.png)

* 节点的 previous_entry_length属性以字节为单位,记录了压缩列表中前一个节点的长度。 previous_entry_length属性的长度可以是1字节或者5字节
  * 如果前一节点的长度小于254字节,那么 previous_entry_length属性的长度为1字节，前一节点的长度就保存在这一个字节里面。
  * 如果前一节点的长度大于等于254字节,那么 previous_entry_length属性的长度为5字节:其中属性的第一字节会被设置为0xFE(十进制值254),而之后的四个字节则用于保存前一节点的长度。
* 节点的encoding属性记录了节点的content属性所保存数据的类型以及**长度**。
  * 一字节、两字节或者五字节长,值的最高位为00、01或者10的是字节数组编码这种编码表示节点的 content属性保存着字节数组,数组的长度由编码除去最高两位之后的其他位记录。
  * 一字节长,值的最高位以11开头的是整数编码:这种编码表示节点的content属性保存着整数值,整数值的类型和长度由编码除去最高两位之后的其他位记录。
* 节点的content属性负责保存节点的值,节点值可以是一个字节数组或者整数,值的类型和长度由节点的encoding属性决定。

#### 级联更新

`prevlous_entry_length`的长度变化会导致一个问题，那就是级联更新。

*当前一个 entry 的长度在 254 字节以内的时候，这个属性用一个字节来记录。否则就会用 5 个字节来记录。*

那么我们设想一个极端的场景，在这个 ziplist 内部，所有的节点的长度都是 253 字节，也就意味着所有节点的`prevlous_entry_length`属性都是一个字节。此时，我们给压缩列表最前端插入一个大于 254 字节的节点，那么此时原来的第一个节点的`prevlous_entry_length`属性会从 1 个字节变成 5 个字节，这个节点的总长度也就来到了 257 字节，大于 254 字节，那么下一个节点（原来的第二个节点）的`prevlous_entry_length`属性也会变成 5 个字节，这又会导致下一个节点的变化。... 引起连锁变化，所有节点的`prevlous_entry_length`值都需要更新一遍。

级联更新的时间复杂度很差，最多需要进行 N 次空间的重分配，每次空间的重分配最差需要 O(N), 所以级联更新的时间复杂度最差是 O(N2)，与新增节点相似，删除节点也有可能会造成级联更新的情况。

### 快速列表（quicklist）

redis的linkedlist和ziplist都是利用链表存储，附加空间相对太高（需要保存每个节点的前后指针），会加剧内存的碎片化，影响内存的管理效率，因此Redis3.2版本开始对列表数据结构进行了改造，列表对象改成了用快速列表实现。

![快速列表结构图](https://gitee.com/syllr/images/raw/master/uPic/20210831131545lOt7Qk.png)

```c
typedef struct quicklistNode {
    struct quicklistNode *prev; //上一个node节点
    struct quicklistNode *next; //下一个node
    unsigned char *zl;            //保存的数据 压缩前ziplist 压缩后压缩的数据
    unsigned int sz;             /* ziplist size in bytes */
    unsigned int count : 16;     /* count of items in ziplist */
    unsigned int encoding : 2;   /* RAW==1 or LZF==2 */
    unsigned int container : 2;  /* NONE==1 or ZIPLIST==2 */
    unsigned int recompress : 1; /* was this node previous compressed? */
    unsigned int attempted_compress : 1; /* node can't compress; too small */
    unsigned int extra : 10; /* more bits to steal for future usage */
} quicklistNode;
```

- prev: 指向链表前一个节点的指针。
- next: 指向链表后一个节点的指针。
- zl: 数据指针。如果当前节点的数据没有压缩，那么它指向一个ziplist结构；否则，它指向一个quicklistLZF结构。
- sz: 表示zl指向的ziplist的总大小（包括`zlbytes`, `zltail`, `zllen`, `zlend`和各个数据项）。需要注意的是：如果ziplist被压缩了，那么这个sz的值仍然是压缩前的ziplist大小。
- count: 表示ziplist里面包含的数据项个数。这个字段只有16bit。
- encoding: 表示ziplist是否压缩了（以及用了哪个压缩算法）。目前只有两种取值：2表示被压缩了（而且用的是LZF压缩算法），1表示没有压缩。
- container: 是一个预留字段。本来设计是用来表明一个quicklist节点下面是直接存数据，还是使用ziplist存数据，或者用其它的结构来存数据（用作一个数据容器，所以叫container）。但是，在目前的实现中，这个值是一个固定的值2，表示使用ziplist作为数据容器。
- recompress: 当我们使用类似lindex这样的命令查看了某一项本来压缩的数据时，需要把数据暂时解压，这时就设置recompress=1做一个标记，等有机会再把数据重新压缩。
- attempted_compress: 这个值只对Redis的自动化测试程序有用。我们不用管它。
- extra: 其它扩展字段。目前Redis的实现里也没用上。

#### 插入

quicklist可以选择在头部或者尾部进行插入(`quicklistPushHead`和`quicklistPushTail`)，而不管是在头部还是尾部插入数据，都包含两种情况：

- 如果头节点（或尾节点）上ziplist大小没有超过限制（即`_quicklistNodeAllowInsert`返回1），那么新数据被直接插入到ziplist中（调用`ziplistPush`）。
- 如果头节点（或尾节点）上ziplist太大了，那么新创建一个quicklistNode节点（对应地也会新创建一个ziplist），然后把这个新创建的节点插入到quicklist双向链表中。

![快速列表插入流程](https://gitee.com/syllr/images/raw/master/uPic/20210831131724sIWtHG.png)

也可以从任意指定的位置插入。`quicklistInsertAfter`和`quicklistInsertBefore`就是分别在指定位置后面和前面插入数据项。这种在任意指定位置插入数据的操作，要比在头部和尾部的进行插入要复杂一些。

- 当插入位置所在的ziplist大小没有超过限制时，直接插入到ziplist中就好了；
- 当插入位置所在的ziplist大小超过了限制，但插入的位置位于ziplist两端，并且相邻的quicklist链表节点的ziplist大小没有超过限制，那么就转而插入到相邻的那个quicklist链表节点的ziplist中；
- 当插入位置所在的ziplist大小超过了限制，但插入的位置位于ziplist两端，并且相邻的quicklist链表节点的ziplist大小也超过限制，这时需要新创建一个quicklist链表节点插入。
- 对于插入位置所在的ziplist大小超过了限制的其它情况（主要对应于在ziplist中间插入数据的情况），**则需要把当前ziplist分裂为两个节点**，然后再其中一个节点上插入数据。

#### 查找

* 通过index查找

  > 只需要先根据我们每个node的个数，从而找到对应的ziplist，调用ziplist的index就能成功找到

* 通过数据查找

  > 两层遍历

#### 删除

在区间删除时，会先找到 start 所在的 quicklistNode，计算删除的元素是否小于要删除的 count，如果不满足删除的个数，则会移动至下一个 quicklistNode 继续删除，依次循环直到删除完成为止。

quicklistDelRange 函数的返回值为 int 类型，当返回 1 时表示成功的删除了指定区间的元素，返回 0 时表示没有删除任何元素

### 紧凑列表（ListPack）

![listpack结构](https://gitee.com/syllr/images/raw/master/uPic/20210831215850Y6cI3K.jpg)

如图：**listpack** 的定义和ziplist基本一致，只是去掉了 **zltail_offset** 属性。

让我们回想一下，ziplist 中用这个属性做什么？用来方便的找到最后一个节点，然后方便进行反向的遍历。新的 listpack 是怎么解决这两个问题的？

* 找到最后一个节点
* 反向遍历

listpack节点定义如下

```c
int<var> encoding;
optional byte[] content;
int<var> length;
```

![listpack entry结构](https://static001.geekbang.org/resource/image/60/27/60833af3db19ccf12957cfe6467e9227.jpg?wh=2000x786)

相比于 ziplist 的定义，它有两点改动：

1. 记录的长度不再是前一个节点的长度，而是自己的长度。
2. 将记录自己的长度entry-len放到了节点的尾部。
   1. entry-len 每个字节的最高位，是用来表示当前字节是否为 entry-len 的最后一个字节，这里存在两种情况，
   2. 分别是：最高位为 1，表示 entry-len 还没有结束，当前字节的左边字节仍然表示 entry-len 的内容；
   3. 最高位为 0，表示当前字节已经是 entry-len 最后一个字节了。而 entry-len 每个字节的低 7 位，则记录了实际的长度信息。
   4. entry-len 每个字节的低 7 位采用了大端模式存储，也就是说，entry-len 的低位字节保存在内存高地址上。

这样做的好处是：

1. 不再需要 zltail_offset 属性也可以快速定位到最后一个节点。用`listpac的总长度-最后一个节点的长度`.
2. 每个节点记录自己的长度，当本节点的值发生了改变，只需要更改自己的长度即可。不再需要更改别的节点的属性，也就彻底的解决掉了级联更新问题。

listpack 是 Redis 设计用来取代掉 ziplist 的数据结构，它通过每个节点记录自己的长度，且放在节点的尾部，来彻底解决掉了 ziplist 存在的级联更新的问题，listpack 在 5.0 版本引入，但是由于 ziplist 在 Reids 内部的使用太过于广泛，有一些兼容问题，我们可以预见这将是一个逐步的替换过程。同样在 5.0 版本引入的 Stream 数据结构中，就使用了 listpack 而不是 ziplist.

## 对象

Redis一共有7中底层的数据结构：简单动态字符串（SDS），双端链表，字典，压缩列表，整数集合，快速列表，紧凑列表；

Redis并没有直接使用这些数据结构来实现键值对数据库，而是基于这些数据结构创建了一个对象系统，这个系统包含字符串对象、列表对象、哈希对象、集合对象和有序集合对象这五种类型的对象，每种对象都用到了至少一种前面所介绍的数据结构。

![redis底层数据结构关系](https://gitee.com/syllr/images/raw/master/uPic/202108311617379LlScL.png)

Redis使用对象来表示数据库中的键和值，每次当我们在Redis的数据库中新创建一个键值对时，我们至少会创建两个对象，一个对象用作键值对的键（键对象），另一个对象用作键值对的值（值对象）。

Redis中的每个对象都由一个redisObject结构表示，该结构中和保存数据有关的三个属性分别是type属性、encoding属性和ptr属性

```c
/*
 * Redis 对象
 */
typedef struct redisObject {

    // 类型
    unsigned type:4;

    // 对齐位
    unsigned notused:2;

    // 编码方式
    unsigned encoding:4;

    // LRU 时间（相对于 server.lruclock）
    unsigned lru:22;

    // 引用计数
    int refcount;

    // 指向对象的值
    void *ptr;

} robj;
```

* type 记录了对象的类型
* encoding：encoding 表示 ptr 指向的具体数据结构，即这个对象使用了什么数据结构作为底层实现
* ptr 指针：指向对象的底层实现数据结构

### RedisDB

Redis中存在“数据库”的概念，该结构由redis.h中的redisDb定义。我们知道Redis提供string、list、set、zset、hash、stream五种数据类型的存储，在Redis运行时，服务器中会存在许多的不同类型的对象，当我们需要操作某个具体的对象时，首先需要快速定位到该对象。比如往一个list中插入一个元素，第一步先要在众多对象实例中找到该list，然后再进行插入操作。如何快速获取指定对象呢？在我们前面介绍过的基础数据结构中字典dict就可以实现该功能。

如果是单机的redis实例默认有16个redisDB对象，即16个数据库，客户端每次连接都会连接相同的数据库，默认为DB0，**Redis集群下只有db0，不支持多db**

具体的做法是：Redis每生成一个对象实例都需要关联一个key，利用dict保存key和对象实例之间的映射关系。这样就可以在O（1）的时间复杂度下根据key找到对应的对象，而Redis中的“数据库”redisDb就是对上述过程的实现。

```c
/* Redis数据库结构体 */
typedef struct redisDb {
    // 数据库键空间，存放着所有的键值对（键为key，值为相应的类型对象）
    dict *dict;                 
    // 键的过期时间
    dict *expires;              
    // 处于阻塞状态的键和相应的client（主要用于List类型的阻塞操作）
    dict *blocking_keys;       
    // 准备好数据可以解除阻塞状态的键和相应的client
    dict *ready_keys;           
    // 被watch命令监控的key和相应client
    dict *watched_keys;         
    // 数据库ID标识
    int id;
    // 数据库内所有键的平均TTL（生存时间）
    long long avg_ttl;         
} redisDb;
```

1. redisDb中的dict *dict成员就是将key和具体的对象（可能是string、list、set、zset、hash中任意类型之一）关联起来，存储着该数据库中所有的键值对数据。该字段又称为键空间key space。
2. expires成员用来存放key的过期时间。
3. id成员是数据库的编号，以整型表示。（集群模式下只有DB0）

#### 键空间

键空间实际就是一个字典dict结构，存储着该库所有的键值对数据，其中字典dict的key是一个字符串对象，字典dict的值是一个RedisObject，其类型可能是string、list、set、zset、hash中任意类型之一。弄明白键空间的底层结构，我们不难画出其存储结构：

![键空间结构图](https://gitee.com/syllr/images/raw/master/uPic/20210901122754j2iYQ1.jpeg)

#### expeires

expires字段也是一个字典dict结构，字典的键为key，值为该key对应的过期时间，过期时间为long long类型整数，是以毫秒为单位的过期 UNIX 时间戳。我们可以看看setExpire函数加以佐证，该函数的作用是为指定key设置过期时间。

redisDb中的db->dict和db->expires两个字典是共享同一个key的，即它们都指向了同一个key字符串，而不是将同一个key复制两份。这点利用指针很容易实现。

**删除过期key**：对于过期的key，Redis负责将该key删除，为了提高运行效率，Redis采取这么一种处理方式：只有当真正要访问该key时才检查该key是否过期。如果过期就删除，如果没过期就正常访问。通常我们把这种只有在访问时才检查过期的策略叫做“惰性删除”。

### 字符串对象

字符串对象的编码可以是int、raw或者embstr。

* 如果一个字符串对象保存的是整数值，并且这个整数值可以用long类型来表示，那么字符串对象会将整数值保存在字符串对象结构的ptr属性里面（将void*转换成long），并将字符串对象的编码设置为int。

* embstr编码是专门用于保存短字符串的一种优化编码方式，这种编码和raw编码一样，都使用redisObject结构和sdshdr结构来表示字符串对象，但raw编码会调用两次内存分配函数来分别创建redisObject结构和sdshdr结构，而embstr编码则通过调用一次内存分配函数来分配一块连续的空间，空间中依次包含redisObject和sdshdr两个结构，因为redis没有为embStr编码的字符串对象编写任何的修改程序，所以embstr事实上是只读的，每次需要修改的embstr的时候都会把这个对象转换为raw编码![embstr结构](https://gitee.com/syllr/images/raw/master/uPic/20210901134812artZUw.png)

  >  embstr编码的字符串对象在执行命令时，产生的效果和raw编码的字符串对象执行命令时产生的效果是相同的，但使用embstr编码的字符串对象来保存短字符串值有以下好处：
  >
  > * embstr编码将创建字符串对象所需的内存分配次数从raw编码的两次降低为一次。
  > * 释放embstr编码的字符串对象只需要调用一次内存释放函数，而释放raw编码的字符串对象需要调用两次内存释放函数。
  > * 因为embstr编码的字符串对象的所有数据都保存在一块连续的内存里面，所以这种编码的字符串对象比起raw编码的字符串对象能够更好地利用缓存带来的优势。

* raw编码是当存储的字符串比较大的时候使用的编码，和embstr编码不同的是，因为需要存储的数据比较大，所以raw编码的redisObject结构和sdshdr结构不是连续的，需要分别分配内存。

#### 编码的转换

Redis没有为embstr编码的字符串对象编写任何相应的修改程序（只有int编码的字符串对象和raw编码的字符串对象有这些程序），所以embstr编码的字符串对象实际上是只读的。当我们对embstr编码的字符串对象执行任何修改命令时，程序会先将对象的编码从embstr转换成raw，然后再执行修改命令。因为这个原因，embstr编码的字符串对象在执行修改命令之后，总会变成一个raw编码的字符串对象。

### 列表对象

在老版本的redis中列表对象有两种编码：ziplist或者linkedlist，在redis4.0之后引入了新的数据结构quickList，新版本的redis对象列表只有quicklist这一种编码；

在老版本中只有当列表对象中的所有元素的长度都小于一定的数值，并且列表所保存的元素个数小于一定的数值时才会使用ziplist编码，原因是因为只有在数据量比较小的时候采用ziplist这种连续的数据结构速度会比较好

新的版本采用quicklist之后结合了ziplist和linkedlist的优点，不需要根据数据量的大小来切换编码方式。

### 哈希对象

哈希对象的编码方式有ziplist和dict两种，当哈希对象存储的键值对数量小于一定数量时，并且键值对的字符串的长度都小于一定的长度的时候，会采用ziplist编码，大于这个数量时采用dict编码

* 采用ziplist编码时，每存储一个键值对ziplist就使用两个连续的entry分别存储键对象和值对象，保存键的节点在前面，保存值的节点在后面
  * 先添加的键值对会被放在压缩列表的表头方向，后来添加到哈希对象中的键值对会被放在压缩列表的表尾方向
  * 采用ziplist编码时要通过键查询的方式就是直接遍历压缩列表（因为数据量比较小，而且还是连续缓存，可以走page cache，所以效率很高，平均1000个entry的效率和dict差不多）

### 集合对象

集合对象的编码方式有intset和dict两种，当集合对象中所有的元素都是整数值，同时集合对象中的元素个数不超过配置的时候使用intset编码，其他情况使用dict编码

### 有序集合对象

有序集合对象的编码方式有ziplist和skiplist两种（当有序集合对象使用skiplist编码时，底层的数据结构不仅仅使用了skiplist，还同时使用了**dict**）

和别的对象一样有序集合对象在数据量比较小的时候使用ziplist编码，当使用ziplist编码时

* 集合中的每个元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员（member），第二个节点保存元素的分值（scrore）
* ziplist中的集合元素按照分值从小到大排列

当使用skiplist编码时其实在底层使用了一个zset结构作为实现，zset结构，一个zset结构同时包含了一个skiplist和一个dict

```c
typedef struct zset {
    zskiplist *zsl;
    dict *dict;
} zset;
```

* zsl在zset中的作用：zset结构中的zsl跳跃表按分值从小到大保存了所有集合元素，每个跳跃表节点都保存了一个集合元素：跳跃表节点的object属性保存成了元素的成员（member），跳跃表节点的score保存了元素的分数（score），通过这个跳跃表，程序可以对有序集合做范围操作。

* dict在zset中的作用：zset中的dict字典为有序集合创建了一个从成员到分值的映射，字典中的每一个键值对都保存了一个集合元素，字典的键保存了元素的成员，字典的值则保存了元素的分值，通过这个字典就可以用O(1)的复杂度找到给定成员的分值。

### Stream对象

Redis5.0带来了Stream对象，主要是用来实现消息队列，基于redis的消息队列的实现有很多种，比如

* PUB/SUB，订阅/发布模式

  > ![redis发布/订阅模式实现消息队列](https://gitee.com/syllr/images/raw/master/uPic/20210901150115ll4I7K.jpg)
  >
  > 发布订阅模式从名字就可以看出，可以实现多个消费者或者多个消费者组订阅主题的功能，可以让一个消息被多个消费者或者消费者组消费，因为redis的PUB/SUB模式是通过推送消息的方法投递消息到消费者的，即每次redis收到新消息，就把新的消息推送给所有订阅这个主题的消费者redis的发布和订阅是**fire and forget**的模式，这个功能是完全基于内存的，Redis服务器在中间完全充当转发消息的作用不会将消息持久化，所以缺点也很明显。
  >
  > * 消费者只能接收到实时的消息，如果消费者下线，再上线，那么掉线期间的所有消息都会丢失
  > * 如果redis服务器宕机那么还没有发出的消息也会丢失
  > * 因为redis服务器是直接转发消息到每个消费者的，所有在redis的服务器中保存着每个消费者的缓存，每次消息以来无论消费者状态如何，都会直接把消息发送到消费者的发送缓存区，然后再发送到消费者，如果这个消费者的消费能力比较低，造成发送缓存区溢出，丢弃的数据消费者也无法消费，而且如果发送缓冲区如果长时间处于满的状态，redis服务器会强行断掉和消费者的连接，相当于踢掉这个消费者。

* 基于列表对象的LPUSH+BRPOP的实现

  > ![基于队列的实现](https://gitee.com/syllr/images/raw/master/uPic/20210901145521auGGGD.jpg)
  >
  > * 生产者使用LPUSH发布消息
  > * 消费者使用BRPOP拉取消息（BRPOP命令如果在队列没有消息的时候执行会阻塞）
  >
  > 这种模式有两个很严重的问题
  >
  > * 不支持重复消费：消费者拉取消息之后，消息就从队列中删除了，无法再次被其他消费者再次消费
  > * 消息丢失：消费者拉取到消息之后，如果发生异常宕机，这条消息就丢失了（还是因为消息一旦被拉取，消息就会从队列中删除）
  > * 消费者无法发送消费成功的ack消息给队列，消费失败无法重试

![redis stream](https://gitee.com/syllr/images/raw/master/uPic/20210901152440NjlttY.jpg)

基于上述描述，redis提出了一种新的数据结构Stream用来实现消息队列，新的stream相对于以前的实现方式，其中最大的区别就是加入了XACK机制，在消费者消费完消息之后发送XACK给Redis服务器，标志着这条消息已经被消费，如果消费者没有发送这条消息的XACK，就说明这条消息没有被消费者消费，那么Redis服务器就会保留这条消息，等接收到这条消息的所有的消费者的XACK之后在删除这条消息，这样也让steam有了持久化的能力，可以把没有消费的消息持久化到磁盘中，也是因为有了可以暂时保存消息的能力，所以可以把消费发送给不同的消费者，因为仅仅是被一个消费者消费了之后这个消息是不会被删除的。要所有订阅了这个消息的消费者组都消费了这个消息之后发送了XACK这个消息才会被删除。

Stream也提供了可以阻塞的读取方式

基于XACK实现了Pending（等待列表），消息转移，死信消息这些功能

* Pending（等待列表）：消费者拉取了消息之后，在这个消费者发送该消息的XACK之前，通过XPENDING命令可以查找当前每个消费者的待消费消息信息
* 消息转移：如果某个消费者长时间没有发送某条消息的XACK，则可以使用XCLAIM命令把这个消费者的超过时间没有回复XACK的消息转移到别的消费者去消费
* 死信：当一个消息被消息转移很多次，就会被当作死信，被删除

### 类型检查与命令多态

#### 类型检查

Redis用于操作键上的命令基本可以分为两种

* 可以对任何类型的键执行，比如DEL命令，EXPIRE命令，RNAME命令，TYPE命令，OBJECT命令
* 只能对特定键执行的命令
  * SET，GET，APPEND，STRLEN命令等只能对字符串执行
  * HDEL，HSET，HGET，HLEN等命令只能对哈希执行
  * RPUSH，LPOP，LINSERT，LLEN，等只能对列表键执行
  * SADD，SPOP，SINTER，SCARD等只能对集合键执行
  * ZADD，ZCAED，ZRANK，ZSCORE等只能对有序键执行

在执行一个特定类型的命令之前Redis首先会检查输入键的类型是否正确，然后在决定是否执行命令，类型特定命令所进行的检查是通过redisObject结构的type属性实现的。

#### 多态命令

Redis还会根据值对象的编码方式，选择正确的命令实现代码来执行命令，比如在执行HDEL命令时，Redis会根据哈希对象的encoding字段判断该使用ziplist的删除方法，还是dict的删除方法。

### 内存回收

因为C语言并不具备自动内存回收的功能，所以Redis在自己的对象系统中构建了一个引用计数技术来实现内存回收

每个对象的引用计数信息由redisObject的结构的refcount属性记录

对象的引用计数信息会随着对象的使用状态而不断变化

* 在创建一个新的对象时，引用计数的值会被初始化为1
* 当对象被一个新程序使用时，它的引用计数值会被加一
* 当对象不在被一个程序使用时，它的引用计数值会被减一
* 当对象的引用计数变为0时，对象所占用的内存会被释放

### 整数字符串对象共享

目前来说redis在初始化服务器的时候，创建了一万个字符串对象，这些对象包含了从0到9999所有整数值，服务器中的所有0到9999的字符串对象都是这写对象的引用

### LRU属性

RedisObject中包含的LUR属性记录了对象最后一次被程序访问的时间，当程序内存吃紧的时候redis会把LRU属性最老的数据持久化到磁盘上并且释放该对象的内存

### 读写键空间时的维护操作

当使用Redis命令对数据库进行读写时，服务器会进行一些额外的维护操作

* 在读取一个键之后（读操作和写操作都要对键进行读取），服务器会根据键是否存在来更新服务器中的键空间命中次数和键空间不命中次数
* 在读取一个键之后（读操作和写操作都要对键进行读取），服务器会更新键的LRU
* 如果服务器在读取一个键时（读操作和写操作都要对键进行读取），发现该键已经过期，那么服务器先删除这个过期键，在执行别的操作（redis的过期策略有三种，惰性删除是其中一种）
* 如果修改了某个键，会将这个键标记为dirty，从而让事务程序注意到这个键已经被修改过，每次以后每次修改该键的时候dirty计数器都会加一

### 过期键的删除

* 定时删除：利用job定时删除过期字典中的过期的所有数据
* 惰性删除：等访问一个键的时候发现这个键已经过期才删除
* 定期删除：Redis 默认会每秒进行十次过期扫描（100ms一次），过期扫描不会遍历过期字典中所有的 key，而是采用了一种简单的贪心策略。
  * 从过期字典中随机 20 个 key；
  * 删除这 20 个 key 中已经过期的 key；
  * 如果过期的 key 比率超过 1/4，那就重复步骤 1；

redis默认采用的是惰性删除和定期删除结合的模式，因为定时删除可能会阻塞cpu主线程。

#### AOF，RDB和复制功能对过期键的处理

##### RDB

在执行SAVE命令或则BGSAVE命令创建一个新的RDB文件时，程序会对数据库中的键进行检查，已过期的键不会被保存到新创建的RDB文件中。

在载入RDB文件的时候如果是主服务器只会载入未过期的键，如果是从服务器则会载入所有的键

##### AOF

当过期键被惰性删除或则定期删除之后，程序回向AOF文件追加一条DEL命令，来显式的记录该键已经被删除，举个例子，如果客户端使用

GET message命令，试图访问过期的message键，那么服务器将执行以下三个动作：

* 从数据库删除message键
* 追加一条DEL message命令到AOF文件
* 向执行GET命令的客户端返回空回复

在执行AOF重写的过程中，程序会对数据库中的键进行检查，已过期的键不会被保存到重写的AOF文件中。

##### 复制

当服务器运行在复制模式下，从服务器的过期删除动作由主服务器控制：

* 主服务器删除一个过期键之后，会显式的地向所有从服务器发送一个DEl命令，告知从服务器删除这个键
* 从服务器在执行客户端发送的读命令时，即使碰到过期键也不会将过期键删除，而是继续向处理未过期键一样处理过期键
* 从服务器只有在接收到主服务器发来的DEL命令之后，才会删除过期键

通过主服务器统一的控制从服务器来删除过期键，可以保证主从的数据一致性。

### 数据库通知（键空间通知）

redis的通知功能就是发布/订阅功能客户端通过subscribe命令来订阅一个键的事件，主要有两种事件

* 某个键执行了什么命令（比如message这个键的新增，删除，过期）这被称之为键空间通知
* 某个命令被什么键执行了（比如哪些键执行了删除命令），这被称之为键事件通知

可用通过设置让redis数据库默认发送键空间通知或则键事件通知

# 持久化

## RDB持久化

RDB持久化可以将Redis在内存中的数据库状态保存到磁盘里面，避免数据意外丢失，RDB持久化可以手动执行，也可以根据服务器配置选项定期执行，该功能可以将某个时间点上的数据库状态保存到一个RDB文件中。RDB文件是一个经过压缩的二进制文件，通过该文件可以还原生成RDB文件时的数据库状态。

<img src="https://gitee.com/syllr/images/raw/master/uPic/20210902085335tXLbjx.png" alt="通过RDB文件备份过程" style="zoom:50%;" />

### RDB文件的创建和载入

Redis使用SAVE和BGSAVE两个命令创建RDB文件

* SAVE命令会阻塞Redis服务进程，直到RDB文件创建完毕为止

* BGSAVE命令会fork出一个子进程，然后由这个子进程负责创建RDB文件（fork出子进程的时候并不会复制主进程的内存，而是利用了linux内核写时复制的特点，只有在主线程的内存页要被修改之时，才会把主线程的内存复制给子进程）

  > fork采用操作系统提供的写实复制(Copy On Write)机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小
  >
  > fork出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，**所以在Redis机器上需要关闭Huge Page机制**。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。
  >
  > 当单机的redis的内存太大的时候，SAVE命令和BGSAVE命令执行的fork函数会长时间阻塞主线程，所以单个redis实例的内存不宜设置的太大，一般8G 12G就行了

### dirty计数器和lastsave

* dirty计数器：dirty计数器记录距离上一次成功执行SAVE命令或者BGSAVE命令之后，服务器对数据库状态（所有数据库的状态）进行了多少次修改（包括写入，删除，更新等操作）。
* lastsave属性：一个unix时间戳，记录了服务器上一次成功执行SAVE或则BGSAVE命令的时间。

### RDB文件结构

![RDB文件结构](https://gitee.com/syllr/images/raw/master/uPic/202109021259566YjJth.png)

* 最前面的REDIS是固定编码，redis在读取RDB文件时会检测文件是不是以“REDIS为开头”，以确定读取的是RDB文件

* db_version记录的是RDB文件的版本号，只有redis的版本和RDB文件的版本兼容才能读取RDB文件。

* databases包含着零个或者任意多个数据库，以及各个数据库中的键值对数据。

  > ![保存了两个数据库的RDB文件](https://gitee.com/syllr/images/raw/master/uPic/20210902133604zDIqLV.png)

每个非空数据库在RDB文件中的都分为SELECTDB，db_number，key_value_pairs三个部分

![RDB文件中数据库的组成](https://gitee.com/syllr/images/raw/master/uPic/20210902133814FdRzA3.png)

* SELECTDB常量的长度为一字节，当读入程序读取到这个值的时候，就知道接下来要读入的是一个数据库号码。

* db_number存储的是数据库号码。

* key_value_pairs保存了数据库中所有键值对数据，如果键值对带有过期时间，那么过期时间也会和键值对一起保存

  * 不带过期时间的键值对在RDB文件中由TYPE，key，value三部分组成

    > ![不带过期时间键值对结构](https://gitee.com/syllr/images/raw/master/uPic/20210902134154u3wVoQ.png)

  * 带有过期时间的键值对相比于不带过期时间的键值对多了EXPIRETIME_MS，ms两个字段

    > ![带有过期时间键值对结构](https://gitee.com/syllr/images/raw/master/uPic/20210902134440NtcMhI.png)

TYPE是一个枚举类型，表示了当前键值对中值的对象类型和编码类型，读取程序根据不同的编码类型决定怎么读取值对象。

## AOF持久化

与RDB持久化通过保存数据库中的键值对的二进制数据不同，AOF（append only file）持久化是通过保存Redis服务器所执行的写命令来记录数据库状态的。

![AOF持久化过程](https://gitee.com/syllr/images/raw/master/uPic/20210902134931KjdR0O.png)

被写入AOF文件的所有命令都是以Redis的命令请求协议格式保存的（也就是说都是文本）可以直接打开。

> RDB存储的键值对的二进制数据，AOF存储的是写命令文本（这个文本并不是redis直接命令的文本，而是写命令的redis协议的文本）

AOF持久化功能的实现可以分为三个步骤

* 命令追加（append）
* 文件写入
* 文件同步

当AOF持久化功能打开的时候，服务器在执行完一个写命令后，会以协议格式将被执行的命令追加到服务器的aof_buf，aof_buf写入磁盘的时机由appendfsync这个参数控制，appendfsync一共有三种配置

* always：每次修改键时将aof_buf的所有内容写入并同步到AOF文件
* everysec（默认，推荐）：每一秒钟保存一次
* no：不保存，当redis被关闭或则aof_buf缓冲区满了才会把数据写入磁盘

AOF文件载入与数据还原

![AOF文件载入过程](https://gitee.com/syllr/images/raw/master/uPic/202109021748035Ku4WP.png)

### 和mysql binlog的区别

Mysql的binlog是写前日志（Write Ahead Log），也就是说在实际写数据前，先把修改的数据写记到日志文件中，AOF日志和它刚好相反，它是后写日志，即先执行redis命令，然后才记录日志。

![img](https://gitee.com/syllr/images/raw/master/uPic/2021090814242807MDNN.jpg)

redis采用后写日志方式的一个原因是因为，为了避免在记录日志的时候把无效指令记录到AOF文件中，所以采用先执行，这样如果指令在执行失败之后是不会记录到AOF文件中的，比如删除一个不存在的key，而mysql有语法检查可以过滤掉无效指令直接记录日志。

但是采用这种方式在宕机的时候会丢失数据，无论如何也做不到100%的一致性。

### AOF重写

<img src="https://gitee.com/syllr/images/raw/master/uPic/202109021818517vxB5J.png" alt="aof重写流程" style="zoom:67%;" />

* 主进程fork出一个子进程，因为子进程和父进程共享内存，所以可以直接读取进程内的键值对写到新的aof文件中（aof重写是把数据库中所有的键值对都重写一遍，相当于做了一次rdb快照）
* 在子进程进行aof重写的时候，主进程把所有修改键的操作记录到aof_buf，和aof重写buf里面
* 重写完成，子进程给父进程发信号，父进程阻塞（为了不继续接受写请求，出现数据不一致），父进程把aof重写buf里面的数据刷入到新的aof文件中，然后用新的aof文件代替旧的aof文件并且清空aof_buf。

# 事件

## 文件事件

Redis采用的是单Reactor模型，在Redis6.0之后加入了线程池来处理decode和encode的逻辑（主要的状态修改逻辑还是单线程顺序执行）

让我们来追踪一次Redis客户端与服务器进行连接并发送命令的整个过程，看看在过程中会产生什么事件，而这些事件又是如何被处理的。

* 假设一个Redis服务器正在运作，那么这个服务器的**监听套接字**的AE_READABLE事件应该正处于监听状态之下，而该事件所对应的处理器为连接应答处理器。
  如果这时有一个Redis客户端向服务器发起连接，那么监听套接字将产生AE_READABLE事件，
* 触发连接应答处理器执行。处理器会对客户端的连接请求进行应答，然后创建**客户端套接字**，以及客户端状态，并将客户端套接字的AE_READABLE事件与命令请求处理器进行关联，使得客户端可以向主服务器发送命令请求。
* 之后，假设客户端向主服务器发送一个命令请求，那么客户端套接字将产生AE_READABLE事件，引发命令请求处理器执行，处理器读取客户端的命令内容，然后传给相关程序去执行。
* 执行命令将产生相应的命令回复，为了将这些命令回复传送回客户端，服务器会将客户端套接字的AE_WRITABLE事件与命令回复处理器进行关联。当客户端尝试读取命令回复的时候，客户端套接字将产生AE_WRITABLE事件，触发命令回复处理器执行，当命令回复处理器将命令回复全部写入到套接字之后，服务器就会解除客户端套接字的AE_WRITABLE事件与命令回复处理器之间的关联。

Redis为文件事件编写了多个处理器，这些事件处理器分别用于实现不同的网络通信需求，比如说：

* 连接应答处理器：当有客户端用sys/socket.h/connect函数连接服务器监听套接字的时候，套接字就会产生AE_READABLE事件，引发连接应答处理器执行，并执行相应的套接字应答操作
* 命令请求处理器：这个处理器负责从套接字中读入客户端发送的命令请求内容，当一个客户端通过连接应答处理器成功连接到服务器之后，服务器会将客户端套接字的AE_READABLE事件和命令请求处理器关联起来，当客户端向服务器发送命令请求的时候，套接字就会产生AE_READABLE事件，引发命令请求处理器执行，并执行相应的套接字读入操作
* 命令回复处理器：当服务器有命令回复需要传送给客户端的时候，服务器会将客户端套接字的AE_WRITABLE事件和命令回复处理器关联起来，当客户端准备好接收服务器传回的命令回复时，就会产生AE_WRITABLE事件，引发命令回复处理器执行，并执行相应的套接字写入操作

Redis单线程处理IO请求性能瓶颈主要包括2个方面：

1. 任意一个请求在server中一旦发生耗时，都会影响整个server的性能，也就是说后面的请求都要等前面这个耗时请求处理完成，自己才能被处理到。耗时的操作包括以下几种：
   * 操作bigkey：写入一个bigkey在分配内存时需要消耗更多的时间，同样，删除bigkey释放内存同样会产生耗时；
   * 使用复杂度过高的命令：例如SORT/SUNION/ZUNIONSTORE，或者O(N)命令，但是N很大，例如lrange key 0 -1一次查询全量数据；
   * 大量key集中过期：Redis的过期机制也是在主线程中执行的，大量key集中过期会导致处理一个请求时，耗时都在删除过期key，耗时变长；
   * 淘汰策略：淘汰策略也是在主线程执行的，当内存超过Redis内存上限后，每次写入都需要淘汰一些key，也会造成耗时变长；
   * AOF刷盘开启always机制：每次写入都需要把这个操作刷到磁盘，写磁盘的速度远比写内存慢，会拖慢Redis的性能；
   * 主从全量同步生成RDB：虽然采用fork子进程生成数据快照，但fork这一瞬间也是会阻塞整个线程的，实例越大，阻塞时间越久；
2. 并发量非常大时，单线程读写客户端IO数据存在性能瓶颈，虽然采用IO多路复用机制，但是读写客户端数据依旧是同步IO，只能单线程依次读取客户端的数据，无法利用到CPU多核。

针对问题1，一方面需要业务人员去规避，一方面Redis在4.0推出了lazy-free机制，把bigkey释放内存的耗时操作放在了异步线程中执行，降低对主线程的影响。

针对问题2，Redis在6.0推出了多线程，可以在高并发场景下利用CPU多核多线程读写客户端数据，进一步提升server性能，当然，只是针对客户端的读写是并行的，每个命令的真正操作依旧是单线程的。

## 时间事件

Redis的时间事件分为以下两类：

* 定时事件：让一段程序在指定的时间之后执行一次。比如说，让程序X在当前时间的30毫秒之后执行一次。
* 周期性事件：让一段程序每隔指定时间就执行一次。比如说，让程序Y每隔30毫秒就执行一次。

服务器将所有时间事件都放在一个无序链表中，每当时间事件执行器运行时（即事件循环执行一次时），它就遍历整个链表，查找所有已到达的时间事件，并调用相应的事件处理器。

# 主从复制

在redis中，用户可以通过执行slaveof或者replicaof命令，让一个服务器去复制另一个服务器，被复制的服务器是主服务器，复制的服务器被称为从服务器

### Redis主从复制机制的演变

从 Redis 2.6 到 4.0 开发人员对复制流程进行逐步的优化，以下是演进过程：

- 2.8 版本之前 Redis 复制采用 sync 命令，无论是第一次主从复制还是断线重连后再进行复制都采用全量同步，成本高
- 2.8 ~ 4.0 之间复制采用 psync 命令，这一特性主要添加了 Redis 在断线重连时候可通过 offset 信息使用部分同步
- 4.0 版本之后也采用 psync，相比于 2.8 版本的 psync 优化了增量复制，这里我们称为 psync2，2.8 版本的 psync 可以称为 psync1

#### sync

* master接收到slave的同步请求之后，执行BGSAVE命令在后台生成一个RDB文件，然后把RDB文件发送给slave，slave载入slave文件之后，master再把缓冲区的数据发送给slave，slave同步完缓冲区数据之后就完成了数据的同步（

  > Redis在全量复制时，既支持先生成RDB文件，再把RDB文件传给从库，也支持在主库上直接通过socket把数据传给从库，这称为无盘复制。如果运行主库的机器磁盘性能不太好，但是网络性能不错的话，可以考虑无盘复制。

* 完成第一次同步之后，slave和master建立长连接，master把修改数据的命令同步给所有连接的slave（这种方式有个缺点，就是当slave宕机或者掉线，总之就是和master连接断开之后，需要重新来一次全量同步）

### psync

#### 全量重同步

前者和 SYNC 大致相同，都是让 `master` 生成并发送 RDB 文件，然后再将保存在缓冲区中的写命令传播给 `slave` 来进行同步，相当于只有同步和命令传播两个阶段。

### 部分重同步

部分同步适用于断线重连之后的同步，`slave` 只需要接收断线期间丢失的写命令就可以，不需要进行全量同步。为了实现部分同步，引入了复制偏移量`（offset）`、复制积压缓冲区`（replication backlog buffer）`和运行 ID `（run_id）`三个概念。

#### 复制偏移量

执行主从复制的双方都会分别维护一个复制偏移量，`master` 每次向 `slave` 传播 N 个字节，自己的复制偏移量就增加 N；同理 `slave` 接收 N 个字节，自身的复制偏移量也增加 N。通过对比主从之间的复制偏移量就可以知道主从间的同步状态。

#### 复制积压缓冲区（repl_backlog_buffer）

复制积压缓冲区是 `master` 维护的一个环型缓冲区，默认大小为 1MB。当 `master` 进行命令传播时，不仅将写命令发给 `slave` 还会同时写进复制积压缓冲区，因此 `master` 的复制积压缓冲区会保存一部分最近传播的写命令。

当 `slave` 重连上 `master` 时会将自己的复制偏移量通过 PSYNC 命令发给 `master`，`master` 检查自己的复制积压缓冲区，如果发现这部分未同步的命令还在自己的复制积压缓冲区中的话就可以利用这些保存的命令进行部分同步，反之如果断线太久这部分命令已经不在复制缓冲区中了，那没办法只能进行全量同步。

repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。

![img](https://gitee.com/syllr/images/raw/master/uPic/20210908173752tLgoR5.jpg)

**repl_backlog_buffer环形缓冲区的概念非常像mysql的redo log。**

#### 运行 ID

令人疑惑的是上述逻辑看似已经很圆满了，这个 `run_id` 是做什么用呢？其实这是因为 `master` 可能会在 `slave` 断线期间发生变更，例如可能超时失去联系或者宕机导致断线重连的是一个崭新的 master，不再是断线前复制的那个了。自然崭新的 `master` 没有之前维护的复制积压缓冲区，只能进行全量同步。因此每个 Redis server 都会有自己的运行 ID，由 40 个随机的十六进制字符组成。当 `slave` 初次复制 `master` 时，master 会将自己的运行 ID 发给 `slave` 进行保存，这样 `slave`

重连时再将这个运行  ID 发送给重连上的 `master` ，master 会接受这个 ID 并于自身的运行 ID 比较进而判断是否是同一个 master。

#### 缺陷

当master宕机，slave成为master之后，别的slave还是需要从新的master进行全量同步（因为新的master没有复制积压缓冲区和复制偏移量）

### psync2

在psync的基础上让slave也开启了复制积压缓冲区，然后分别用两个字段来记录当前同步的master id和上次同步的master id，当一个slave晋升成为master时会把当前同步的master id改成自己的id，把上次同步的master id设置到上次同步的master id这个字段上，然后当别的slave来进行同步数据的时候可以通过复制偏移量去复制挤压缓冲区去取数据，这样就不用再进行一次全量同步了

当slave变成了新的master之后，剩下的slave来同步数据的时候会带着上次的master id，因为新的master存有上次的master id，所以可以用这个作为判断，即对于剩下的slave其实就是相当于自己掉线了一次，再重新进行增量同步而已

psync2和psync的本质去边就是psync2让所有slave都开启了复制积压缓冲区，当master宕机之后，可以新的master可以保留复制积压缓冲区中的数据进行增量同步

## 主从结构

一主多从

![img](https://gitee.com/syllr/images/raw/master/uPic/20210904161830fhZWkf.png)

链式主从

![img](https://gitee.com/syllr/images/raw/master/uPic/20210904161838SmvLzL.png)

# 哨兵模式

Redis主从复制模式下，一旦主节点（主服务器）由于故障不能提供服务，需要人工将节点晋升为主节点，同时还要通知应用方更新主节点的地址，然而应用方无法及时感知到主节点的变化，必然会造成一定的写数据丢失和读数据错误，所以这是在大多数情况是无法接受的。所以Redis提供了一种高可用的解决方法——哨兵。

Sentinel是Redis的高可用解决方案：**由一个或多个Sentinel实例组成的Sentinel系统可以监视任意多个主服务器以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态下时，自动将下线主服务器属下的某个从服务器升级为主服务器，然后由新的主服务器代替已下线的主服务器继续处理命令请求。如果下线的主服务器重新连接上线的话，它会被Sentinel系统降级为新主服务器的从服务器。**而这些过程完全是自动的，不需要人工介。

### 启动并初始化sentinel

  Sentinel只是一个运行在特殊模式下的Redis服务器，其本身就是独立的Redis节点，只不过它不存储数据，只支持部分命令。

 对于每个被Sentinel监视的主服务器来说，Sentinel会创建两个连向主服务器的异步网络连接：

1. 一个是命令连接，这个连接专门用于向主服务器的网络连接，并接受命令。用于向服务器发送命令，比如发送info命令获取服务器主从信息，发送ping命令维持心跳，发送命令让从服务器变成主服务器，发送slaveof命令指定主服务器等等。
2. 另一个是订阅连接，这个连接专门用于订阅主服务器的_sentinel_:hello频道。通过redis的发布/订阅功能让所有监听一个服务器的sentinel互相建立联系

<img src="https://upload-images.jianshu.io/upload_images/18464438-c2e8877479e80991.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp" alt="img" style="zoom:150%;" />

### Sentinel三个定时任务

* 定时获取服务器信息：sentinel在启动的时候只需要连接主服务器就可以了（不用连接该主服务器的从服务器，也不需要连接其他监听该主服务器的其他sentinel） ，Sentinel默认每10秒一次的频率，通过命令连接向被 监视的主服务器发送*INFO*命令，并通过*INFO*命令的回复来获取主服务器以下的信息：

  1. 服务器本身的信息，包括运行ID以及服务器的角色（role）； 
  2. 主服务属下的所有从服务器信息，包括从服务器的IP地址，端口号，然后保存在内存中。**根据这些IP和端口号，Sentinel无须用户提供从服务器的地址信息，就可以自动发现从服务器。**
  3. 当sentinel通过第二步获取到了从服务器信息之后，Sentinel还会为创建连接到从服务器的命令连接和订阅连接。在创建命令连接之后， Sentinel在默认情况下， 会以每10秒 一次的频率通过命令连接向从服务器发送*INFO*命令，并获取从服务器的回复信息，包括从服务器运行ID、从服务器的角色，主服务器的IP和端口、从服务的优先级等。根据这些信息对从服务器实例结构进行更新。

* 定时发送订阅消息：在默认情况下，Sentinel会以每2秒一次的频率，通过命令连接向所有被监听的主服务器和从服务器的_sentinel_ hello频道发送一条消息。消息的信息包括Sentinel本身的信息和对主服务器判断的信息。

  *   当Sentinel与一个主服务器或者从服务器建立起订阅连接之后， Sentinel就会通过订阅连接， 向服务器发送以下命令：SUBSCRIBE _sentinel_:hello 。
  *  Sentinel对_sentinel_:hello频道的订阅会一直持续到Sentinel与服务器的连接断开为止。
  * 这也就是说， 对于每个与Sentinel连接的服务器， Sentinel既通过命令连接向服务器的 sentinel_:hello频道发送信息， 又通过订阅连接从服务器的 sentinel :hello 频道接收信息。

  >   对于监视同一个服务器的多个Sentinel 来说， 一个Sentinel发送的信息会被其他 Sentinel接收到， 这些信息会被用于更新其他Sentinel对发送信息Sentinel的认知 ，也会被用于更新其他Sentinel对被监视服务器的认知。
  >
  >   举个例子， 假设现在有sentinel1、sentinel 2、sentinel 3三个Sentinel在监视同一个服务器， 那么当sentinel1向服务器的_sentinel_:hello频道发送一条信息时，所有订阅了_sentinel_:hello频道的Sentinel（包括sentinel1自己在内）都会收到这条信息。
  >
  > ![img](https://gitee.com/syllr/images/raw/master/uPic/20210905144642rIxy00.jpg)
  >
  > **因为一个Sentinel可以通过分析接收到的频道信息来获取其他Sentinel的存在，并通过发送频道信息让其他Sentinel知道自己的存在，所以用户在使用Sentinel时不需要提供各个Sentinel的地址信息，监视同一个主服务器的多个Sentinel可以自动发现对方。**

  * 创建连向其他Sentinel命令连接：当Sentinel通过频道信息发现一个新的Sentinel时， 它不仅会为新Sentinel在sentinels中创建相应的实例结构， 还会创建一个连向新Sentinel的命令连接， 而新Sentinel也同样会创建连向这个Sentinel的命令连接， 最终监视同一主服务器的多个Sentinel将形成相互连接的网络。

    > ![img](https://gitee.com/syllr/images/raw/master/uPic/20210905144934Z4sFWm.jpg)
    >
    > 通过定时往发送订阅消息，利用redis的发布/订阅模式，实现了监听一个服务器的所有sentinel之间的相互连接

* 发送心跳：在默认情况下，Sentinel会以**每秒一次**的频率向所有与它创建了命令的连接实例**（包括主服务器、从服务器、其他Sentinel在内），发送PING命令**，并通过实例返回PING命令的回复判断实例是否在线，如果在规定的时间内，连续向Sentinel返回无效的回复（除了+PONG、-LOADING、-MASTERDOWN之外的回复），那么Sentinel会修改这个实例所对应的实例结构，在结构的flags属性中打开SRI_S_DOWN标识，以此来标识这个实例已经进入了**主观下线状态**。

### 检查下线

#### 主观下线和客观下线

如果监视的服务器在规定的时间内没有给sentinel回复有效的信息，则这台sentinel判断该服务器主观下线，当一台sentinel判读一台服务器主观下线之后，会询问监控这台服务器的所有sentinel，当有足够数量的（大于配置的quorum）sentinel都任务这个服务器下线，则认定该服务器客观下线。

#### 选举领头sentinel

当一个主服务器被判断为客观下线时，监视这个下线的主服务器的各个Sentinel会进行协商，选举出一个领头Sentinel（选举的算法为raft算法），并由领头Sentinel对下线主服务器执行故障转移操作。

在投票过程中，任何一个想成为 Leader 的哨兵，要满足两个条件：第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。以 3 个哨兵为例，假设此时的 quorum 设置为 2，那么，任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以了。

![img](https://gitee.com/syllr/images/raw/master/uPic/20210908203006BzD4SD.jpg)

* 在 T1 时刻，S1 判断主库为“客观下线”，它想成为 Leader，就先给自己投一张赞成票，然后分别向 S2 和 S3 发送命令，表示要成为 Leader。
* 在 T2 时刻，S3 判断主库为“客观下线”，它也想成为 Leader，所以也先给自己投一张赞成票，再分别向 S1 和 S2 发送命令，表示要成为 Leader。
* 在 T3 时刻，S1 收到了 S3 的 Leader 投票请求。因为 S1 已经给自己投了一票 Y，所以它不能再给其他哨兵投赞成票了，所以 S1 回复 N 表示不同意。同时，S2 收到了 T2 时 S3 发送的 Leader 投票请求。因为 S2 之前没有投过票，它会给第一个向它发送投票请求的哨兵回复 Y，给后续再发送投票请求的哨兵回复 N，所以，在 T3 时，S2 回复 S3，同意 S3 成为 Leader。
* 在 T4 时刻，S2 才收到 T1 时 S1 发送的投票命令。因为 S2 已经在 T3 时同意了 S3 的投票请求，此时，S2 给 S1 回复 N，表示不同意 S1 成为 Leader。发生这种情况，是因为 S3 和 S2 之间的网络传输正常，而 S1 和 S2 之间的网络传输可能正好拥塞了，导致投票请求传输慢了。
* 最后，在 T5 时刻，S1 得到的票数是来自它自己的一票 Y 和来自 S2 的一票 N。而 S3 除了自己的赞成票 Y 以外，还收到了来自 S2 的一票 Y。此时，S3 不仅获得了半数以上的 Leader 赞成票，也达到预设的 quorum 值（quorum 为 2），所以它最终成为了 Leader。
* 接着，S3 会开始执行选主操作，而且在选定新主库后，会给其他从库和客户端通知新主库的信息。

如果 S3 没有拿到 2 票 Y，那么这轮投票就不会产生 Leader。哨兵集群会等待一段时间（也就是哨兵故障转移超时时间的 2 倍），再重新选举。

这是因为，哨兵集群能够进行成功投票，很大程度上依赖于选举命令的正常网络传播。如果网络压力较大或有短时堵塞，就可能导致没有一个哨兵能拿到半数以上的赞成票。所以，等到网络拥塞好转之后，再进行投票选举，成功的概率就会增加。需要注意的是，如果哨兵集群只有 2 个实例，此时，一个哨兵要想成为 Leader，必须获得 2 票，而不是 1 票。所以，如果有个哨兵挂掉了，那么，此时的集群是无法进行主从库切换的。因此，通常我们至少会配置 3 个哨兵实例。

#### 故障转移

在选举产生出领头Sentinel之后，领头Sentinel将对已下线的主服务器执行故障转移操作，该操作包含以下三个步骤：

* 在已下线主服务器属下的所有从服务器里面，挑选出一个从服务器，并将其转换为主服务器。
* 让已下线主服务器属下的所有从服务器改为复制新的主服务器。
* 将已下线主服务器设置为新的主服务器的从服务器， 当这个旧的主服务器重新上线时，它就会成为新的主服务器的从服务器

**新的主服务器是怎么挑选出来的**

领头Sentinel会将已下线的主服务器的所有从服务器存到一个列表里，然后按照以下规则一条条过滤：

* 过滤掉列表中所有下线或断线状态的从服务器。
*  过滤掉列表中所有最近5秒内没有回复过领头Sentinel的INFO命令的从服务器。
*  过滤掉所有与已下线的主服务连接断开超过规定时长的从服务器，这是为了保证列表中剩余服务器没有过早的与主服务器断开连接，保证列表中从服务器数据都是比较新的。
*  之后，按照从服务器的优先级，对列表中剩余的从服务器排序，选出优先级最高的从服务器；如果存在相同的，则比较从服务器的复制偏移量，选出其中较大的；如果还是存在相同的，则选出运行ID最小的作为主服务器。

### 新的主选出来之后怎么通知客户端

哨兵提升一个从库为新主库后，哨兵会把新主库的地址写入自己实例的pubsub（switch-master）中。客户端需要订阅这个pubsub，当这个pubsub有数据时，客户端就能感知到主库发生变更，同时可以拿到最新的主库地址，然后把写请求写到这个新主库即可，这种机制属于哨兵主动通知客户端。

如果客户端因为某些原因错过了哨兵的通知，或者哨兵通知后客户端处理失败了，安全起见，客户端也需要支持重新上线后主动去sentinel获取最新主从的地址进行访问。

#### 定时任务总结

> * 每隔10秒，每个Sentinel会向服务器的_sentinel_:hello频道发送*INFO*命令，并根据命令的回复信息创建或更新相应的实例结构。
>
> * 每隔2秒，每个Sentinel通过命令连接向所有被监视的主从服务器发送自己当前的信息以及对主服务器的认知信息。同时每个Sentinel也会订阅该频道，来了解其他Sentinel节点以及它们对主服务器的认知。
> * 每隔1秒，每隔Sentinel会向主服务器、从服务器、其余Sentinel发送一条PING命令，并根据回复信息来确认它们是否在线，如果在规定的时间内（通过参数down-after-milliseconds控制）没有进行有效的回复（除了PONG、-LOADING、-MASTERDOWN之外的回复，或者不回复），Sentinel会判定该实例已经进入主观下线。

# Cluster模式

Redis集群主要分为三个模式，主从模式，sentinel模式，cluster模式

## Redis Cluster特点

- **多主多从，去中心化**：从节点作为备用，复制主节点，不做读写操作，不提供服务
- **不支持处理多个key**：因为数据分散在多个节点，在数据量大高并发的情况下会影响性能；
- **支持动态扩容节点**：这是我认为算是Rerdis Cluster最大的优点之一；
- **节点之间相互通信，相互选举，不再依赖sentinel**：准确来说是主节点之间相互“监督”，保证及时故障转移

## Redis Cluster与其它集群模式的区别

- 相比较sentinel模式，**多个master节点可以互相保证主要业务（比如master节点主要负责写）稳定性，不需要搭建多个sentinel实例监控一个master节点**；
- 相比较一主多从的模式，不需要手动切换**，具有自我故障检测，故障转移的特点**；
- 相比较其他两个模式而言，**对数据进行分片（sharding），不同节点存储的数据是不一样的**；
- 从某种程度上来说，Sentinel模式主要针对高可用（HA），**而Cluster模式是不仅针对大数据量，高并发，同时也支持HA。**

## Redis Cluster如何集群实现？

### 新节点加入集群

CLUSTER MEET命令：当一个新的节点要加入集群时，通过向节点A（集群中的任意一个节点都可以）发送CLUSTER MEET命令（cluster meet <B节点ip> <B节点port>），客户端可以让接收命令的节点A将另一个节点B添加到节点A当前所在的集群里面，

收到命令的节点A将与节点B进行握手（handshake），以此来确认彼此的存在，并且交换信息，节点A会为节点B创建一个**clusterNode**结构，并将该结构添加到自己的clusterState.nodes字典里面 ，节点A会将节点B的信息通过**Gossip**协议传播给集群中的其他节点，让其他节点也与节点B进行握手，最终，经过一段时间之后，节点B会被集群中的所有节点认识。

### Redis Cluster是如何将数据分片的？----哈希槽Slot

Redis集群使用一种称作一致性哈希的复合分区形式（组合了哈希分区和列表分袂的特征来计算键的归属实例），键的CRC16哈希值被称为哈希槽。比如对于三个Redis节点，哈希槽的分配方式如下：

* 第一个节点拥有0-5500哈希槽
* 第二节点拥有5501-11000哈希槽
* 第三节点拥有剩余的11001-16384哈希槽

当数据库中的16384个槽都有节点在处理时，集群处于上线状态（ok）；相反地，如果数据库中有任何一个槽没有得到处理，那么集群处于下线状态（fail）。每个节点所负责的槽位都是手动指派的，一个节点可以负责0个槽，也可以负责16384个槽

### 记录节点的槽指派信息

clusterNode结构的slots属性和numslot属性记录了节点负责处理哪些槽：

```c
struct clusterNode {
  // ...
  unsigned char slots[16384/8];
  int numslots;
  // ...
};
```

slots属性是一个二进制位数组（bit array，就是一个位图），这个数组的长度为16384/8=2048个字节，共包含16384个二进制位，如果slots数组在索引i上的二进制位的值为1，那么表示该节点负责处理槽i，numslots负责表示该节点一共负责处理多少个槽。

一个节点除了会将自己负责处理的槽记录在clusterNode结构的slots属性和numslots属性之外，它还会将自己的slots数组通过消息发送给集群中的其他节点，以此来告知其他节点自己目前负责处理哪些槽。

因为集群中的每个节点都会将自己的slots数组通过消息发送给集群中的其他节点，并且每个接收到slots数组的节点都会将数组保存到相应节点的clusterNode结构里面，因此，集群中的每个节点都会知道数据库中的16384个槽分别被指派给了集群中的哪些节点。

clusterState结构中的slots数组记录了集群中所有16384个槽的指派信息：

```c
typedef struct clusterState {
  // ...
  clusterNode *slots[16384];
  // ...
} clusterState;
```

slots数组包含16384个项，每个数组项都是一个指向clusterNode结构的指针：

* 如果slots[i]指针指向NULL，那么表示槽i尚未指派给任何节点。
* 如果slots[i]指针指向一个clusterNode结构，那么表示槽i已经指派给了clusterNode结构所代表的节点。”

<img src="https://gitee.com/syllr/images/raw/master/uPic/20210906205518lfE2id.png" alt="image-20210906205516196" style="zoom:67%;" />

这样每个节点都存有集群中所有槽的指派信息，并且可以通过数组直接读取每个槽所指派的节点信息，复杂度仅为O(1)。

### 在集群中执行命令

在对数据库中的16384个槽都进行了指派之后，集群就会进入上线状态，这时客户端就可以向集群中的节点发送数据命令了。

当客户端向节点发送与数据库键有关的命令时，接收命令的节点会计算出命令要处理的数据库键属于哪个槽，并检查这个槽是否指派给了自己：

* 如果键所在的槽正好就指派给了当前节点，那么节点直接执行这个命令。
* 如果键所在的槽并没有指派给当前节点，那么节点会向客户端返回一个MOVED错误，指引客户端转向（redirect）至正确的节点，并再次发送之前想要执行的命令。

![image-20210906205753765](https://gitee.com/syllr/images/raw/master/uPic/20210906205755vDo2Kn.png)

客户端第一次连接集群可以通过cluster nodes命令获取集群中每个节点所指派的槽和每个节点的信息，并且存入本地的缓存中，方便在每次调用的时候查询，并且如果遇到moved错误的时候更新槽的分配信息。

### 重新分片

Redis集群的重新分片可以将任意数量已经指派给某个节点（源节点）的槽改为指派给另一个节点（目标节点），并且相关槽所属的键值对也会被移动到目标节点。

### 迁移中的数据怎么处理

在进行重新分片期间，源节点向目标节点迁移过程中，可能会出现这样一种情况：**当客户端有操作键值对的有关的命令，同时该键值对正好属于被迁移槽。并且被迁移槽的部分键值对还驻留在source节点中，另外部分键已经保存在target节点中**；则会进行下列动作：

- **如果能在source节点找到对应的key，那么直接执行client的命令；**
- **如果找不到该key，那很有可能就在target中，此时source节点会向client发送一个ASK错误，引导client转向正在导入槽的target节点，并再次发送之前想要执行的命令。**

　　举例说明：比如在源节点中一开始有key1-key3三个key，此时需要源节点需要向目标节点迁移，key2已经迁移完成，key3正在迁移，则会发生以下动作：

![img](https://gitee.com/syllr/images/raw/master/uPic/202109062206579fMvYk.png)

### ASK错误与MOVED错误的区别

按照参考书上定义其实就已经很明了，两者之间的区别

- MOVED错误表示槽的负责权已经从一个节点转移到另外的节点。（如果是moved的错误说明该槽的所有数据都已经转移，客户端接收到这个错误之后应该更新本地的槽指派信息，下一次对这个槽的所有请求应该都发送到新的节点）
- ASK错误则是表示两个节点在迁移槽过程中对key处理的负责权。（ASK错误说明槽还在转移中，只是槽中的这一个键发生了转移，客户端接收到这个错误之后不会更新本地的槽指派信息，下一次对这个槽的所有请求还是应该发送给以前的服务器）

### 故障转移

#### 故障检测

集群中每个节点都会定期地向集群中的其他节点（不分主从）发送PING消息，以此检测对方是否在线；如果接收PING消息的节点没有在规定的时间内，向发送PING消息的节点返回PONG消息，那么发送PING消息的节点就会将PING消息节点标记为疑似下线（possible fail，PFAIL）。

![img](https://gitee.com/syllr/images/raw/master/uPic/20210906221738niluA6.png)

**如果在集群中，超过半数以上负责处理槽的主节点都将某个节点X标记为PFAIL，则某个主节点就会将这个主节点X就会被标记为已下线（FAIL），并且广播到这条消息，这样其他所有的节点都会立即将主节点X标记为FAIL。**

#### 故障转移流程

当一个从节点发现自己正在复制的主节点下线时，从节点将开始对下线主节点进行故障转移：

1. 在该下线主节点的所有从节点中，选择一个做主节点
2. 被选中的从节点会执行SLAVEOF no one命令，成为新的主节点
3. 新的主节点会撤销对所有对已下线主节点的槽指派，并将这些槽全部派给自己。
4. 新的主节点向集群广播一条PONG消息，让其他节点知道“我已经变成主节点了，并且我会接管已下线节点负责的处理的槽”
5. 新主节点开始接收和自己负责处理的槽有关的命令请求，故障转移完成。

#### 选举新节点

1. 集群配置纪元是一个自增计数器，它的初始值为0；
2. 当集群里的某个节点开始一次故障转移时，集群配置纪元的值会被增加1
3. 对于每个配置纪元，集群里的每个负责处理槽的主节点都有一次投票的机会，而第一个向主节点要求投票的从节点将获得主节点的投票。
4. 当从节点发现自己正在复制的主节点进入已下线状态时，从节点会向集群广播消息：要求所有收到这条消息、并且具有投票权的主节点向这个从节点投票。
5. 如果一个主节点具有投票权，并且这个主节点尚未投票跟其它从节点，那么主节点将要求投票的从节点返回一条ACK消息，表示支持该从节点成为新的主节点。
6. 每个主节点只有一次投票机会，所有有N个主节点的话，那么具有大于N/2+1张支持票的从节点只有一个。
7. 如果在一个配置纪元里没有从节点能收集到足够多的支持票，那么集群进入一个新的配置纪元，并再次进行选举，直到选出新的主节点为止。

总结：这跟sentinel模式下的选举类似，两个都是**基于Raft算法的领头选举方法**来实现

## 一致性哈希算法

Redis cluster的分片方法是利用哈希槽进行分片，redis集群时3.0版本才出现的，出现的比较晚，在集群模式出现之前，很多公司都做了自己的redis集群了。

这些自研的redis集群的实现方式有多种

* 比如在redis的jedis客户端jar包就是实现了一致性hash算法（客户端模式）
* 或者在redis集群前面加上一层前置代理如Twemproxy也实现了hash一致性算法（代理模式）

一致性哈希算法并不是Redis cluster采用的分片方案，但是有很多客户端和中间件都采用这种分片方案。

### 主要解决的问题

一致性hash算法主要应用于分布式存储系统中，可以有效地解决分布式存储结构下普通余数Hash算法带来的伸缩性差的问题，**可以保证在动态增加和删除节点的情况下尽量有多的请求命中原来的机器节点。**

举个例子，现在集群中有六个节点，其中三主三从，

* 那么16384个哈希槽第一台主负责0到5461
* 第二台主负责5462到10922
* 第三台主负责10923到16384

如果这个时候新加入两台机器，一主一丛，那么所有的哈希槽需要重新分配，第一台主需要负责0到4121，第二台主需要负责4122到8242，第三台主需要负责8242到12363，第四台主需要负责12364到16384，这要算下来需要有一半左右的槽需要迁移。

解决上面的问题大概有两种方案

* 第一种就是redis cluster采用的方案，每个节点分配的槽可以不是均匀且连续的，这样的话就可以在每次重新分配槽的时候手动指定槽给新的节点，让槽的迁移数最小
* 使用哈希环

### **Hash环**

一致性Hash算法也是使用取模的方法，只是，刚才描述的取模法是对服务器的数量进行取模，而一致性Hash算法是对2^ 32-1取模，，一致性Hash算法将整个Hash值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32-1取模（即哈希值是一个32位无符号整型），整个哈希环如下：

![preview](https://gitee.com/syllr/images/raw/master/uPic/20210906233733gEpSxs.jpg)

整个空间按顺时针方向组织，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^ 32-1，也就是说0点左侧的第一个点代表2^ 32-1， 0和2^ 32-1在零点中方向重合，我们把这个由2^32个点组成的圆环称为Hash环。

下一步将各个服务器进行哈希，具体可以选择服务器的主机名（考虑到ip变动，不要使用ip）作为关键字进行哈希，这样每台机器就能确定其在哈希环上的位置，这里假设将上文中三个master节点的IP地址哈希后在环空间的位置如下：

![preview](https://gitee.com/syllr/images/raw/master/uPic/20210906233752pj2jzv.jpg)

例如我们有a、b、c三个key，经过哈希计算后，在环空间上的位置如下：key-a存储在node1，key-b存储在node2，key-c存储在node3。

![preview](https://gitee.com/syllr/images/raw/master/uPic/20210906233811VZsugs.jpg)

现假设Node 2不幸宕机，可以看到此时对象key-a和key-c不会受到影响，只有key-b被重定位到Node 3。

一般的，在一致性Hash算法中，如果一台服务器不可用，则受影响的数据仅仅是此服务器到其环空间中前一台服务器（即沿着逆时针方向行走遇到的第一台服务器，如下图中Node 2与Node 1之间的数据，图中受影响的是key-2）之间数据，其它不会受到影响。

同样的，如果集群中新增一个node 4，受影响的数据是node 1和node 4之间的数据，其他的数据是不受影响的。

![preview](https://gitee.com/syllr/images/raw/master/uPic/20210906233849Hrjnxh.jpg)

综上所述，一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的容错性和可扩展性。

### 数据倾斜

一致性Hash算法在服务节点太少时，容易因为节点分部不均匀而造成数据倾斜（被缓存的对象大部分集中缓存在某一台服务器上）问题，例如系统中只有两台服务器，此时必然造成大量数据集中到Node 2上，而只有极少量会定位到Node 1上。其环分布如下：



![img](https://gitee.com/syllr/images/raw/master/uPic/202109062343492W5mSM.jpg)

为了解决数据倾斜问题，一致性Hash算法引入了虚拟节点机制，即对每一个服务节点计算多个哈希，每个计算结果位置都放置一个此服务节点，称为虚拟节点。具体做法可以在主机名的后面增加编号来实现。例如上面的情况，可以为每台服务器计算三个虚拟节点，于是可以分别计算 “Node 1#1”、“Node 1#2”、“Node 1#3”、“Node 2#1”、“Node 2#2”、“Node 2#3”的哈希值，于是形成六个虚拟节点：

![img](https://gitee.com/syllr/images/raw/master/uPic/20210906234407AahMSL.jpg)



上图中虚拟节点node 1#1，node 1#2，node 1#3都属于真实节点node 1；虚拟节点node 2#1，node 2#2，node 2#3都属于真实节点node 2。

### 实际项目中使用

上来先说一个误区，Redis 集群没有使用一致性hash, 而是引入了哈希槽slots的概念

我们说的一致性hash都不是缓存机器自身的功能，而是集群前置的代理或客户端实现的。而redis官方的集群是集群本身通过slots实现了数据分片。

# 发布订阅功能

Redis的发布与订阅功能由PUBLISH、SUBSCRIBE、PSUBSCRIBE等命令组成。

通过执行SUBSCRIBE命令，客户端可以订阅一个或多个频道，从而成为这些频道的订阅者（subscriber）：每当有其他客户端向被订阅的频道发送消息（message）时，**频道的所有订阅者都会收到这条消息。**

除了订阅频道之外，客户端还可以通过执行PSUBSCRIBE命令订阅一个或多个模式，从而成为这些模式的订阅者：每当有其他客户端向某个频道发送消息时，消息不仅会被发送给这个频道的所有订阅者，它还会被发送给所有与这个频道相匹配的模式的订阅者。

![image-20210907124232210](https://gitee.com/syllr/images/raw/master/uPic/20210907124234fIlcjB.png)

## 频道的订阅与退订

Redis将所有频道的订阅关系都保存在服务器状态的pubsub_channels字典里，这个字典的键是某个被订阅的频道，而键的值则是一个链表，链表里面记录了所有订阅这个频道的客户端

```c
struct redisServer {
  // 保存所有频道的订阅关系
  dict *pubsub_channels;
  // ...别的属性
};
```

![image-20210907124700563](https://gitee.com/syllr/images/raw/master/uPic/202109071247023NKcXK.png)

## 模式的订阅和退订

服务器将所有频道的订阅关系都保存在服务器状态的pubsub_channels属性里面，与此类似，服务器也将所有模式的订阅关系都保存在服务器状态的pubsub_patterns属性里面：

```c
struct redisServer {
  // ...
  //保存所有模式订阅关系
  list *pubsub_patterns;
  // ...
};
```

pubsub_patterns属性是一个链表，链表中的每个节点都包含着一个pubsub Pattern结构，这个结构的pattern属性记录了被订阅的模式，而client属性则记录了订阅模式的客户端：

```c
typedef struct pubsubPattern {
  // 订阅模式的客户端
  redisClient *client;
  // 被订阅的模式
  robj *pattern;
} pubsubPattern;
```

![image-20210907125028187](https://gitee.com/syllr/images/raw/master/uPic/20210907125029RMmLZo.png)

当一个Redis客户端执行PUBLISH<channel><message>命令将消息message发送给频道channel的时候，服务器需要执行以下两个动作：

1. 将消息message发送给channel频道的所有订阅者。
2. 如果有一个或多个模式pattern与频道channel相匹配，那么将消息message发送给pattern模式的订阅者。

## 将消息发送给订阅者

因为redis服务器在内存中存储了频道的订阅信息和模式的订阅信息，所以在服务器接收到发布的消息的时候，会立刻在内存中查找到订阅该频道的客户端，然后直接发送给对应的客户端，由于这种的发布模式，所以在客户端下线的时候，是无法接收到订阅消息的。

# 多命令（事务）

Redis通过MULTI、EXEC、WATCH等命令来实现事务（transaction）功能。事务提供了一种将多个命令请求打包，然后一次性、按顺序地执行多个命令的机制，并且在事务执行期间，服务器不会中断事务而改去执行其他客户端的命令请求，它会将事务中的所有命令都执行完毕，然后才去处理其他客户端的命令请求。

事务从开始到结束通常会经历以下三个阶段：

1. 事务开始。
2. 命令入队。事务队列以先进先出的方式保存入队的命令，较先入队的命令会被放到数组的前面，而较后入队的命令则会被放到数组的后面
3. 事务执行。

## 事务的使用

### 1. 开启事务

命令:`multi`

```
127.0.0.1:6379> multi
OK
```

执行该命令后,连接会进入事务模式

### 2.执行操作

可以执行任意的redis数据操作命令,那么执行操作会进入一个`待执行队列`

```
127.0.0.1:6379> set name zhangsan
QUEUED
127.0.0.1:6379> set age 34
QUEUED
```

### 3.提交事务

命令:`exec`
提交之后,`待执行队列`中的命令将执行

```
127.0.0.1:6379> exec
1) OK
2) OK
```

## 事务的具体情况处理

### Redis事务的特点

#### 1.没有隔离级别的概念

开启事务之后的操作全部是在`待执行队列`中缓存,并没有真正执行,也就不存在事务内部的查询要看到事务即将的更新,事务外部也不知道

#### 2.不保证原子性（或者说保证一定的原子性）

Redis对单条命令是保证原子性(比如批量`msetnx`命令),但是如果事务不保证原子性(一致性),就没有回滚的概念了.事务中任何命令的失败，**其余命令任会执行**

> 可以这么说.Redis的以上两个事务特征几乎可以认为,redis没有事务功能.更应该称之为命令的打包执行.

#### 3.若在`待执行队列`中存在语法性错误,`exec`提交之后,其他正确命令也会被执行,这是单纯的错误命令抛出异常

```sql
127.0.0.1:6379> multi
OK
127.0.0.1:6379> set name li si #错误的命令
QUEUED
127.0.0.1:6379> set money 100
QUEUED
127.0.0.1:6379> exec
1) (error) ERR syntax error
2) OK
```

> 如果是错误的命令名(比如`setnx`写成`setnn`,则不能称之为语法错误),如果在队列中出现了类似错误,则整个队列不成功

### watch

语法:`watch key`
watch类似于乐观锁

如果在`watch`命令观测一个`key`之后,开启事务后修改该`key`.这个时候如果有其它连接修改了`key`,则会导致事务执行失败,在这个事务的其他操作也是失败
`exec`之后,`watch`命令监控取消

`watch`命令可以说是redis的事务功能最关键的运用了,在使用了`watch`之后可以保证一定的原子性和数据安全

#### watch命令的使用

![preview](https://gitee.com/syllr/images/raw/master/uPic/20210907184503RYrtaO.jpg)

1. 在执行MULTI之前，首先使用watch命令监控一个key或者多个key

2. 使用multi命令将要执行的命令入队列

3. 使用EXEC命令执行队列里面的命令：EXEC在执行命令的时候会去判断客户端的REDIS_DIRTY_CAS标识

   * 如果客户端的REDIS_DIRTY_CAS标识已经被打开，那么说明客户端所监视的键当中，至少有一个键已经被修改过了，在这种情况下，客户端提交的事务已经不再安全，所以服务器会拒绝执行客户端提交的事务。
   * 如果客户端的REDIS_DIRTY_CAS标识没有被打开，那么说明客户端监视的所有键都没有被修改过（或者客户端没有监视任何键），事务仍然是安全的，服务器将执行客户端提交的这个事务。

   ![image-20210907185929329](https://gitee.com/syllr/images/raw/master/uPic/202109071859319qOeTp.png)

#### watch命令的实现

每个Redis数据库都保存着一个watched_keys字典，这个字典的键是某个被WATCH命令监视的数据库键，而字典的值则是一个链表，链表中记录了所有监视相应数据库键的客户端。

![image-20210907190321757](https://gitee.com/syllr/images/raw/master/uPic/20210907190323mHOGjx.png)

所有对数据库进行修改的命令，比如SET、LPUSH、SADD、ZREM、DEL、FLUSHDB等等，在执行之后都会调用multi.c/touchWatchKey函数对watched_keys字典进行检查，查看是否有客户端正在监视刚刚被命令修改过的数据库键。

如果有的话，那么touchWatchKey函数会将监视被修改键的客户端的REDIS_DIRTY_CAS标识打开，表示该客户端的事务安全性已经被破坏。

## 事务的ACID属性

### 原子性

事务具有原子性指的是，数据库将事务中的多个操作当作一个整体来执行，服务器要么就执行事务中的所有操作，要么就一个操作也不执行。

Redis的事务和传统的关系型数据库事务的最大区别在于，**Redis不支持事务回滚机制（rollback）**，即使事务队列中的某个命令在执行期间出现了错误，整个事务也会继续执行下去，直到将事务队列中的所有命令都执行完毕为止。

### 一致性

**可以理解一致性就是，应用系统从一个正确的状态到另一个正确的状态，而ACID就是说事务能够通过AID来保证这个C的过程。C是目的，AID都是手段**。Redis的事务并不具备一致性

### 隔离性

Redis的事务在执行的时候都是串行执行的，并且通过watch命令可以避免在命令入队列时候的，对应的键被修改，所以Redis的事务是满足隔离性的，而且隔离的级别是串行化。

### 持久性

RDB和AOF两种备份方式保证了Redis事务的持久性，具体的持久性要看redis采用哪种备份方式

redis它只是做到了

1. 它认为的原子性。
2. 隔离性。
3. AOF/RDB保证了部分的持久性。
4. 它不存在ACID中的一致性的概念。

因为redis的事务必须要保证执行的命令都是在同一个服务器执行（redis的事务是单机事务，并不是分布式事务），所以在集群模式下，事务的支持程度不好，当然如果能确定一个事务中的所有涉及到的键都存在同一个节点中，那么也是可以支持事务的。

## 事务和lua脚本，pipeline的比较

### pipeline

* pipeline是只有一次网络开销执行多个命令，而redis事务是N次网络开销执行N次命令
* pipeline不具备原子性，redis的事务具备原子性
* pipeline可能存在的场景是：pipeline 中执行**命令1 命令2 命令3** 其他非pinpeline执行**命令4 命令5**，最后的结果可能是**命令1 命令4 命令2 命令5 命令3**，即不保证隔离性。

### lua脚本

redis用multi命令开启事务后，后面的命令都是放入队列中，遇到exec再真正的执行，放入队列中的命令不会立马返回结果，只是返回QUEUED表示成功放入命令。EXEC统一执行了之后统一返回每个命令的结果。

换句话说，如果我们想实现这个场景，用redis的事务就实现不了：得到key=age1的数据，如果该数据存在且该数据为100，那么删掉该数据，否则不做操作。因为在事务中get age1命令返回的时QUEUED，并不是返回的age1的值

而这个场景用redis lua脚本可以实现，lua脚本的和multi都利用了redis串行化执行命令的特点保证了隔离性，但是lua脚本没有提供watch命令，而同时lua脚本可以在脚本中执行判断流程和循环流程等其他逻辑。

**在cluster模式下，lua脚本和multi命令都要求所涉及到的key在同一个节点。**

# 其他

## bit array

Redis提供了`SETBIT`、`GETBIT`、`BITCOUNT`、`BITOP`四个命令用于处理二进制位数组。

- `SETBIT`:为位数组指定偏移量上的二进制位设置值，偏移量从0开始计数，二进制位的值只能为0或1。返回原位置值。
- `GETBIT`:获取指定偏移量上二进制位的值。
- `BITCOUNT`:统计位数组中值为1的二进制位数量。
- `BITOP`:对多个位数组进行按位与、或、异或运算。

底层结构

 Redis使用字符串对象(SDS)来表示位数组，因为字符串对象使用的SDS数据结构是二进制安全的，所以程序可以直接使用SDS结构来保存位数组，并使用SDS结构的操作函数来处理位数组。

## 布隆过滤器

布隆过滤器（Bloom Filter）是由Howard Bloom在1970年提出的一种比较巧妙的概率型数据结构，它可以告诉你某种东西**一定不存在**或者**可能存在**。

* 当布隆过滤器说，某种东西存在时，这种东西可能不存在；
* 当布隆过滤器说，某种东西不存在时，那么这种东西一定不存在。

布隆过滤器相对于Set、Map 等数据结构来说，它可以更高效地插入和查询，并且占用空间更少，它也有缺点，就是判断某种东西是否存在时，可能会被误判。但是只要参数设置的合理，它的精确度也可以控制的相对精确，只会有小小的误判概率。

### redis中的布隆过滤器

之前的布隆过滤器可以使用Redis中的位图操作实现，直到Redis4.0版本提供了插件功能，Redis官方提供的布隆过滤器才正式登场。布隆过滤器作为一个插件加载到Redis Server中，就会给Redis提供了强大的布隆去重功能。

### 布隆过滤器的基本使用

在Redis中，布隆过滤器有两个基本命令，分别是：

- `bf.add`：添加元素到布隆过滤器中，类似于集合的`sadd`命令，不过`bf.add`命令只能一次添加一个元素，如果想一次添加多个元素，可以使用`bf.madd`命令。
- `bf.exists`：判断某个元素是否在过滤器中，类似于集合的`sismember`命令，不过`bf.exists`命令只能一次查询一个元素，如果想一次查询多个元素，可以使用`bf.mexists`命令。

### 布隆过滤器的高级使用

Redis还提供了自定义参数的布隆过滤器，想要尽量减少布隆过滤器的误判，就要设置合理的参数。

在使用`bf.add`命令添加元素之前，使用`bf.reserve`命令创建一个自定义的布隆过滤器。`bf.reserve`命令有三个参数，分别是：

- `key`：键
- `error_rate`：期望错误率，期望错误率越低，需要的空间就越大。
- `capacity`：初始容量，当实际元素的数量超过这个初始化容量时，误判率上升。

### 布隆过滤器的原理

Redis中布隆过滤器的数据结构就是一个很大的位数组和几个不一样的无偏哈希函数（能把元素的哈希值算得比较平均，能让元素被哈希到位数组中的位置比较随机）。如下图，A、B、C就是三个这样的哈希函数，分别对“OneMoreStudy”和“万猫学社”这两个元素进行哈希，位数组的对应位置则被设置为1：
![img](https://gitee.com/syllr/images/raw/master/uPic/202109081037503tcJG5.jpg)
向布隆过滤器中添加元素时，会使用多个无偏哈希函数对元素进行哈希，算出一个整数索引值，然后对位数组长度进行取模运算得到一个位置，每个无偏哈希函数都会得到一个不同的位置。再把位数组的这几个位置都设置为1，这就完成了`bf.add`命令的操作。

向布隆过滤器查询元素是否存在时，和添加元素一样，也会把哈希的几个位置算出来，然后看看位数组中对应的几个位置是否都为1，只要有一个位为0，那么就说明布隆过滤器里不存在这个元素。如果这几个位置都为1，并不能完全说明这个元素就一定存在其中，有可能这些位置为1是因为其他元素的存在，这就是布隆过滤器会出现误判的原因。

### 布隆过滤器的应用

#### 解决缓存穿透的问题

一般情况下，先查询缓存是否有该条数据，缓存中没有时，再查询数据库。当数据库也不存在该条数据时，每次查询都要访问数据库，这就是缓存穿透。缓存穿透带来的问题是，当有大量请求查询数据库不存在的数据时，就会给数据库带来压力，甚至会拖垮数据库。

可以使用布隆过滤器解决缓存穿透的问题，把已存在数据的key存在布隆过滤器中。当有新的请求时，先到布隆过滤器中查询是否存在，如果不存在该条数据直接返回；如果存在该条数据再查询缓存查询数据库。

#### 黑名单校验

发现存在黑名单中的，就执行特定操作。比如：识别垃圾邮件，只要是邮箱在黑名单中的邮件，就识别为垃圾邮件。假设黑名单的数量是数以亿计的，存放起来就是非常耗费存储空间的，布隆过滤器则是一个较好的解决方案。把所有黑名单都放在布隆过滤器中，再收到邮件时，判断邮件地址是否在布隆过滤器中即可。

## fork子进程时阻塞的问题

最新的Linux内核内存是分页的，一个内存页通过配置可以是1kb-2Mb，而用户运行的程序是连续的。

用户的程序在运行的时候需要一片连续的内存空间，如果是在物理内存为不同的程序开辟不同的连续的内存空间，就会有大量的内存碎片的问题。

分页机制的思想是:通过映射，可以使连续的线性地址与物理地址相关联，逻辑上连续的线性地址对应的物理地址可以不连续。 分页的作用 - 将线性地址转换为物理地址 - 用大小相同的页替换大小不同的段。

![img](https://gitee.com/syllr/images/raw/master/uPic/20210908221525nNRPYW.jpg)

### 一级页表

 我们把一页的大小定义为4K,那么4G就有1M个页，在32位的保护模式下，地址都是32位二进制表示的，用20位二进制定位页表，剩余的12位表示4K里面的偏移。

### 二级页表

每个进程1M个页表，每个4字节，进程多了占用的内存还是很多的。

一般进程使用的内存是远低于全部虚拟内存的。二级模式只为进程实际使用的那些虚拟内存区分配页表，既提升了效率，也减少了内存的使用量。

fork时虽然有写时复制的机制不会把主进程的所有内存拷贝一边，但是会把主进程所有涉及到的页表（就是虚拟内存和物理内存的映射）都复制一份，如果主内存的数据量大，页表的数据量也大，也会阻塞主进程。

## 使用二级编码节约内存容量

使用string作为键值对数据存储结构，如果键值对的数量太多，而且每个键值的字符串都不长比如url，因为String字符串有大量的元数据，如果String容量不大，那么会有很多内存用来存放元数据，这样浪费的空间太多，可以使用二级编码，用一个hash对象来存储，在hash对象中数据比较少的时候是利用ziplist存储的。所以可以利用编码把大量数据都存放到一个hash对象中。这样可以利用ziplist把所有的数据存储。节约容量，如果以100万个长度为10的字符串键值对为例，这种方式可以把内存的消耗从70Mb到10Mb。

## 基数统计（HyperLogLog）

HyperLogLog 是一种用于统计基数的数据集合类型，它的最大优势就在于，当集合元素数量非常多时，它计算基数所需的空间总是固定的，而且还很小。

在 Redis 中，每个 HyperLogLog 只需要花费 12 KB 内存，就可以计算接近 2^64 个元素的基数。你看，和元素越多就越耗费内存的 Set 和 Hash 类型相比，HyperLogLog 就非常节省空间。

![img](https://gitee.com/syllr/images/raw/master/uPic/20210909103641HgBulm.jpg)

HyperLogLog要求所有的请求都在同一个节点上，所以在集群模式下这个数据结构的用处不大。

## GEOHASH

GEOHASH是Redis用来存储经纬度的数据结构，这个方法的基本原理就是“二分区间，区间编码”。当我们要对一组经纬度进行 GeoHash 编码时，我们要先对经度和纬度分别编码，然后再把经纬度各自的编码组合成一个最终编码。

GeoHash编码类似二分查找，但是我们不一定要找到具体的元素，找出元素所在的区间即可。假如我们的地理范围从-180到180。目标值是120，第一次二分是-180～0和0～180。那么目标值就在右边，这时可以用一个bit表示，比如1。后面依次类推，二分的次数可以自己定，最终会根据二分的结果形成一个二进制串，比如11001。

## Redis子线程

Redis 主线程启动后，会使用操作系统提供的 pthread_create 函数创建 3 个子线程，分别由它们负责 AOF 日志写操作、键值对删除以及文件关闭的异步执行。

![img](https://gitee.com/syllr/images/raw/master/uPic/20210910101418kESmEa.jpg)

主线程通过一个链表形式的任务队列和子线程进行交互。当收到键值对删除和清空数据库的操作时，主线程会把这个操作封装成一个任务，放入到任务队列中，然后给客户端返回一个完成信息，表明删除已经完成。但实际上，这个时候删除还没有执行，等到后台子线程从任务队列中读取任务后，才开始实际删除键值对，并释放相应的内存空间。

因此，我们把这种异步删除也称为惰性删除（lazy free）。此时，删除或清空操作不会阻塞主线程，这就避免了对主线程的性能影响。

主线程在删除数据的时候会判断这个对象的大小，如果是比较大就会把redisDB里面的key删除（相当于标记删除，让下次主线程查找时找不到这个key），然后给子线程发任务，让子线程来删除value对象（把内存释放），如果对象比较小，就直接在主线程删除了。

和惰性删除类似，当 AOF 日志配置成 everysec 选项后，主线程会把 AOF 写日志操作封装成一个任务，也放到任务队列中。后台子线程读取任务后，开始自行写入 AOF 日志，这样主线程就不用一直等待 AOF 日志写完了。

## 淘汰策略

Redis 4.0 之前一共实现了 6 种内存淘汰策略，在 4.0 之后，又增加了 2 种策略。我们可以按照是否会进行数据淘汰把它们分成两类：

* 不进行数据淘汰的策略，只有 noeviction 这一种。
* 会进行淘汰的 7 种其他策略。

会进行淘汰的 7 种策略，我们可以再进一步根据淘汰候选数据集的范围把它们分成两类

* 在设置了过期时间的数据中进行淘汰，包括 volatile-random、volatile-ttl、volatile-lru、volatile-lfu（Redis 4.0 后新增）四种。
* 在所有数据范围内进行淘汰，包括 allkeys-lru、allkeys-random、allkeys-lfu（Redis 4.0 后新增）三种。

![img](https://gitee.com/syllr/images/raw/master/uPic/20210910133718ik3sjO.jpg)

### LRU和LFU的实现

#### 内存污染

在一些场景下，有些数据被访问的次数非常少，甚至只会被访问一次。当这些数据服务完访问请求后，如果还继续留存在缓存中的话，就只会白白占用缓存空间。这种情况，就是缓存污染。

#### Redis中的LRU和LFU

RedisObject中有一个lru字段存储着该数据最近被访问的时间，当数据被访问的时候会更新这个数据（无论是读操作还是写操作都会更新这个字段），scan，keys这些操作也会更新lru的数据

所以，对于采用了 LRU 策略的 Redis 缓存来说，扫描式单次查询会造成缓存污染。为了应对这类缓存污染问题，Redis 从 4.0 版本开始增加了 LFU 淘汰策略。

与 LRU 策略相比，LFU 策略中会从两个维度来筛选并淘汰数据：一是，数据访问的时效性（访问时间离当前时间的远近）；二是，数据的被访问次数。

LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时

* 首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。
* 如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。

和那些被频繁访问的数据相比，扫描式单次查询的数据因为不会被再次访问，所以它们的访问次数不会再增加。因此，LFU 策略会优先把这些访问次数低的数据淘汰出缓存。这样一来，LFU 策略就可以避免这些数据对缓存造成污染了。

LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。

**Redis 在实现 LFU 策略的时候，只是把原来 24bit 大小的 lru 字段，又进一步拆分成了两部分。前面16个字节用来记录数据的访问时间戳，后面八个字节用来记录数据的访问次数，后八个字节的次数并不是和访问次数一一对应的，而是类似于指数的方式，比如访问100次记录为2，访问1000次记录为3**

#### 贪心算法

Redis中并没有有链表或则集合来记录整个数据库中LRU或者LRU的排名，而是每次要剔除内存的时候随机选取一定数量的数据，在这些数据中比较LRU和LFU，把符合的数据删除。

## 分布式锁

[redis中分布式锁的介绍](https://mp.weixin.qq.com/s/s8xjm1ZCKIoTGT3DCVA4aw)

## Redis6.0新特性

### 多个 IO 线程来处理网络请求，提高网络请求处理的并行度

### 客户端缓存

redis6.0提供了一个种通知机制，通知客户端哪些key被改变，也称为跟踪（Tracking）功能，可以用来实现客户端缓存

6.0 实现的 Tracking 功能实现了两种模式，来解决**如果数据被修改了或是失效了，如何通知客户端对缓存的数据做失效处理？**这个问题。

* 第一种模式是普通模式。在这个模式下，实例会在服务端记录客户端读取过的 key，并监测 key 是否有修改。一旦 key 的值发生变化，服务端会给客户端发送 invalidate 消息，通知客户端缓存失效了。
* 第二种模式是广播模式。在这个模式下，服务端会给客户端广播所有 key 的失效情况，不过，这样做了之后，如果 key 被频繁修改，服务端会发送大量的失效广播消息，这就会消耗大量的网络带宽资源。

## Hashtag分片

在cluster模式下，如果一个key中有{}符号，比如key:{111}，redis集群在进行crc取模来算出哈希槽的时候，使用的是{}里面的数据来算的，利用这个特性，这样可以把不同的名称的key路由到同一个哈希槽

比如现在需要一个原子性的操作，把keyA加一然后再把KeyB减一（模拟转账），如果是在cluster模式下，因为keyA，和keyB可能分布在不同的节点，所以不能使用lua脚本或者multi命令保证原子性，把keyA，keyB的key值做一下修改为KeyA:{1}，keyB:{1}，这样两个key最后都会被存到同一个节点。
